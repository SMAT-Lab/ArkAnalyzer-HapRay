#!/usr/bin/env python3
"""
æ›¿æ¢ perf HTML æŠ¥å‘Šä¸­çš„ç¼ºå¤±ç¬¦å·ä¸º LLM æ¨æ–­çš„å‡½æ•°å
"""

import base64
import gzip
import re
import zlib

import pandas as pd

from core.utils import config
from core.utils.logger import get_logger

logger = get_logger(__name__)


def load_function_mapping(excel_file):
    """ä» Excel æ–‡ä»¶åŠ è½½åœ°å€åˆ°å‡½æ•°åçš„æ˜ å°„"""
    df = pd.read_excel(excel_file, engine='openpyxl')

    # åˆ›å»ºæ˜ å°„ï¼šåœ°å€ -> å‡½æ•°å
    mapping = {}
    for _, row in df.iterrows():
        address = str(row.get('åœ°å€', '')).strip()
        function_name = str(row.get('LLMæ¨æ–­å‡½æ•°å', '')).strip()

        if address and function_name and function_name != 'nan' and function_name:
            # æå–åœ°å€éƒ¨åˆ†ï¼ˆå¦‚ libxwebcore.so+0x50338a0ï¼‰
            mapping[address] = function_name

    logger.info(f'âœ… åŠ è½½äº† {len(mapping)} ä¸ªå‡½æ•°åæ˜ å°„')
    return mapping


def extract_symbol_from_address(address_str):
    """ä»åœ°å€å­—ç¬¦ä¸²ä¸­æå–ç¬¦å·éƒ¨åˆ†ï¼ˆå¦‚ libxwebcore.so+0x50338a0 æˆ– libtaobaoavsdk_bridge.so+0x1243acï¼‰"""
    # åŒ¹é… lib*.so+0x... æ ¼å¼ï¼ˆæ”¯æŒä¸‹åˆ’çº¿ï¼Œå¦‚ libtaobaoavsdk_bridge.soï¼‰
    match = re.search(r'(lib[\w_]+\.so\+0x[0-9a-fA-F]+)', address_str, re.IGNORECASE)
    if match:
        return match.group(1)
    return None


def replace_symbols_in_html(html_content, function_mapping):
    """åœ¨ HTML å†…å®¹ä¸­æ›¿æ¢ç¼ºå¤±ç¬¦å·ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œåªå¤„ç† JSON æ•°æ®éƒ¨åˆ†ï¼‰"""

    # ç»Ÿè®¡ä¿¡æ¯
    replaced_count = {'count': 0}
    replacement_info = []

    # æå–åœ°å€éƒ¨åˆ†ï¼ˆå¦‚ libxwebcore.so+0x50338a0 æˆ– libtaobaoavsdk_bridge.so+0x1de430ï¼‰
    def extract_address(full_path):
        """ä»å®Œæ•´è·¯å¾„ä¸­æå–åœ°å€éƒ¨åˆ†ï¼ˆæ”¯æŒä»»ä½• .so æ–‡ä»¶ï¼ŒåŒ…æ‹¬ä¸‹åˆ’çº¿ï¼‰"""
        # ä½¿ç”¨ [\w_]+ æ¥åŒ¹é…åŒ…å«ä¸‹åˆ’çº¿çš„åº“åï¼Œå¦‚ libtaobaoavsdk_bridge.so
        match = re.search(r'(lib[\w_]+\.so\+0x[0-9a-fA-F]+)', full_path, re.IGNORECASE)
        return match.group(1) if match else None

    # ä¼˜åŒ–ï¼šä¼˜å…ˆå¤„ç† <script id="record_data"> æ ‡ç­¾ä¸­çš„ JSON æ•°æ®
    # è¿™æ˜¯ Chart Statistics ä½¿ç”¨çš„æ•°æ®æº
    record_data_pattern = r'(<script id="record_data"[^>]*>)(.*?)(</script>)'
    record_data_match = re.search(record_data_pattern, html_content, re.DOTALL | re.IGNORECASE)

    # ä¹Ÿæ£€æŸ¥ <script id="record_bz_data"> æ ‡ç­¾ï¼ˆå‹ç¼©çš„ JSON æ•°æ®ï¼‰
    if not record_data_match:
        record_bz_data_pattern = r'(<script[^>]*id=["\']record_bz_data["\'][^>]*>)(.*?)(</script>)'
        record_data_match = re.search(record_bz_data_pattern, html_content, re.DOTALL | re.IGNORECASE)

    json_match = None
    data_content = None
    data_prefix = ''
    data_suffix = ''

    if record_data_match:
        logger.info('æ‰¾åˆ° <script id="record_data"> æ•°æ®å—ï¼Œä¼˜å…ˆå¤„ç†è¿™éƒ¨åˆ†...')
        data_prefix = record_data_match.group(1)
        data_content_raw = record_data_match.group(2).strip()  # åŸå§‹æ•°æ®å†…å®¹
        data_suffix = record_data_match.group(3)

        # æ£€æŸ¥æ•°æ®æ˜¯å¦è¢«ç¼–ç /å‹ç¼©
        data_content = None
        is_compressed = False

        # æ£€æŸ¥æ˜¯å¦æ˜¯ base64 ç¼–ç 
        if not data_content_raw.startswith('{') and not data_content_raw.startswith('['):
            logger.info('  æ£€æµ‹åˆ°æ•°æ®å¯èƒ½è¢«ç¼–ç /å‹ç¼©ï¼Œå°è¯•è§£ç ...')
            try:
                # å°è¯• base64 è§£ç 
                decoded = base64.b64decode(data_content_raw)
                logger.info(f'  âœ… Base64 è§£ç æˆåŠŸï¼Œå¤§å°: {len(decoded) / 1024 / 1024:.2f} MB')

                # æ£€æŸ¥æ˜¯å¦æ˜¯ gzip
                if decoded[:2] == b'\x1f\x8b':
                    logger.info('  âœ… æ£€æµ‹åˆ° gzip å‹ç¼©ï¼Œæ­£åœ¨è§£å‹...')
                    decompressed = gzip.decompress(decoded)
                    data_content = decompressed.decode('utf-8', errors='ignore')
                    is_compressed = True
                    logger.info(f'  âœ… Gzip è§£å‹æˆåŠŸï¼Œå¤§å°: {len(data_content) / 1024 / 1024:.2f} MB')
                # æ£€æŸ¥æ˜¯å¦æ˜¯ zlib
                elif decoded[:2] in (b'x\x9c', b'x\xda', b'x\x01'):
                    logger.info('  âœ… æ£€æµ‹åˆ° zlib å‹ç¼©ï¼Œæ­£åœ¨è§£å‹...')
                    decompressed = zlib.decompress(decoded)
                    data_content = decompressed.decode('utf-8', errors='ignore')
                    is_compressed = True
                    compression_format = 'zlib'
                    logger.info(f'  âœ… Zlib è§£å‹æˆåŠŸï¼Œå¤§å°: {len(data_content) / 1024 / 1024:.2f} MB')
                else:
                    compression_format = None
                    # ç›´æ¥å°è¯•ä½œä¸º UTF-8 å­—ç¬¦ä¸²
                    try:
                        data_content = decoded.decode('utf-8', errors='ignore')
                        logger.info('  âœ… è§£ç ä¸º UTF-8 å­—ç¬¦ä¸²')
                    except Exception:
                        logger.info('  âš ï¸  æ— æ³•è§£ç ï¼Œä½¿ç”¨åŸå§‹æ•°æ®')
                        data_content = data_content_raw
            except Exception as e:
                logger.info(f'  âš ï¸  è§£ç å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ•°æ®')
                data_content = data_content_raw
        else:
            # å·²ç»æ˜¯ JSON æ ¼å¼
            data_content = data_content_raw

        # ä¼˜åŒ–ï¼šåªå¤„ç† SymbolMap éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯æ•´ä¸ª JSON
        # åœ¨ data_content ä¸­æŸ¥æ‰¾ SymbolMap
        symbol_map_start = data_content.find('"SymbolMap"')
        if symbol_map_start == -1:
            symbol_map_start = data_content.find('"functionMap"')  # å¯èƒ½æ˜¯å‹ç¼©æ ¼å¼

        if symbol_map_start != -1:
            logger.info('åœ¨ record_data ä¸­æ‰¾åˆ° SymbolMapï¼Œåªå¤„ç†è¿™éƒ¨åˆ†...')
            # æ‰¾åˆ° SymbolMap çš„å¼€å§‹å’Œç»“æŸä½ç½®
            brace_start = data_content.find('{', symbol_map_start)
            brace_count = 0
            symbol_map_end = brace_start

            # ä¼˜åŒ–ï¼šé™åˆ¶æœç´¢èŒƒå›´ï¼Œé¿å…å¤„ç†è¿‡å¤§çš„æ•°æ®
            max_search = min(len(data_content), brace_start + 10000000)  # æœ€å¤š10MB
            logger.info(f'  æœç´¢ SymbolMap è¾¹ç•Œï¼ˆèŒƒå›´: {max_search - brace_start} å­—èŠ‚ï¼‰...')

            for i in range(brace_start, max_search):
                if data_content[i] == '{':
                    brace_count += 1
                elif data_content[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        symbol_map_end = i + 1
                        break

                # æ¯å¤„ç† 1MB è¾“å‡ºä¸€æ¬¡è¿›åº¦
                if (i - brace_start) % 1000000 == 0 and i > brace_start:
                    logger.info(f'    æœç´¢è¿›åº¦: {(i - brace_start) / 1024 / 1024:.1f} MB')

            if brace_count != 0:
                logger.info('  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°å®Œæ•´çš„ SymbolMap è¾¹ç•Œï¼Œä½¿ç”¨æ•´ä¸ª record_data')
                symbol_map_end = len(data_content)

            # åªæ›¿æ¢ SymbolMap éƒ¨åˆ†
            symbol_map_content = data_content[symbol_map_start:symbol_map_end]

            # åˆ›å»ºä¸€ä¸ªåŒ¹é…å¯¹è±¡
            class SymbolMapMatch:
                def __init__(
                    self,
                    full_start,
                    full_end,
                    prefix,
                    suffix,
                    content_before,
                    symbol_map,
                    content_after,
                ):
                    self._full_start = full_start
                    self._full_end = full_end
                    self._prefix = prefix
                    self._suffix = suffix
                    self._content_before = content_before
                    self._symbol_map = symbol_map
                    self._content_after = content_after

                def start(self):
                    return self._full_start

                def end(self):
                    return self._full_end

                def get_parts(self):
                    return (
                        self._prefix,
                        self._content_before,
                        self._symbol_map,
                        self._content_after,
                        self._suffix,
                    )

            json_match = SymbolMapMatch(
                record_data_match.start(),
                record_data_match.end(),
                data_prefix,
                data_suffix,
                data_content[:symbol_map_start],
                symbol_map_content,
                data_content[symbol_map_end:],
            )
            # æ ‡è®°æ˜¯å¦å‹ç¼©å’Œå‹ç¼©æ ¼å¼ï¼Œç”¨äºåç»­å¤„ç†
            json_match._is_compressed = is_compressed
            json_match._compression_format = compression_format
        else:
            logger.info('åœ¨ record_data ä¸­æœªæ‰¾åˆ° SymbolMapï¼Œå¤„ç†æ•´ä¸ª JSON...')

            # å›é€€åˆ°å¤„ç†æ•´ä¸ª JSON
            class RecordDataMatch:
                def __init__(self, start, end, prefix, content, suffix, compressed=False):
                    self._start = start
                    self._end = end
                    self._prefix = prefix
                    self._content = content
                    self._suffix = suffix
                    self._is_compressed = compressed

                def start(self):
                    return self._start

                def end(self):
                    return self._end

                def group(self, n):
                    if n == 1:
                        return self._prefix
                    if n == 2:
                        return self._content
                    return ''

            json_match = RecordDataMatch(
                record_data_match.start(),
                record_data_match.end(),
                data_prefix,
                data_content,
                data_suffix,
                is_compressed,
            )
            # æ ‡è®°å‹ç¼©æ ¼å¼
            json_match._compression_format = compression_format

    # å¦‚æœæ²¡æ‰¾åˆ° record_dataï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»– JSON æ•°æ®å—
    if not json_match:
        # æŸ¥æ‰¾åŒ…å« SymbolMap çš„ JSON å¯¹è±¡
        # å…ˆå°è¯•æŸ¥æ‰¾å†…è”çš„ JSON å¯¹è±¡ï¼ˆå¯èƒ½å¾ˆå¤§ï¼Œéœ€è¦æ‰¾åˆ°å®Œæ•´çš„å¯¹è±¡ï¼‰
        # æŸ¥æ‰¾ "SymbolMap" çš„ä½ç½®
        symbol_map_pos = html_content.find('"SymbolMap"')
        if symbol_map_pos != -1:
            # å‘å‰æŸ¥æ‰¾ JSON å¯¹è±¡çš„å¼€å§‹
            json_start = symbol_map_pos
            while json_start > 0 and html_content[json_start] != '{':
                json_start -= 1
                if json_start < symbol_map_pos - 1000000:  # æœ€å¤šå‘å‰æŸ¥æ‰¾1MB
                    break

            if json_start >= 0 and html_content[json_start] == '{':
                # æ‰¾åˆ° JSON å¯¹è±¡çš„å¼€å§‹ï¼Œç°åœ¨æ‰¾åˆ°ç»“æŸä½ç½®ï¼ˆä¼˜åŒ–ï¼šæ·»åŠ è¿›åº¦æç¤ºï¼‰
                brace_count = 0
                json_end = json_start
                max_search = min(len(html_content), json_start + 10000000)  # æœ€å¤š10MB
                logger.info(f'  æœç´¢ JSON å¯¹è±¡è¾¹ç•Œï¼ˆèŒƒå›´: {max_search - json_start} å­—èŠ‚ï¼‰...')

                for i in range(json_start, max_search):
                    if html_content[i] == '{':
                        brace_count += 1
                    elif html_content[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break

                    # æ¯å¤„ç† 1MB è¾“å‡ºä¸€æ¬¡è¿›åº¦
                    if (i - json_start) % 1000000 == 0 and i > json_start:
                        logger.info(f'    æœç´¢è¿›åº¦: {(i - json_start) / 1024 / 1024:.1f} MB')

                if brace_count != 0:
                    logger.info('  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°å®Œæ•´çš„ JSON å¯¹è±¡è¾¹ç•Œ')
                    json_end = min(len(html_content), json_start + 10000000)

                if json_end > json_start:
                    # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰èµ‹å€¼è¯­å¥
                    prefix_start = max(0, json_start - 200)
                    prefix_text = html_content[prefix_start:json_start]

                    # æŸ¥æ‰¾èµ‹å€¼è¯­å¥
                    assign_match = re.search(
                        r'(window\.data\s*=\s*|(?:const|let|var)\s+json\s*=\s*)$',
                        prefix_text,
                        re.MULTILINE,
                    )
                    if assign_match:
                        # æ‰¾åˆ°èµ‹å€¼è¯­å¥ï¼Œåˆ›å»ºåŒ¹é…å¯¹è±¡
                        class InlineJsonMatch:
                            def __init__(self, start, end, prefix, content):
                                self._start = start
                                self._end = end
                                self._prefix = prefix
                                self._content = content

                            def start(self):
                                return self._start

                            def end(self):
                                return self._end

                            def group(self, n):
                                if n == 1:
                                    return self._prefix
                                if n == 2:
                                    return self._content
                                return ''

                        json_match = InlineJsonMatch(
                            json_start,
                            json_end,
                            html_content[prefix_start:json_start],
                            html_content[json_start:json_end],
                        )

        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ ¼å¼
        if not json_match:
            json_patterns = [
                r'(window\.data\s*=\s*)(\{.*?"SymbolMap".*?\});',
                r'((?:const|let|var)\s+json\s*=\s*)(\{.*?"SymbolMap".*?\});',
            ]

            for pattern in json_patterns:
                match = re.search(pattern, html_content, re.DOTALL | re.IGNORECASE)
                if match:
                    json_match = match
                    break

    if json_match:
        logger.info('æ‰¾åˆ° JSON æ•°æ®å—ï¼Œåªå¤„ç†è¿™éƒ¨åˆ†...')

        # åˆ¤æ–­æ˜¯ SymbolMapMatch è¿˜æ˜¯å…¶ä»–ç±»å‹
        if hasattr(json_match, 'get_parts'):
            # SymbolMapMatch å¯¹è±¡ - åªå¤„ç† SymbolMap éƒ¨åˆ†
            (
                data_prefix,
                content_before,
                symbol_map_content,
                content_after,
                data_suffix,
            ) = json_match.get_parts()
            data_content_to_replace = symbol_map_content
            is_symbol_map_only = True
        elif hasattr(json_match, '_content'):
            # RecordDataMatch å¯¹è±¡
            data_prefix = json_match._prefix
            data_content_to_replace = json_match._content
            data_suffix = json_match._suffix
            content_before = ''
            content_after = ''
            is_symbol_map_only = False
        elif hasattr(json_match, 'group'):
            # æ­£åˆ™åŒ¹é…å¯¹è±¡
            data_prefix = json_match.group(1) if json_match.group(1) else ''
            data_content_to_replace = json_match.group(2)
            data_suffix = ''
            content_before = ''
            content_after = ''
            is_symbol_map_only = False
        else:
            data_prefix = ''
            data_content_to_replace = html_content[json_match.start() : json_match.end()]
            data_suffix = ''
            content_before = ''
            content_after = ''
            is_symbol_map_only = False

        # åªåœ¨è¿™ä¸ªæ•°æ®å—ä¸­è¿›è¡Œæ›¿æ¢ï¼ˆæ”¯æŒæ‰€æœ‰ .so æ–‡ä»¶ï¼‰
        so_addresses = function_mapping  # ä½¿ç”¨æ‰€æœ‰åœ°å€æ˜ å°„ï¼Œä¸å†åªè¿‡æ»¤ libxwebcore.so
        total_addresses = len(so_addresses)
        logger.info(f'  éœ€è¦å¤„ç† {total_addresses} ä¸ªåœ°å€æ˜ å°„')
        logger.info(f'  JSON æ•°æ®å—å¤§å°: {len(data_content_to_replace) / (1024 * 1024):.2f} MB')

        # ä¼˜åŒ–ï¼šå…ˆä½¿ç”¨æ–¹æ³•1æ‰¹é‡æ›¿æ¢ symbol å­—æ®µï¼Œè¿™æ˜¯æœ€å¸¸è§çš„æ ¼å¼
        logger.info('  æ­¥éª¤ 1/3: æ‰¹é‡æ›¿æ¢ symbol å­—æ®µ...')

        def replace_in_symbol_field(match):
            prefix = match.group(1)  # "symbol": " æˆ– "f": "
            symbol_value = match.group(2)  # ç¬¦å·å€¼

            # å¦‚æœå·²ç»æ›¿æ¢è¿‡ï¼Œè·³è¿‡
            if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in symbol_value:
                return match.group(0)

            # æå–åœ°å€éƒ¨åˆ†ï¼ˆå¯èƒ½æ˜¯å®Œæ•´è·¯å¾„æˆ–ç®€å•åœ°å€ï¼‰
            address = extract_address(symbol_value)
            if address and address in so_addresses:
                function_name = so_addresses[address]
                replaced_count['count'] += 1
                if address not in [r['original'] for r in replacement_info]:
                    replacement_info.append({'original': address, 'replaced': function_name})
                return f'{prefix}{function_name} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ]"'
            return match.group(0)

        # åŒ¹é… symbol å­—æ®µï¼ˆå®Œæ•´æ ¼å¼å’Œå‹ç¼©æ ¼å¼ï¼‰
        symbol_pattern = r'("(?:symbol|f)"\s*:\s*")([^"]*lib[\w_]+\.so\+0x[0-9a-fA-F]+[^"]*)"'
        data_content_to_replace = re.sub(
            symbol_pattern, replace_in_symbol_field, data_content_to_replace, flags=re.IGNORECASE
        )
        logger.info(f'  æ­¥éª¤ 1 å®Œæˆï¼Œå·²æ›¿æ¢ {replaced_count["count"]} ä¸ªç¬¦å·')

        # æ–¹æ³•2: æ›¿æ¢å®Œæ•´è·¯å¾„æ ¼å¼ï¼ˆä¼˜åŒ–ï¼šåªå¤„ç†æœªè¢«æ–¹æ³•1æ›¿æ¢çš„åœ°å€ï¼‰
        logger.info('  æ­¥éª¤ 2/3: æ›¿æ¢å®Œæ•´è·¯å¾„æ ¼å¼...')
        existing_replacements = {r['original'] for r in replacement_info}
        remaining_addresses = {addr: name for addr, name in so_addresses.items() if addr not in existing_replacements}
        if remaining_addresses:
            logger.info(f'  å‰©ä½™ {len(remaining_addresses)} ä¸ªåœ°å€éœ€è¦å¤„ç†...')
            logger.info(
                f'  æ³¨æ„: ç”±äº JSON æ•°æ®å—è¾ƒå¤§ï¼ˆ{len(data_content_to_replace) / (1024 * 1024):.2f} MBï¼‰ï¼Œå¤„ç†å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...'
            )
            total_patterns = len(remaining_addresses) * 3  # æ¯ä¸ªåœ°å€3ä¸ªæ¨¡å¼
            pattern_count = 0

            for processed, (address, function_name) in enumerate(remaining_addresses.items(), 1):
                logger.info(f'    å¤„ç†åœ°å€ {processed}/{len(remaining_addresses)}: {address[:50]}...')

                # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´ç®€å•çš„æ¨¡å¼ï¼Œé¿å…å¤æ‚çš„æ­£åˆ™
                # ç›´æ¥æ›¿æ¢åœ°å€å­—ç¬¦ä¸²ï¼ˆè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼‰
                escaped_address = re.escape(address)

                # æ¨¡å¼1: å®Œæ•´è·¯å¾„æ ¼å¼
                pattern_count += 1
                logger.info(f'      æ¨¡å¼ 1/3: å®Œæ•´è·¯å¾„æ ¼å¼ ({pattern_count}/{total_patterns})...')
                pattern_full = rf'([^"]*/proc/[^"]*/)([^"]*libs/arm64/)({escaped_address})'

                def replace_full_path(m, fn=function_name):
                    if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in m.group(0):
                        return m.group(0)
                    replaced_count['count'] += 1
                    return f'{m.group(1)}{m.group(2)}{fn} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ]'

                data_content_to_replace = re.sub(pattern_full, replace_full_path, data_content_to_replace)

                # æ¨¡å¼2: ç®€å•æ ¼å¼ï¼ˆåœ¨å¼•å·å†…ï¼‰
                pattern_count += 1
                logger.info(f'      æ¨¡å¼ 2/3: ç®€å•æ ¼å¼ ({pattern_count}/{total_patterns})...')
                pattern_simple = rf'(")({escaped_address})(")'

                def replace_simple(m, fn=function_name):
                    if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in m.group(0):
                        return m.group(0)
                    replaced_count['count'] += 1
                    return f'{m.group(1)}{fn} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ]{m.group(3)}'

                data_content_to_replace = re.sub(pattern_simple, replace_simple, data_content_to_replace)

                # æ¨¡å¼3: symbol å­—æ®µä¸­çš„å®Œæ•´è·¯å¾„
                pattern_count += 1
                logger.info(f'      æ¨¡å¼ 3/3: symbol å­—æ®µ ({pattern_count}/{total_patterns})...')
                pattern_in_symbol = rf'("(?:symbol|f)"\s*:\s*")([^"]*{escaped_address}[^"]*)"'

                def replace_in_symbol_direct(m, fn=function_name):
                    if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in m.group(2):
                        return m.group(0)
                    replaced_count['count'] += 1
                    return f'{m.group(1)}{fn} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ]"'

                data_content_to_replace = re.sub(pattern_in_symbol, replace_in_symbol_direct, data_content_to_replace)

                logger.info(f'    âœ… åœ°å€ {processed} å¤„ç†å®Œæˆï¼ˆå·²æ›¿æ¢ {replaced_count["count"]} ä¸ªç¬¦å·ï¼‰')

        logger.info(f'  æ­¥éª¤ 2 å®Œæˆï¼Œæ€»å…±æ›¿æ¢äº† {replaced_count["count"]} ä¸ªç¬¦å·')
        logger.info('  æ­¥éª¤ 3/3: å®Œæˆæ›¿æ¢')

        # å¦‚æœæ•°æ®è¢«å‹ç¼©ï¼Œéœ€è¦é‡æ–°å‹ç¼©å’Œç¼–ç 
        # æ£€æŸ¥ json_match æ˜¯å¦æœ‰ _is_compressed å±æ€§
        is_compressed_flag = getattr(json_match, '_is_compressed', False) if json_match else False
        compression_format = getattr(json_match, '_compression_format', 'gzip') if json_match else 'gzip'

        if is_compressed_flag:
            logger.info('  é‡æ–°å‹ç¼©å’Œç¼–ç æ•°æ®...')
            try:
                # å¦‚æœæ˜¯ SymbolMapMatchï¼Œéœ€è¦å‹ç¼©æ•´ä¸ª JSONï¼ˆåŒ…æ‹¬ content_before å’Œ content_afterï¼‰
                # å¦åˆ™åªå‹ç¼© data_content_to_replace
                if is_symbol_map_only:
                    # æ„å»ºå®Œæ•´çš„ JSON å†…å®¹ç”¨äºå‹ç¼©
                    full_json_content = content_before + data_content_to_replace + content_after
                    logger.info(
                        f'  å‹ç¼©å®Œæ•´ JSONï¼ˆåŒ…æ‹¬ SymbolMap å‰åå†…å®¹ï¼‰ï¼Œå¤§å°: {len(full_json_content) / 1024 / 1024:.2f} MB'
                    )
                else:
                    full_json_content = data_content_to_replace

                # æ ¹æ®åŸå§‹å‹ç¼©æ ¼å¼é€‰æ‹©å‹ç¼©æ–¹æ³•
                if compression_format == 'zlib':
                    logger.info('  ä½¿ç”¨ zlib å‹ç¼©...')
                    compressed = zlib.compress(full_json_content.encode('utf-8'))
                else:
                    logger.info('  ä½¿ç”¨ gzip å‹ç¼©...')
                    compressed = gzip.compress(full_json_content.encode('utf-8'))

                # Base64 ç¼–ç 
                encoded = base64.b64encode(compressed).decode('utf-8')

                # æ›´æ–° data_content_to_replace
                # å‹ç¼©åçš„æ•°æ®æ˜¯å®Œæ•´çš„ JSONï¼ˆå¯¹äº SymbolMapMatchï¼‰æˆ–éƒ¨åˆ† JSONï¼ˆå¯¹äºå…¶ä»–æ¨¡å¼ï¼‰
                data_content_to_replace = encoded

                logger.info(f'  âœ… é‡æ–°å‹ç¼©å’Œç¼–ç å®Œæˆï¼Œå¤§å°: {len(encoded) / 1024 / 1024:.2f} MB')
            except Exception:
                logger.exception('  âš ï¸  é‡æ–°å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨æœªå‹ç¼©çš„æ•°æ®')

        # æ›¿æ¢å›åŸæ–‡ä»¶
        start_pos = json_match.start() if hasattr(json_match, 'start') else 0
        end_pos = json_match.end() if hasattr(json_match, 'end') else len(html_content)

        if is_symbol_map_only:
            # SymbolMapMatch - åªæ›¿æ¢ SymbolMap éƒ¨åˆ†
            # å¦‚æœå‹ç¼©äº†ï¼Œdata_content_to_replace æ˜¯å‹ç¼©åçš„æ•´ä¸ª JSON
            if is_compressed_flag:
                # å‹ç¼©æ¨¡å¼ä¸‹ï¼Œdata_content_to_replace å·²ç»æ˜¯å‹ç¼©åçš„æ•´ä¸ª JSON
                # éœ€è¦æ›¿æ¢æ•´ä¸ª record_data å†…å®¹
                html_content = (
                    html_content[:start_pos]
                    + data_prefix
                    + data_content_to_replace
                    + data_suffix
                    + html_content[end_pos:]
                )
            else:
                # æœªå‹ç¼©æ¨¡å¼ï¼Œæ­£å¸¸æ›¿æ¢
                html_content = (
                    html_content[:start_pos]
                    + data_prefix
                    + content_before
                    + data_content_to_replace
                    + content_after
                    + data_suffix
                    + html_content[end_pos:]
                )
        elif hasattr(json_match, '_suffix'):
            # RecordDataMatch å¯¹è±¡ï¼Œéœ€è¦åŒ…å« suffix
            html_content = (
                html_content[:start_pos] + data_prefix + data_content_to_replace + data_suffix + html_content[end_pos:]
            )
        else:
            html_content = html_content[:start_pos] + data_prefix + data_content_to_replace + html_content[end_pos:]
    else:
        # å¦‚æœæ‰¾ä¸åˆ° window.dataï¼Œå›é€€åˆ°å…¨æ–‡ä»¶æ›¿æ¢ï¼ˆä½†åªæ›¿æ¢ symbol å­—æ®µï¼‰
        logger.info('æœªæ‰¾åˆ° window.dataï¼Œä½¿ç”¨å…¨æ–‡ä»¶æ›¿æ¢æ¨¡å¼...')
        so_addresses = function_mapping  # ä½¿ç”¨æ‰€æœ‰åœ°å€æ˜ å°„ï¼Œä¸å†åªè¿‡æ»¤ libxwebcore.so

        def replace_in_symbol_field(match):
            prefix = match.group(1)
            symbol_value = match.group(2)
            address = extract_address(symbol_value)
            if address and address in so_addresses:
                function_name = so_addresses[address]
                replaced_count['count'] += 1
                if address not in [r['original'] for r in replacement_info]:
                    replacement_info.append({'original': address, 'replaced': function_name})
                return f'{prefix}{function_name} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ]"'
            return match.group(0)

        # åŒ¹é… symbol å­—æ®µï¼ˆå®Œæ•´æ ¼å¼å’Œå‹ç¼©æ ¼å¼ "f"ï¼Œæ”¯æŒä»»ä½• .so æ–‡ä»¶ï¼ŒåŒ…æ‹¬ä¸‹åˆ’çº¿ï¼‰
        symbol_pattern = r'("(?:symbol|f)"\s*:\s*")([^"]*lib[\w_]+\.so\+0x[0-9a-fA-F]+[^"]*)"'
        html_content = re.sub(symbol_pattern, replace_in_symbol_field, html_content, flags=re.IGNORECASE)

    logger.info(f'âœ… æ›¿æ¢äº† {replaced_count["count"]} ä¸ªç¼ºå¤±ç¬¦å·')
    return html_content, replacement_info


def add_disclaimer(html_content, reference_report_file=None, relative_path=None):
    """åœ¨ HTML ä¸­æ·»åŠ å…è´£å£°æ˜å’Œå‚è€ƒé“¾æ¥

    Args:
        html_content: HTML å†…å®¹
        reference_report_file: æŠ€æœ¯å‚è€ƒæŠ¥å‘Šæ–‡ä»¶åï¼ˆå¦‚ event_count_top33_report.htmlï¼‰ï¼Œ
                               å¦‚æœä¸º Noneï¼Œåˆ™è‡ªåŠ¨æŸ¥æ‰¾
        relative_path: ä» HTML æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•çš„ç›¸å¯¹è·¯å¾„
                      å¦‚æœä¸º Noneï¼Œåˆ™è‡ªåŠ¨è®¡ç®—æˆ–ä½¿ç”¨é»˜è®¤è·¯å¾„
    """
    # è·å–è¾“å‡ºç›®å½•
    output_dir = config.get_output_dir()
    config.ensure_output_dir(output_dir)

    # ç¡®å®šç›¸å¯¹è·¯å¾„
    if relative_path is None:
        # é»˜è®¤ç›¸å¯¹è·¯å¾„
        relative_path = f'../{output_dir.name}'
    elif relative_path == '.':
        # å½“å‰ç›®å½•ï¼Œä¸éœ€è¦å‰ç¼€
        relative_path = ''

    # ç¡®å®šå‚è€ƒæŠ¥å‘Šæ–‡ä»¶
    if reference_report_file:
        reference_link = f'{relative_path}/{reference_report_file}' if relative_path else reference_report_file
    # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„æŠ¥å‘Šæ–‡ä»¶
    elif output_dir.exists():
        # æŸ¥æ‰¾æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        report_files = list(output_dir.glob('*_report.html'))
        if report_files:
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
            report_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            reference_link = f'{relative_path}/{report_files[0].name}' if relative_path else report_files[0].name
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤åç§°
        elif relative_path:
            reference_link = f'{relative_path}/{config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)}'
        else:
            reference_link = config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)
    elif relative_path:
        reference_link = f'{relative_path}/{config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)}'
    else:
        reference_link = config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)

    disclaimer = f"""
    <!-- ç¬¦å·æ›¿æ¢è¯´æ˜ -->
    <div style="position: fixed; top: 10px; right: 10px; background: #fff3cd; border: 2px solid #ffc107;
                padding: 15px; border-radius: 5px; z-index: 10000; max-width: 350px; font-size: 12px; box-shadow: 0 2px 8px rgba(0,0,0,0.2);">
        <strong>âš ï¸ ç¬¦å·æ›¿æ¢è¯´æ˜</strong><br>
        æŠ¥å‘Šä¸­æ ‡è®°ä¸º <span style="color: #d32f2f; font-weight: bold;">[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]</span> çš„å‡½æ•°å<br>
        æ˜¯é€šè¿‡ LLM åˆ†æåæ±‡ç¼–ä»£ç æ¨æ–­çš„ï¼Œ<br>
        æ ¼å¼ä¸º "Function: {{å‡½æ•°å}}"ï¼Œ<br>
        å¯èƒ½ä¸å®é™…å‡½æ•°åå­˜åœ¨å·®å¼‚ï¼Œä»…ä¾›å‚è€ƒã€‚<br><br>
        <strong>ğŸ“š æŠ€æœ¯å‚è€ƒ:</strong><br>
        <a href="{reference_link}" target="_blank"
           style="color: #1976d2; text-decoration: underline; font-weight: bold;">
           æŸ¥çœ‹è¯¦ç»†åˆ†ææŠ¥å‘Šï¼ˆæŠ€æœ¯åŸç†ã€Tokenç»Ÿè®¡ã€å‡½æ•°åˆ—è¡¨ï¼‰
        </a>
    </div>
    """

    # åœ¨ </body> æ ‡ç­¾å‰æ’å…¥å£°æ˜
    if '</body>' in html_content:
        html_content = html_content.replace('</body>', disclaimer + '</body>')
    elif '</html>' in html_content:
        html_content = html_content.replace('</html>', disclaimer + '</html>')

    return html_content
