#!/usr/bin/env python3
"""
æ›¿æ¢ perf HTML æŠ¥å‘Šä¸­çš„ç¼ºå¤±ç¬¦å·ä¸º LLM æ¨æ–­çš„å‡½æ•°å
"""

import base64
import gzip
import json
import re
import zlib
from pathlib import Path

import pandas as pd

from core.utils import config
from core.utils import common as util
from core.utils.logger import get_logger

logger = get_logger(__name__)


def format_function_name(function_name: str) -> str:
    """
    æ ¼å¼åŒ–å‡½æ•°åï¼Œæ·»åŠ  "Function: " å‰ç¼€
    
    Args:
        function_name: åŸå§‹å‡½æ•°å
    
    Returns:
        æ ¼å¼åŒ–åçš„å‡½æ•°åï¼ˆå¦‚æœä¸ºç©ºåˆ™è¿”å›ç©ºå­—ç¬¦ä¸²ï¼‰
    """
    if not function_name or function_name == 'nan' or function_name == 'None':
        return ''
    # å¦‚æœå·²ç»æœ‰ "Function: " å‰ç¼€ï¼Œä¸å†æ·»åŠ 
    if function_name.startswith('Function: '):
        return function_name
    return f'Function: {function_name}'


def load_function_mapping(excel_file):
    """ä» Excel æ–‡ä»¶åŠ è½½åœ°å€åˆ°å‡½æ•°åçš„æ˜ å°„ï¼ˆç²¾ç¡®åŒ¹é…ï¼‰
    
    ç”±äºåœ°å€æ¥è‡ª perf é‡‡æ ·ï¼Œä¸åˆ†ææ—¶çš„åœ°å€ä¸€è‡´ï¼Œåªéœ€è¦ç²¾ç¡®åŒ¹é…ã€‚
    """
    df = pd.read_excel(excel_file, engine='openpyxl')

    # åˆ›å»ºæ˜ å°„ï¼šåœ°å€ -> å‡½æ•°åï¼ˆæ·»åŠ  "Function: " å‰ç¼€ï¼‰
    mapping = {}
    for _, row in df.iterrows():
        address = str(row.get('åœ°å€', '')).strip()
        function_name = str(row.get('LLMæ¨æ–­å‡½æ•°å', '')).strip()

        if address and function_name and function_name != 'nan' and function_name:
            # æ ¼å¼åŒ–å‡½æ•°åï¼Œæ·»åŠ  "Function: " å‰ç¼€
            formatted_name = format_function_name(function_name)
            mapping[address] = formatted_name

    logger.info(f'âœ… åŠ è½½äº† {len(mapping)} ä¸ªå‡½æ•°åæ˜ å°„')
    return mapping


def load_excel_data_for_report(excel_file):
    """ä» Excel æ–‡ä»¶åŠ è½½å®Œæ•´æ•°æ®ç”¨äºç”ŸæˆæŠ¥å‘Š"""
    df = pd.read_excel(excel_file, engine='openpyxl')
    
    results = []
    for _, row in df.iterrows():
        # å¤„ç† event_count åˆ—åï¼ˆå¯èƒ½æœ‰ç©ºæ ¼æˆ–æ²¡æœ‰ç©ºæ ¼ï¼‰
        event_count = 0
        if 'æŒ‡ä»¤æ•°(event_count)' in row:
            event_count = row.get('æŒ‡ä»¤æ•°(event_count)', 0)
        elif 'æŒ‡ä»¤æ•° (event_count)' in row:
            event_count = row.get('æŒ‡ä»¤æ•° (event_count)', 0)
        
        # å¤„ç†å­—ç¬¦ä¸²å¸¸é‡ï¼ˆå¯èƒ½æ˜¯ NaNï¼‰
        strings_value = row.get('å­—ç¬¦ä¸²å¸¸é‡', '')
        if pd.isna(strings_value):
            strings_value = ''
        else:
            strings_value = str(strings_value)
        
        # å¤„ç†æŒ‡ä»¤æ•°é‡ï¼ˆå¯èƒ½æ˜¯ 'æŒ‡ä»¤æ•°' åˆ—ï¼‰
        instruction_count = row.get('æŒ‡ä»¤æ•°', 0)
        if pd.isna(instruction_count):
            instruction_count = 0
        
        # å¤„ç†è°ƒç”¨çš„å‡½æ•°ï¼ˆå¯èƒ½æ˜¯é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼‰
        called_functions_str = str(row.get('è°ƒç”¨çš„å‡½æ•°', ''))
        called_functions = []
        if called_functions_str and called_functions_str != 'nan':
            called_functions = [f.strip() for f in called_functions_str.split(',') if f.strip()]
        
        # æ ¼å¼åŒ–å‡½æ•°åï¼Œæ·»åŠ  "Function: " å‰ç¼€
        function_name = str(row.get('LLMæ¨æ–­å‡½æ•°å', ''))
        if function_name and function_name != 'nan' and function_name != 'None':
            function_name = format_function_name(function_name)
        
        # å¤„ç†è´Ÿè½½é—®é¢˜è¯†åˆ«ä¸ä¼˜åŒ–å»ºè®®ï¼ˆå¯èƒ½æ˜¯ NaNï¼‰
        performance_analysis = row.get('è´Ÿè½½é—®é¢˜è¯†åˆ«ä¸ä¼˜åŒ–å»ºè®®', '')
        if pd.isna(performance_analysis):
            performance_analysis = ''
        else:
            performance_analysis = str(performance_analysis)
        
        result = {
            'rank': row.get('æ’å', ''),
            'file_path': str(row.get('æ–‡ä»¶è·¯å¾„', '')),
            'address': str(row.get('åœ°å€', '')),
            'offset': str(row.get('åç§»é‡', '')),
            'call_count': row.get('è°ƒç”¨æ¬¡æ•°', 0),
            'instruction_count': int(instruction_count) if instruction_count else 0,
            'event_count': int(event_count) if event_count else 0,
            'strings': strings_value,
            'called_functions': called_functions,  # æ·»åŠ è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
            'llm_result': {
                'function_name': function_name,
                'functionality': str(row.get('LLMåŠŸèƒ½æè¿°', '')),
                'performance_analysis': performance_analysis,  # æ·»åŠ è´Ÿè½½é—®é¢˜è¯†åˆ«ä¸ä¼˜åŒ–å»ºè®®
                'confidence': str(row.get('LLMç½®ä¿¡åº¦', '')),
            }
        }
        results.append(result)
    
    return results


def extract_symbol_from_address(address_str):
    """ä»åœ°å€å­—ç¬¦ä¸²ä¸­æå–ç¬¦å·éƒ¨åˆ†ï¼ˆå¦‚ libxwebcore.so+0x50338a0 æˆ– libtaobaoavsdk_bridge.so+0x1243acï¼‰"""
    # åŒ¹é… lib*.so+0x... æ ¼å¼ï¼ˆæ”¯æŒä¸‹åˆ’çº¿ï¼Œå¦‚ libtaobaoavsdk_bridge.soï¼‰
    match = re.search(r'(lib[\w_]+\.so\+0x[0-9a-fA-F]+)', address_str, re.IGNORECASE)
    if match:
        return match.group(1)
    return None


def replace_symbols_in_html(html_content, function_mapping):
    """åœ¨ HTML å†…å®¹ä¸­æ›¿æ¢ç¼ºå¤±ç¬¦å·ï¼ˆä¼˜åŒ–ç‰ˆæœ¬ï¼Œåªå¤„ç† JSON æ•°æ®éƒ¨åˆ†ï¼‰"""

    # ç»Ÿè®¡ä¿¡æ¯
    replaced_count = {'count': 0}
    replacement_info = []

    # æå–åœ°å€éƒ¨åˆ†ï¼ˆå¦‚ libxwebcore.so+0x50338a0 æˆ– libtaobaoavsdk_bridge.so+0x1de430ï¼‰
    def extract_address(full_path):
        """ä»å®Œæ•´è·¯å¾„ä¸­æå–åœ°å€éƒ¨åˆ†ï¼ˆæ”¯æŒä»»ä½• .so æ–‡ä»¶ï¼ŒåŒ…æ‹¬ä¸‹åˆ’çº¿ï¼‰"""
        # ä½¿ç”¨ [\w_]+ æ¥åŒ¹é…åŒ…å«ä¸‹åˆ’çº¿çš„åº“åï¼Œå¦‚ libtaobaoavsdk_bridge.so
        match = re.search(r'(lib[\w_]+\.so\+0x[0-9a-fA-F]+)', full_path, re.IGNORECASE)
        return match.group(1) if match else None

    # ä¼˜åŒ–ï¼šä¼˜å…ˆå¤„ç† <script id="record_data"> æ ‡ç­¾ä¸­çš„ JSON æ•°æ®
    # è¿™æ˜¯ Chart Statistics ä½¿ç”¨çš„æ•°æ®æº
    record_data_pattern = r'(<script id="record_data"[^>]*>)(.*?)(</script>)'
    record_data_match = re.search(record_data_pattern, html_content, re.DOTALL | re.IGNORECASE)

    # ä¹Ÿæ£€æŸ¥ <script id="record_bz_data"> æ ‡ç­¾ï¼ˆå‹ç¼©çš„ JSON æ•°æ®ï¼‰
    if not record_data_match:
        record_bz_data_pattern = r'(<script[^>]*id=["\']record_bz_data["\'][^>]*>)(.*?)(</script>)'
        record_data_match = re.search(record_bz_data_pattern, html_content, re.DOTALL | re.IGNORECASE)

    json_match = None
    data_content = None
    data_prefix = ''
    data_suffix = ''

    if record_data_match:
        logger.info('æ‰¾åˆ° <script id="record_data"> æ•°æ®å—ï¼Œä¼˜å…ˆå¤„ç†è¿™éƒ¨åˆ†...')
        data_prefix = record_data_match.group(1)
        data_content_raw = record_data_match.group(2).strip()  # åŸå§‹æ•°æ®å†…å®¹
        data_suffix = record_data_match.group(3)

        # æ£€æŸ¥æ•°æ®æ˜¯å¦è¢«ç¼–ç /å‹ç¼©
        data_content = None
        is_compressed = False
        compression_format = None

        # æ£€æŸ¥æ˜¯å¦æ˜¯ base64 ç¼–ç 
        if not data_content_raw.startswith('{') and not data_content_raw.startswith('['):
            logger.info('  æ£€æµ‹åˆ°æ•°æ®å¯èƒ½è¢«ç¼–ç /å‹ç¼©ï¼Œå°è¯•è§£ç ...')
            try:
                # å°è¯• base64 è§£ç 
                decoded = base64.b64decode(data_content_raw)
                logger.info(f'  âœ… Base64 è§£ç æˆåŠŸï¼Œå¤§å°: {len(decoded) / 1024 / 1024:.2f} MB')

                # æ£€æŸ¥æ˜¯å¦æ˜¯ gzip
                if decoded[:2] == b'\x1f\x8b':
                    logger.info('  âœ… æ£€æµ‹åˆ° gzip å‹ç¼©ï¼Œæ­£åœ¨è§£å‹...')
                    decompressed = gzip.decompress(decoded)
                    data_content = decompressed.decode('utf-8', errors='ignore')
                    is_compressed = True
                    compression_format = 'gzip'
                    logger.info(f'  âœ… Gzip è§£å‹æˆåŠŸï¼Œå¤§å°: {len(data_content) / 1024 / 1024:.2f} MB')
                # æ£€æŸ¥æ˜¯å¦æ˜¯ zlib
                elif decoded[:2] in (b'x\x9c', b'x\xda', b'x\x01'):
                    logger.info('  âœ… æ£€æµ‹åˆ° zlib å‹ç¼©ï¼Œæ­£åœ¨è§£å‹...')
                    decompressed = zlib.decompress(decoded)
                    data_content = decompressed.decode('utf-8', errors='ignore')
                    is_compressed = True
                    compression_format = 'zlib'
                    logger.info(f'  âœ… Zlib è§£å‹æˆåŠŸï¼Œå¤§å°: {len(data_content) / 1024 / 1024:.2f} MB')
                else:
                    compression_format = None
                    # ç›´æ¥å°è¯•ä½œä¸º UTF-8 å­—ç¬¦ä¸²
                    try:
                        data_content = decoded.decode('utf-8', errors='ignore')
                        logger.info('  âœ… è§£ç ä¸º UTF-8 å­—ç¬¦ä¸²')
                    except Exception:
                        logger.info('  âš ï¸  æ— æ³•è§£ç ï¼Œä½¿ç”¨åŸå§‹æ•°æ®')
                        data_content = data_content_raw
            except Exception as e:
                logger.info(f'  âš ï¸  è§£ç å¤±è´¥: {e}ï¼Œä½¿ç”¨åŸå§‹æ•°æ®')
                data_content = data_content_raw
        else:
            # å·²ç»æ˜¯ JSON æ ¼å¼
            data_content = data_content_raw

        # ä¼˜åŒ–ï¼šåªå¤„ç† SymbolMap éƒ¨åˆ†ï¼Œè€Œä¸æ˜¯æ•´ä¸ª JSON
        # åœ¨ data_content ä¸­æŸ¥æ‰¾ SymbolMap
        symbol_map_start = data_content.find('"SymbolMap"')
        if symbol_map_start == -1:
            symbol_map_start = data_content.find('"functionMap"')  # å¯èƒ½æ˜¯å‹ç¼©æ ¼å¼

        if symbol_map_start != -1:
            logger.info('åœ¨ record_data ä¸­æ‰¾åˆ° SymbolMapï¼Œåªå¤„ç†è¿™éƒ¨åˆ†...')
            # æ‰¾åˆ° SymbolMap çš„å¼€å§‹å’Œç»“æŸä½ç½®
            brace_start = data_content.find('{', symbol_map_start)
            brace_count = 0
            symbol_map_end = brace_start

            # ä¼˜åŒ–ï¼šé™åˆ¶æœç´¢èŒƒå›´ï¼Œé¿å…å¤„ç†è¿‡å¤§çš„æ•°æ®
            max_search = min(len(data_content), brace_start + 10000000)  # æœ€å¤š10MB
            logger.info(f'  æœç´¢ SymbolMap è¾¹ç•Œï¼ˆèŒƒå›´: {max_search - brace_start} å­—èŠ‚ï¼‰...')

            for i in range(brace_start, max_search):
                if data_content[i] == '{':
                    brace_count += 1
                elif data_content[i] == '}':
                    brace_count -= 1
                    if brace_count == 0:
                        symbol_map_end = i + 1
                        break

                # æ¯å¤„ç† 1MB è¾“å‡ºä¸€æ¬¡è¿›åº¦
                if (i - brace_start) % 1000000 == 0 and i > brace_start:
                    logger.info(f'    æœç´¢è¿›åº¦: {(i - brace_start) / 1024 / 1024:.1f} MB')

            if brace_count != 0:
                logger.info('  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°å®Œæ•´çš„ SymbolMap è¾¹ç•Œï¼Œä½¿ç”¨æ•´ä¸ª record_data')
                symbol_map_end = len(data_content)

            # åªæ›¿æ¢ SymbolMap éƒ¨åˆ†
            symbol_map_content = data_content[symbol_map_start:symbol_map_end]

            # åˆ›å»ºä¸€ä¸ªåŒ¹é…å¯¹è±¡
            class SymbolMapMatch:
                def __init__(
                    self,
                    full_start,
                    full_end,
                    prefix,
                    suffix,
                    content_before,
                    symbol_map,
                    content_after,
                ):
                    self._full_start = full_start
                    self._full_end = full_end
                    self._prefix = prefix
                    self._suffix = suffix
                    self._content_before = content_before
                    self._symbol_map = symbol_map
                    self._content_after = content_after

                def start(self):
                    return self._full_start

                def end(self):
                    return self._full_end

                def get_parts(self):
                    return (
                        self._prefix,
                        self._content_before,
                        self._symbol_map,
                        self._content_after,
                        self._suffix,
                    )

            json_match = SymbolMapMatch(
                record_data_match.start(),
                record_data_match.end(),
                data_prefix,
                data_suffix,
                data_content[:symbol_map_start],
                symbol_map_content,
                data_content[symbol_map_end:],
            )
            # æ ‡è®°æ˜¯å¦å‹ç¼©å’Œå‹ç¼©æ ¼å¼ï¼Œç”¨äºåç»­å¤„ç†
            json_match._is_compressed = is_compressed
            json_match._compression_format = compression_format
        else:
            logger.info('åœ¨ record_data ä¸­æœªæ‰¾åˆ° SymbolMapï¼Œå¤„ç†æ•´ä¸ª JSON...')

            # å›é€€åˆ°å¤„ç†æ•´ä¸ª JSON
            class RecordDataMatch:
                def __init__(self, start, end, prefix, content, suffix, compressed=False):
                    self._start = start
                    self._end = end
                    self._prefix = prefix
                    self._content = content
                    self._suffix = suffix
                    self._is_compressed = compressed

                def start(self):
                    return self._start

                def end(self):
                    return self._end

                def group(self, n):
                    if n == 1:
                        return self._prefix
                    if n == 2:
                        return self._content
                    return ''

            json_match = RecordDataMatch(
                record_data_match.start(),
                record_data_match.end(),
                data_prefix,
                data_content,
                data_suffix,
                is_compressed,
            )
            # æ ‡è®°å‹ç¼©æ ¼å¼
            json_match._compression_format = compression_format

    # å¦‚æœæ²¡æ‰¾åˆ° record_dataï¼Œå°è¯•æŸ¥æ‰¾å…¶ä»– JSON æ•°æ®å—
    if not json_match:
        # æŸ¥æ‰¾åŒ…å« SymbolMap çš„ JSON å¯¹è±¡
        # å…ˆå°è¯•æŸ¥æ‰¾å†…è”çš„ JSON å¯¹è±¡ï¼ˆå¯èƒ½å¾ˆå¤§ï¼Œéœ€è¦æ‰¾åˆ°å®Œæ•´çš„å¯¹è±¡ï¼‰
        # æŸ¥æ‰¾ "SymbolMap" çš„ä½ç½®
        symbol_map_pos = html_content.find('"SymbolMap"')
        if symbol_map_pos != -1:
            # å‘å‰æŸ¥æ‰¾ JSON å¯¹è±¡çš„å¼€å§‹
            json_start = symbol_map_pos
            while json_start > 0 and html_content[json_start] != '{':
                json_start -= 1
                if json_start < symbol_map_pos - 1000000:  # æœ€å¤šå‘å‰æŸ¥æ‰¾1MB
                    break

            if json_start >= 0 and html_content[json_start] == '{':
                # æ‰¾åˆ° JSON å¯¹è±¡çš„å¼€å§‹ï¼Œç°åœ¨æ‰¾åˆ°ç»“æŸä½ç½®ï¼ˆä¼˜åŒ–ï¼šæ·»åŠ è¿›åº¦æç¤ºï¼‰
                brace_count = 0
                json_end = json_start
                max_search = min(len(html_content), json_start + 10000000)  # æœ€å¤š10MB
                logger.info(f'  æœç´¢ JSON å¯¹è±¡è¾¹ç•Œï¼ˆèŒƒå›´: {max_search - json_start} å­—èŠ‚ï¼‰...')

                for i in range(json_start, max_search):
                    if html_content[i] == '{':
                        brace_count += 1
                    elif html_content[i] == '}':
                        brace_count -= 1
                        if brace_count == 0:
                            json_end = i + 1
                            break

                    # æ¯å¤„ç† 1MB è¾“å‡ºä¸€æ¬¡è¿›åº¦
                    if (i - json_start) % 1000000 == 0 and i > json_start:
                        logger.info(f'    æœç´¢è¿›åº¦: {(i - json_start) / 1024 / 1024:.1f} MB')

                if brace_count != 0:
                    logger.info('  âš ï¸  è­¦å‘Š: æœªæ‰¾åˆ°å®Œæ•´çš„ JSON å¯¹è±¡è¾¹ç•Œ')
                    json_end = min(len(html_content), json_start + 10000000)

                if json_end > json_start:
                    # æ£€æŸ¥å‰é¢æ˜¯å¦æœ‰èµ‹å€¼è¯­å¥
                    prefix_start = max(0, json_start - 200)
                    prefix_text = html_content[prefix_start:json_start]

                    # æŸ¥æ‰¾èµ‹å€¼è¯­å¥
                    assign_match = re.search(
                        r'(window\.data\s*=\s*|(?:const|let|var)\s+json\s*=\s*)$',
                        prefix_text,
                        re.MULTILINE,
                    )
                    if assign_match:
                        # æ‰¾åˆ°èµ‹å€¼è¯­å¥ï¼Œåˆ›å»ºåŒ¹é…å¯¹è±¡
                        class InlineJsonMatch:
                            def __init__(self, start, end, prefix, content):
                                self._start = start
                                self._end = end
                                self._prefix = prefix
                                self._content = content

                            def start(self):
                                return self._start

                            def end(self):
                                return self._end

                            def group(self, n):
                                if n == 1:
                                    return self._prefix
                                if n == 2:
                                    return self._content
                                return ''

                        json_match = InlineJsonMatch(
                            json_start,
                            json_end,
                            html_content[prefix_start:json_start],
                            html_content[json_start:json_end],
                        )

        # å¦‚æœè¿˜æ²¡æ‰¾åˆ°ï¼Œå°è¯•å…¶ä»–æ ¼å¼
        if not json_match:
            json_patterns = [
                r'(window\.data\s*=\s*)(\{.*?"SymbolMap".*?\});',
                r'((?:const|let|var)\s+json\s*=\s*)(\{.*?"SymbolMap".*?\});',
            ]

            for pattern in json_patterns:
                match = re.search(pattern, html_content, re.DOTALL | re.IGNORECASE)
                if match:
                    json_match = match
                    break

    if json_match:
        logger.info('æ‰¾åˆ° JSON æ•°æ®å—ï¼Œåªå¤„ç†è¿™éƒ¨åˆ†...')

        # åˆ¤æ–­æ˜¯ SymbolMapMatch è¿˜æ˜¯å…¶ä»–ç±»å‹
        if hasattr(json_match, 'get_parts'):
            # SymbolMapMatch å¯¹è±¡ - åªå¤„ç† SymbolMap éƒ¨åˆ†
            (
                data_prefix,
                content_before,
                symbol_map_content,
                content_after,
                data_suffix,
            ) = json_match.get_parts()
            data_content_to_replace = symbol_map_content
            is_symbol_map_only = True
        elif hasattr(json_match, '_content'):
            # RecordDataMatch å¯¹è±¡
            data_prefix = json_match._prefix
            data_content_to_replace = json_match._content
            data_suffix = json_match._suffix
            content_before = ''
            content_after = ''
            is_symbol_map_only = False
        elif hasattr(json_match, 'group'):
            # æ­£åˆ™åŒ¹é…å¯¹è±¡
            data_prefix = json_match.group(1) if json_match.group(1) else ''
            data_content_to_replace = json_match.group(2)
            data_suffix = ''
            content_before = ''
            content_after = ''
            is_symbol_map_only = False
        else:
            data_prefix = ''
            data_content_to_replace = html_content[json_match.start() : json_match.end()]
            data_suffix = ''
            content_before = ''
            content_after = ''
            is_symbol_map_only = False

        # åªåœ¨è¿™ä¸ªæ•°æ®å—ä¸­è¿›è¡Œæ›¿æ¢ï¼ˆæ”¯æŒæ‰€æœ‰ .so æ–‡ä»¶ï¼‰
        so_addresses = function_mapping  # ä½¿ç”¨æ‰€æœ‰åœ°å€æ˜ å°„ï¼Œä¸å†åªè¿‡æ»¤ libxwebcore.so
        total_addresses = len(so_addresses)
        logger.info(f'  éœ€è¦å¤„ç† {total_addresses} ä¸ªåœ°å€æ˜ å°„')
        logger.info(f'  JSON æ•°æ®å—å¤§å°: {len(data_content_to_replace) / (1024 * 1024):.2f} MB')

        # ä¼˜åŒ–ï¼šå…ˆä½¿ç”¨æ–¹æ³•1æ‰¹é‡æ›¿æ¢ symbol å­—æ®µï¼Œè¿™æ˜¯æœ€å¸¸è§çš„æ ¼å¼
        logger.info('  æ­¥éª¤ 1/3: æ‰¹é‡æ›¿æ¢ symbol å­—æ®µ...')

        def replace_in_symbol_field(match):
            prefix = match.group(1)  # "symbol": " æˆ– "f": "
            symbol_value = match.group(2)  # ç¬¦å·å€¼

            # å¦‚æœå·²ç»æ›¿æ¢è¿‡ï¼Œè·³è¿‡
            if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in symbol_value:
                return match.group(0)

            # æå–åœ°å€éƒ¨åˆ†ï¼ˆå¯èƒ½æ˜¯å®Œæ•´è·¯å¾„æˆ–ç®€å•åœ°å€ï¼‰
            address = extract_address(symbol_value)
            if not address:
                return match.group(0)
            
            # åªè¿›è¡Œç²¾ç¡®åŒ¹é…ï¼ˆåœ°å€æ¥è‡ª perf é‡‡æ ·ï¼Œä¸åˆ†ææ—¶çš„åœ°å€ä¸€è‡´ï¼‰
            matched_function = None
            matched_address = None
            
            if address in so_addresses:
                matched_function = so_addresses[address]
                matched_address = address
            
            if matched_function and matched_address:
                replaced_count['count'] += 1
                if matched_address not in [r['original'] for r in replacement_info]:
                    replacement_info.append({'original': matched_address, 'replaced': matched_function})
                # åœ¨æ›¿æ¢åä¿ç•™åŸå§‹åœ°å€ï¼Œä¾¿äºè¿½æº¯
                return f'{prefix}{matched_function} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ] ({address})"'
            return match.group(0)

        # åŒ¹é… symbol å­—æ®µï¼ˆå®Œæ•´æ ¼å¼å’Œå‹ç¼©æ ¼å¼ï¼‰
        symbol_pattern = r'("(?:symbol|f)"\s*:\s*")([^"]*lib[\w_]+\.so\+0x[0-9a-fA-F]+[^"]*)"'
        data_content_to_replace = re.sub(
            symbol_pattern, replace_in_symbol_field, data_content_to_replace, flags=re.IGNORECASE
        )
        logger.info(f'  æ­¥éª¤ 1 å®Œæˆï¼Œå·²æ›¿æ¢ {replaced_count["count"]} ä¸ªç¬¦å·')

        # æ–¹æ³•2: æ›¿æ¢å®Œæ•´è·¯å¾„æ ¼å¼ï¼ˆä¼˜åŒ–ï¼šåªå¤„ç†æœªè¢«æ–¹æ³•1æ›¿æ¢çš„åœ°å€ï¼‰
        logger.info('  æ­¥éª¤ 2/3: æ›¿æ¢å®Œæ•´è·¯å¾„æ ¼å¼...')
        existing_replacements = {r['original'] for r in replacement_info}
        # è·å–å°šæœªæ›¿æ¢çš„åœ°å€
        remaining_addresses = {
            addr: func_name for addr, func_name in so_addresses.items()
            if addr not in existing_replacements
        }
        if remaining_addresses:
            logger.info(f'  å‰©ä½™ {len(remaining_addresses)} ä¸ªåœ°å€éœ€è¦å¤„ç†...')
            logger.info(
                f'  æ³¨æ„: ç”±äº JSON æ•°æ®å—è¾ƒå¤§ï¼ˆ{len(data_content_to_replace) / (1024 * 1024):.2f} MBï¼‰ï¼Œå¤„ç†å¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´...'
            )
            total_patterns = len(remaining_addresses) * 3  # æ¯ä¸ªåœ°å€3ä¸ªæ¨¡å¼
            pattern_count = 0

            for processed, (address, function_name) in enumerate(remaining_addresses.items(), 1):
                logger.info(f'    å¤„ç†åœ°å€ {processed}/{len(remaining_addresses)}: {address[:50]}...')

                # ä¼˜åŒ–ï¼šä½¿ç”¨æ›´ç®€å•çš„æ¨¡å¼ï¼Œé¿å…å¤æ‚çš„æ­£åˆ™
                # ç›´æ¥æ›¿æ¢åœ°å€å­—ç¬¦ä¸²ï¼ˆè½¬ä¹‰ç‰¹æ®Šå­—ç¬¦ï¼‰
                escaped_address = re.escape(address)

                # æ¨¡å¼1: å®Œæ•´è·¯å¾„æ ¼å¼
                pattern_count += 1
                logger.info(f'      æ¨¡å¼ 1/3: å®Œæ•´è·¯å¾„æ ¼å¼ ({pattern_count}/{total_patterns})...')
                pattern_full = rf'([^"]*/proc/[^"]*/)([^"]*libs/arm64/)({escaped_address})'

                def replace_full_path(m, fn=function_name, addr=address):
                    if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in m.group(0):
                        return m.group(0)
                    replaced_count['count'] += 1
                    # åœ¨æ›¿æ¢åä¿ç•™åŸå§‹åœ°å€ï¼Œä¾¿äºè¿½æº¯
                    return f'{m.group(1)}{m.group(2)}{fn} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ] ({addr})'

                data_content_to_replace = re.sub(pattern_full, replace_full_path, data_content_to_replace)

                # æ¨¡å¼2: ç®€å•æ ¼å¼ï¼ˆåœ¨å¼•å·å†…ï¼‰
                pattern_count += 1
                logger.info(f'      æ¨¡å¼ 2/3: ç®€å•æ ¼å¼ ({pattern_count}/{total_patterns})...')
                pattern_simple = rf'(")({escaped_address})(")'

                def replace_simple(m, fn=function_name, addr=address):
                    if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in m.group(0):
                        return m.group(0)
                    replaced_count['count'] += 1
                    # åœ¨æ›¿æ¢åä¿ç•™åŸå§‹åœ°å€ï¼Œä¾¿äºè¿½æº¯
                    return f'{m.group(1)}{fn} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ] ({addr}){m.group(3)}'

                data_content_to_replace = re.sub(pattern_simple, replace_simple, data_content_to_replace)

                # æ¨¡å¼3: symbol å­—æ®µä¸­çš„å®Œæ•´è·¯å¾„
                pattern_count += 1
                logger.info(f'      æ¨¡å¼ 3/3: symbol å­—æ®µ ({pattern_count}/{total_patterns})...')
                pattern_in_symbol = rf'("(?:symbol|f)"\s*:\s*")([^"]*{escaped_address}[^"]*)"'

                def replace_in_symbol_direct(m, fn=function_name, addr=address):
                    if '[åæ¨ï¼Œä»…ä¾›å‚è€ƒ]' in m.group(2):
                        return m.group(0)
                    replaced_count['count'] += 1
                    # åœ¨æ›¿æ¢åä¿ç•™åŸå§‹åœ°å€ï¼Œä¾¿äºè¿½æº¯
                    return f'{m.group(1)}{fn} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ] ({addr})"'

                data_content_to_replace = re.sub(pattern_in_symbol, replace_in_symbol_direct, data_content_to_replace)

                logger.info(f'    âœ… åœ°å€ {processed} å¤„ç†å®Œæˆï¼ˆå·²æ›¿æ¢ {replaced_count["count"]} ä¸ªç¬¦å·ï¼‰')

        logger.info(f'  æ­¥éª¤ 2 å®Œæˆï¼Œæ€»å…±æ›¿æ¢äº† {replaced_count["count"]} ä¸ªç¬¦å·')
        logger.info('  æ­¥éª¤ 3/3: å®Œæˆæ›¿æ¢')

        # å¦‚æœæ•°æ®è¢«å‹ç¼©ï¼Œéœ€è¦é‡æ–°å‹ç¼©å’Œç¼–ç 
        # æ£€æŸ¥ json_match æ˜¯å¦æœ‰ _is_compressed å±æ€§
        is_compressed_flag = getattr(json_match, '_is_compressed', False) if json_match else False
        compression_format = getattr(json_match, '_compression_format', 'gzip') if json_match else 'gzip'

        if is_compressed_flag:
            logger.info('  é‡æ–°å‹ç¼©å’Œç¼–ç æ•°æ®...')
            try:
                # å¦‚æœæ˜¯ SymbolMapMatchï¼Œéœ€è¦å‹ç¼©æ•´ä¸ª JSONï¼ˆåŒ…æ‹¬ content_before å’Œ content_afterï¼‰
                # å¦åˆ™åªå‹ç¼© data_content_to_replace
                if is_symbol_map_only:
                    # æ„å»ºå®Œæ•´çš„ JSON å†…å®¹ç”¨äºå‹ç¼©
                    full_json_content = content_before + data_content_to_replace + content_after
                    logger.info(
                        f'  å‹ç¼©å®Œæ•´ JSONï¼ˆåŒ…æ‹¬ SymbolMap å‰åå†…å®¹ï¼‰ï¼Œå¤§å°: {len(full_json_content) / 1024 / 1024:.2f} MB'
                    )
                else:
                    full_json_content = data_content_to_replace

                # æ ¹æ®åŸå§‹å‹ç¼©æ ¼å¼é€‰æ‹©å‹ç¼©æ–¹æ³•
                if compression_format == 'zlib':
                    logger.info('  ä½¿ç”¨ zlib å‹ç¼©...')
                    compressed = zlib.compress(full_json_content.encode('utf-8'))
                else:
                    logger.info('  ä½¿ç”¨ gzip å‹ç¼©...')
                    compressed = gzip.compress(full_json_content.encode('utf-8'))

                # Base64 ç¼–ç 
                encoded = base64.b64encode(compressed).decode('utf-8')

                # æ›´æ–° data_content_to_replace
                # å‹ç¼©åçš„æ•°æ®æ˜¯å®Œæ•´çš„ JSONï¼ˆå¯¹äº SymbolMapMatchï¼‰æˆ–éƒ¨åˆ† JSONï¼ˆå¯¹äºå…¶ä»–æ¨¡å¼ï¼‰
                data_content_to_replace = encoded

                logger.info(f'  âœ… é‡æ–°å‹ç¼©å’Œç¼–ç å®Œæˆï¼Œå¤§å°: {len(encoded) / 1024 / 1024:.2f} MB')
            except Exception:
                logger.exception('  âš ï¸  é‡æ–°å‹ç¼©å¤±è´¥ï¼Œä½¿ç”¨æœªå‹ç¼©çš„æ•°æ®')

        # æ›¿æ¢å›åŸæ–‡ä»¶
        start_pos = json_match.start() if hasattr(json_match, 'start') else 0
        end_pos = json_match.end() if hasattr(json_match, 'end') else len(html_content)

        if is_symbol_map_only:
            # SymbolMapMatch - åªæ›¿æ¢ SymbolMap éƒ¨åˆ†
            # å¦‚æœå‹ç¼©äº†ï¼Œdata_content_to_replace æ˜¯å‹ç¼©åçš„æ•´ä¸ª JSON
            if is_compressed_flag:
                # å‹ç¼©æ¨¡å¼ä¸‹ï¼Œdata_content_to_replace å·²ç»æ˜¯å‹ç¼©åçš„æ•´ä¸ª JSON
                # éœ€è¦æ›¿æ¢æ•´ä¸ª record_data å†…å®¹
                html_content = (
                    html_content[:start_pos]
                    + data_prefix
                    + data_content_to_replace
                    + data_suffix
                    + html_content[end_pos:]
                )
            else:
                # æœªå‹ç¼©æ¨¡å¼ï¼Œæ­£å¸¸æ›¿æ¢
                html_content = (
                    html_content[:start_pos]
                    + data_prefix
                    + content_before
                    + data_content_to_replace
                    + content_after
                    + data_suffix
                    + html_content[end_pos:]
                )
        elif hasattr(json_match, '_suffix'):
            # RecordDataMatch å¯¹è±¡ï¼Œéœ€è¦åŒ…å« suffix
            html_content = (
                html_content[:start_pos] + data_prefix + data_content_to_replace + data_suffix + html_content[end_pos:]
            )
        else:
            html_content = html_content[:start_pos] + data_prefix + data_content_to_replace + html_content[end_pos:]
    else:
        # å¦‚æœæ‰¾ä¸åˆ° window.dataï¼Œå›é€€åˆ°å…¨æ–‡ä»¶æ›¿æ¢ï¼ˆä½†åªæ›¿æ¢ symbol å­—æ®µï¼‰
        logger.info('æœªæ‰¾åˆ° window.dataï¼Œä½¿ç”¨å…¨æ–‡ä»¶æ›¿æ¢æ¨¡å¼...')
        so_addresses = function_mapping  # ä½¿ç”¨æ‰€æœ‰åœ°å€æ˜ å°„ï¼Œä¸å†åªè¿‡æ»¤ libxwebcore.so

        def replace_in_symbol_field(match):
            prefix = match.group(1)
            symbol_value = match.group(2)
            address = extract_address(symbol_value)
            if address and address in so_addresses:
                function_name = so_addresses[address]
                replaced_count['count'] += 1
                if address not in [r['original'] for r in replacement_info]:
                    replacement_info.append({'original': address, 'replaced': function_name})
                # åœ¨æ›¿æ¢åä¿ç•™åŸå§‹åœ°å€ï¼Œä¾¿äºè¿½æº¯
                return f'{prefix}{function_name} [åæ¨ï¼Œä»…ä¾›å‚è€ƒ] ({address})"'
            return match.group(0)

        # åŒ¹é… symbol å­—æ®µï¼ˆå®Œæ•´æ ¼å¼å’Œå‹ç¼©æ ¼å¼ "f"ï¼Œæ”¯æŒä»»ä½• .so æ–‡ä»¶ï¼ŒåŒ…æ‹¬ä¸‹åˆ’çº¿ï¼‰
        symbol_pattern = r'("(?:symbol|f)"\s*:\s*")([^"]*lib[\w_]+\.so\+0x[0-9a-fA-F]+[^"]*)"'
        html_content = re.sub(symbol_pattern, replace_in_symbol_field, html_content, flags=re.IGNORECASE)

    logger.info(f'âœ… æ›¿æ¢äº† {replaced_count["count"]} ä¸ªç¼ºå¤±ç¬¦å·')
    return html_content, replacement_info


def extract_html_body_content(html_file_path: Path) -> str:
    """ä» HTML æ–‡ä»¶ä¸­æå– body å†…å®¹ï¼ˆä¸åŒ…æ‹¬ body æ ‡ç­¾æœ¬èº«ï¼‰"""
    try:
        with open(html_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # æå– <body> æ ‡ç­¾å†…çš„å†…å®¹
        body_match = re.search(r'<body[^>]*>(.*?)</body>', content, re.DOTALL | re.IGNORECASE)
        if body_match:
            return body_match.group(1).strip()
        
        # å¦‚æœæ²¡æœ‰ body æ ‡ç­¾ï¼Œå°è¯•æå–æ•´ä¸ªæ–‡æ¡£å†…å®¹ï¼ˆé™¤äº† html/head æ ‡ç­¾ï¼‰
        html_match = re.search(r'</head>(.*?)</html>', content, re.DOTALL | re.IGNORECASE)
        if html_match:
            return html_match.group(1).strip()
        
        # å¦‚æœéƒ½æ²¡æœ‰ï¼Œè¿”å›ç©ºå­—ç¬¦ä¸²
        return ''
    except Exception as e:
        logger.warning(f'æ— æ³•è¯»å– HTML æŠ¥å‘Šæ–‡ä»¶ {html_file_path}: {e}')
        return ''


def add_disclaimer(html_content, reference_report_file=None, relative_path=None, 
                   html_report_file=None, excel_file=None, report_data=None, llm_analyzer=None):
    """åœ¨ HTML ä¸­æ·»åŠ å…è´£å£°æ˜ã€å‚è€ƒé“¾æ¥å’ŒåµŒå…¥çš„æŠ¥å‘Š

    Args:
        html_content: HTML å†…å®¹
        reference_report_file: æŠ€æœ¯å‚è€ƒæŠ¥å‘Šæ–‡ä»¶åï¼ˆå¦‚ event_count_top33_report.htmlï¼‰ï¼Œ
                               å¦‚æœä¸º Noneï¼Œåˆ™è‡ªåŠ¨æŸ¥æ‰¾
        relative_path: ä» HTML æ–‡ä»¶åˆ°è¾“å‡ºç›®å½•çš„ç›¸å¯¹è·¯å¾„
                      å¦‚æœä¸º Noneï¼Œåˆ™è‡ªåŠ¨è®¡ç®—æˆ–ä½¿ç”¨é»˜è®¤è·¯å¾„
        html_report_file: HTML æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™åµŒå…¥æŠ¥å‘Šå†…å®¹ï¼‰
        excel_file: Excel æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™æ·»åŠ ä¸‹è½½é“¾æ¥ï¼‰
    """
    # è·å–è¾“å‡ºç›®å½•
    output_dir = config.get_output_dir()
    config.ensure_output_dir(output_dir)

    # ç¡®å®šç›¸å¯¹è·¯å¾„
    if relative_path is None:
        # é»˜è®¤ç›¸å¯¹è·¯å¾„
        relative_path = f'../{output_dir.name}'
    elif relative_path == '.':
        # å½“å‰ç›®å½•ï¼Œä¸éœ€è¦å‰ç¼€
        relative_path = ''

    # ç¡®å®šå‚è€ƒæŠ¥å‘Šæ–‡ä»¶
    if reference_report_file:
        reference_link = f'{relative_path}/{reference_report_file}' if relative_path else reference_report_file
    # è‡ªåŠ¨æŸ¥æ‰¾æœ€æ–°çš„æŠ¥å‘Šæ–‡ä»¶
    elif output_dir.exists():
        # æŸ¥æ‰¾æ‰€æœ‰æŠ¥å‘Šæ–‡ä»¶ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´æ’åº
        report_files = list(output_dir.glob('*_report.html'))
        if report_files:
            # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œå–æœ€æ–°çš„
            report_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            reference_link = f'{relative_path}/{report_files[0].name}' if relative_path else report_files[0].name
        # å¦‚æœæ²¡æœ‰æ‰¾åˆ°ï¼Œä½¿ç”¨é»˜è®¤åç§°
        elif relative_path:
            reference_link = f'{relative_path}/{config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)}'
        else:
            reference_link = config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)
    elif relative_path:
        reference_link = f'{relative_path}/{config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)}'
    else:
        reference_link = config.EVENT_COUNT_REPORT_PATTERN.format(n=config.DEFAULT_TOP_N)

    # æ„å»º Excel ä¸‹è½½é“¾æ¥
    excel_link = ''
    if excel_file:
        excel_path = Path(excel_file)
        if excel_path.exists():
            excel_link_path = f'{relative_path}/{excel_path.name}' if relative_path else excel_path.name
            excel_link = f'''
        <strong>ğŸ“Š Excel æŠ¥å‘Š:</strong><br>
        <a href="{excel_link_path}" download
           style="color: #1976d2; text-decoration: underline; font-weight: bold;">
           ä¸‹è½½ Excel åˆ†ææŠ¥å‘Š
        </a><br><br>'''

    # ä¸å†æ˜¾ç¤ºå…è´£å£°æ˜æ¡†
    disclaimer = ""

    # ç”ŸæˆæŠ¥å‘Šå†…å®¹ï¼ˆä¼˜å…ˆä½¿ç”¨ report_dataï¼Œå¦åˆ™ä»æ–‡ä»¶è¯»å–ï¼‰
    report_body_content = ''
    if report_data:
        # ç›´æ¥ä»æ•°æ®ç”ŸæˆæŠ¥å‘Šå†…å®¹
        full_html = util.render_html_report(
            report_data,
            llm_analyzer=llm_analyzer,
            time_tracker=None,
            title='ç¼ºå¤±ç¬¦å·å‡½æ•°åˆ†ææŠ¥å‘Š',
        )
        # æå– body å†…å®¹
        body_match = re.search(r'<body[^>]*>(.*?)</body>', full_html, re.DOTALL | re.IGNORECASE)
        if body_match:
            report_body_content = body_match.group(1).strip()
    elif html_report_file:
        html_report_path = Path(html_report_file)
        if html_report_path.exists():
            report_body_content = extract_html_body_content(html_report_path)
    
    # åµŒå…¥ HTML æŠ¥å‘Šå†…å®¹ï¼ˆå¦‚æœæä¾›ï¼‰
    embedded_report = ''
    if report_body_content:
        # è½¬ä¹‰ JavaScript å­—ç¬¦ä¸²ä¸­çš„ç‰¹æ®Šå­—ç¬¦
        report_body_content_escaped = json.dumps(report_body_content)
        
        embedded_report = f"""
    <!-- æ·»åŠ æ–°çš„ tab æ¥æ˜¾ç¤ºè¯¦ç»†åˆ†ææŠ¥å‘Š -->
    <script>
        (function() {{
            function addReportTab() {{
                // æŸ¥æ‰¾ lit-tabs å…ƒç´ 
                var tabs = document.querySelector('lit-tabs');
                if (!tabs) {{
                    // å¦‚æœæ‰¾ä¸åˆ°ï¼Œå»¶è¿Ÿé‡è¯•
                    setTimeout(addReportTab, 500);
                    return;
                }}
                
                // æ£€æŸ¥æ˜¯å¦å·²ç»æ·»åŠ è¿‡
                var existingPane = tabs.querySelector('lit-tabpane[key="5"]');
                if (existingPane) {{
                    return;
                }}
                
                // åˆ›å»ºæ–°çš„ tabpane
                var newPane = document.createElement('lit-tabpane');
                newPane.setAttribute('id', 'pane5');
                newPane.setAttribute('tab', 'è¯¦ç»†åˆ†ææŠ¥å‘Š');
                newPane.setAttribute('key', '5');
                
                // å°†æŠ¥å‘Šå†…å®¹æ·»åŠ åˆ° tabpane ä¸­
                var reportContent = {report_body_content_escaped};
                
                // åˆ›å»ºå®¹å™¨å¹¶æ·»åŠ æ ·å¼
                var container = document.createElement('div');
                container.style.cssText = 'padding: 20px; background: white; min-height: 100vh;';
                
                // åˆ›å»ºæ ·å¼å…ƒç´ 
                var styleElement = document.createElement('style');
                styleElement.textContent = '.container {{ max-width: 100%; margin: 0; background: white; padding: 20px; box-sizing: border-box; }} ' +
                    'h1 {{ color: #333; border-bottom: 3px solid #4CAF50; padding-bottom: 10px; margin-top: 0; }} ' +
                    'table {{ width: 100%; border-collapse: collapse; margin-top: 20px; table-layout: auto; }} ' +
                    'th {{ background-color: #4CAF50; color: white; padding: 12px 8px; text-align: left; position: sticky; top: 0; white-space: nowrap; font-size: 13px; }} ' +
                    'td {{ padding: 10px 8px; border-bottom: 1px solid #ddd; vertical-align: top; font-size: 13px; word-wrap: break-word; }} ' +
                    'tr:hover {{ background-color: #f5f5f5; }} ' +
                    '.rank {{ font-weight: bold; color: #4CAF50; text-align: center; width: 50px; }} ' +
                    '.address {{ font-family: "Courier New", monospace; font-size: 0.85em; white-space: nowrap; max-width: 200px; overflow: hidden; text-overflow: ellipsis; }} ' +
                    '.call-count {{ text-align: right; font-weight: bold; white-space: nowrap; }} ' +
                    '.confidence-high {{ color: #4CAF50; font-weight: bold; }} ' +
                    '.confidence-medium {{ color: #FF9800; font-weight: bold; }} ' +
                    '.confidence-low {{ color: #f44336; }} ' +
                    '.functionality {{ max-width: 400px; word-wrap: break-word; line-height: 1.4; }} ' +
                    '.strings {{ font-family: "Courier New", monospace; font-size: 0.85em; max-width: 300px; word-wrap: break-word; line-height: 1.4; }} ' +
                    '.section {{ margin-top: 40px; padding: 20px; background-color: #f9f9f9; border-radius: 5px; border-left: 4px solid #4CAF50; }} ' +
                    '.section h2 {{ color: #333; margin-top: 0; border-bottom: 2px solid #4CAF50; padding-bottom: 10px; }} ' +
                    '.token-stats {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(200px, 1fr)); gap: 15px; margin-top: 15px; }} ' +
                    '.token-stat-item {{ background: white; padding: 15px; border-radius: 5px; border: 1px solid #ddd; }} ' +
                    '.token-stat-label {{ font-size: 0.9em; color: #666; margin-bottom: 5px; }} ' +
                    '.token-stat-value {{ font-size: 1.5em; font-weight: bold; color: #4CAF50; }} ' +
                    'td:nth-child(2) {{ max-width: 250px; }} ' +
                    'td:nth-child(9) {{ max-width: 350px; }} ' +
                    'td:nth-child(10) {{ max-width: 400px; }}';
                container.appendChild(styleElement);
                
                // æ’å…¥æŠ¥å‘Šå†…å®¹
                container.innerHTML += reportContent;
                newPane.appendChild(container);
                
                // æ·»åŠ åˆ° tabs ä¸­
                tabs.appendChild(newPane);
            }}
            
            // é¡µé¢åŠ è½½åæ‰§è¡Œ
            if (document.readyState === 'loading') {{
                document.addEventListener('DOMContentLoaded', addReportTab);
            }} else {{
                addReportTab();
            }}
            
            // å»¶è¿Ÿæ‰§è¡Œï¼Œç¡®ä¿æ‰€æœ‰å†…å®¹éƒ½å·²åŠ è½½
            setTimeout(addReportTab, 500);
            setTimeout(addReportTab, 1000);
        }})();
    </script>
    """

    # æ’å…¥æ ·å¼å’Œè„šæœ¬ï¼ˆåœ¨ head æˆ– body å¼€å§‹å¤„ï¼‰
    layout_style_script = ''
    if embedded_report:
        # æå–æ ·å¼å’Œè„šæœ¬éƒ¨åˆ†
        style_match = re.search(r'<style>(.*?)</style>', embedded_report, re.DOTALL)
        script_match = re.search(r'<script>(.*?)</script>', embedded_report, re.DOTALL)
        
        if style_match:
            layout_style_script += f'<style>{style_match.group(1)}</style>'
        if script_match:
            layout_style_script += f'<script>{script_match.group(1)}</script>'
    
    # æ’å…¥å¸ƒå±€æ ·å¼å’Œè„šæœ¬åˆ° head æˆ– body å¼€å§‹å¤„
    if layout_style_script:
        if '</head>' in html_content:
            html_content = html_content.replace('</head>', layout_style_script + '</head>')
        elif '<body' in html_content:
            body_match = re.search(r'(<body[^>]*>)', html_content, re.IGNORECASE)
            if body_match:
                html_content = html_content.replace(body_match.group(1), body_match.group(1) + layout_style_script)
    
    # æå–æŠ¥å‘Šå®¹å™¨éƒ¨åˆ†ï¼ˆä¸åŒ…å«æ ·å¼å’Œè„šæœ¬ï¼‰
    report_container = ''
    if embedded_report:
        container_match = re.search(r'(<div id="embedded-report-container".*?</div>)', embedded_report, re.DOTALL)
        if container_match:
            report_container = container_match.group(1)
    
    # åœ¨ </body> æ ‡ç­¾å‰æ’å…¥å£°æ˜å’ŒæŠ¥å‘Šå®¹å™¨
    insertion_content = disclaimer + report_container
    if '</body>' in html_content:
        html_content = html_content.replace('</body>', insertion_content + '</body>')
    elif '</html>' in html_content:
        html_content = html_content.replace('</html>', insertion_content + '</html>')
    else:
        # å¦‚æœæ²¡æœ‰ body æˆ– html æ ‡ç­¾ï¼Œåœ¨æœ«å°¾æ·»åŠ 
        html_content += insertion_content

    return html_content
