#!/usr/bin/env python3
"""
ä»perf.data æˆ– excel æ–‡ä»¶è¯»å–ç¼ºå¤±ç¬¦å·çš„å‡½æ•°ï¼Œè¿›è¡Œåæ±‡ç¼–å’ŒLLMåˆ†æ
"""

import os
import shutil
import sqlite3
from collections import defaultdict
from pathlib import Path
from typing import Optional

import pandas as pd
from elftools.elf.elffile import ELFFile

try:
    from openpyxl import Workbook
    from openpyxl.styles import Alignment
    from openpyxl.utils import get_column_letter
except ImportError:  # pragma: no cover - optional dependency
    Workbook = None
    Alignment = None
    get_column_letter = None

try:
    from core.llm.batch_analyzer import BatchLLMFunctionAnalyzer
except ImportError:  # pragma: no cover - optional dependency
    BatchLLMFunctionAnalyzer = None
from core.llm.initializer import init_llm_analyzer
from core.utils import StringExtractor, config, get_logger
from core.utils import common as util

logger = get_logger(__name__)

try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    logger.warning('æœªå®‰è£… python-dotenv åº“ï¼Œå°†è·³è¿‡ .env æ–‡ä»¶çš„åŠ è½½')
    logger.warning('è¯·å®‰è£… python-dotenv åº“: pip install python-dotenv')
except Exception as e:
    logger.error('åŠ è½½ .env æ–‡ä»¶æ—¶å‡ºé”™: %s', e)
    raise

try:
    import r2pipe

    from core.analyzers.r2_analyzer import R2FunctionAnalyzer

    R2_AVAILABLE = True
except ImportError:
    R2_AVAILABLE = False
    R2FunctionAnalyzer = None
    r2pipe = None
    logger.warning('r2_function_analyzer æ¨¡å—ä¸å¯ç”¨,å°†ä½¿ç”¨capstoneè¿›è¡Œåæ±‡ç¼–å’ŒLLMåˆ†æ')


def _check_r2_actually_available():
    """
    æ£€æµ‹ radare2 æ˜¯å¦çœŸçš„å¯ç”¨ï¼ˆä¸ä»…ä»…æ˜¯æ¨¡å—æ˜¯å¦å¯å¯¼å…¥ï¼‰
    é€šè¿‡æ£€æŸ¥ r2 å‘½ä»¤æ˜¯å¦åœ¨ PATH ä¸­æ¥åˆ¤æ–­

    Returns:
        bool: å¦‚æœ radare2 å¯ç”¨è¿”å› Trueï¼Œå¦åˆ™è¿”å› False
    """
    if not R2_AVAILABLE:
        return False

    try:
        # æ£€æŸ¥ r2 å‘½ä»¤æ˜¯å¦åœ¨ PATH ä¸­
        r2_path = shutil.which('r2')
        if r2_path:
            logger.debug(f'æ‰¾åˆ° radare2 å‘½ä»¤: {r2_path}')
            return True

        # å¦‚æœæ‰¾ä¸åˆ° r2 å‘½ä»¤ï¼Œè¯´æ˜ radare2 ä¸å¯ç”¨
        logger.debug('æœªæ‰¾åˆ° radare2 å‘½ä»¤ï¼ˆr2 ä¸åœ¨ PATH ä¸­ï¼‰')
        return False
    except Exception as e:
        logger.debug(f'æ£€æµ‹ radare2 å¯ç”¨æ€§æ—¶å‡ºé”™: {e}')
        return False


class MissingSymbolFunctionAnalyzer:
    """åˆ†æç¼ºå¤±ç¬¦å·çš„å‡½æ•°"""

    def __init__(
        self,
        excel_file=None,
        so_dir=None,
        perf_db_file=None,
        use_llm=True,
        llm_model=None,
        use_batch_llm=True,
        batch_size=None,
        context=None,
        use_capstone_only=False,
        save_prompts=False,
        output_dir=None,
        skip_decompilation=False,
    ):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            excel_file: ç¼ºå¤±ç¬¦å·åˆ†æ Excel æ–‡ä»¶ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾› perf_db_file åˆ™ä¸éœ€è¦ï¼‰
            so_dir: SO æ–‡ä»¶ç›®å½•
            perf_db_file: perf.db æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ç›´æ¥ä»æ•°æ®åº“è¯»å–ï¼Œä¸éœ€è¦ Excelï¼‰
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM åˆ†æ
            llm_model: LLM æ¨¡å‹åç§°
            use_batch_llm: æ˜¯å¦ä½¿ç”¨æ‰¹é‡ LLM åˆ†æï¼ˆä¸€ä¸ª prompt åŒ…å«å¤šä¸ªå‡½æ•°ï¼Œé»˜è®¤ Trueï¼‰
            batch_size: æ‰¹é‡åˆ†ææ—¶æ¯ä¸ª prompt åŒ…å«çš„å‡½æ•°æ•°é‡ï¼ˆé»˜è®¤ 3ï¼‰
            context: è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™æ ¹æ® SO æ–‡ä»¶åè‡ªåŠ¨æ¨æ–­ï¼‰
            use_capstone_only: åªä½¿ç”¨ Capstone åæ±‡ç¼–ï¼ˆä¸ä½¿ç”¨ Radare2ï¼Œå³ä½¿å·²å®‰è£…ï¼‰
            save_prompts: æ˜¯å¦ä¿å­˜ç”Ÿæˆçš„ prompt åˆ°æ–‡ä»¶
            output_dir: è¾“å‡ºç›®å½•ï¼Œç”¨äºä¿å­˜ prompt æ–‡ä»¶
            skip_decompilation: æ˜¯å¦è·³è¿‡åç¼–è¯‘ï¼ˆé»˜è®¤ Falseï¼Œå¯ç”¨åç¼–è¯‘å¯æé«˜ LLM åˆ†æè´¨é‡ä½†è¾ƒæ…¢ï¼‰
        """
        self.excel_file = Path(excel_file) if excel_file else None
        self.perf_db_file = Path(perf_db_file) if perf_db_file else None
        self.so_dir = Path(so_dir) if so_dir else None
        self.use_llm = use_llm
        self.llm_model = llm_model if llm_model is not None else config.DEFAULT_LLM_MODEL
        self.use_batch_llm = use_batch_llm
        self.batch_size = batch_size if batch_size is not None else config.DEFAULT_BATCH_SIZE
        self.context = context  # è‡ªå®šä¹‰ä¸Šä¸‹æ–‡
        self.use_capstone_only = use_capstone_only  # å¼ºåˆ¶ä½¿ç”¨ Capstone
        self.skip_decompilation = skip_decompilation  # æ˜¯å¦è·³è¿‡åç¼–è¯‘
        self._r2_actually_available = None  # ç¼“å­˜ radare2 å®é™…å¯ç”¨æ€§ï¼ˆå»¶è¿Ÿæ£€æµ‹ï¼‰

        # éªŒè¯è¾“å…¥ï¼šå¿…é¡»æä¾› excel_file æˆ– perf_db_file ä¹‹ä¸€
        if not self.excel_file and not self.perf_db_file:
            raise ValueError('å¿…é¡»æä¾› excel_file æˆ– perf_db_file ä¹‹ä¸€')

        if self.excel_file and not self.excel_file.exists():
            raise FileNotFoundError(f'Excel æ–‡ä»¶ä¸å­˜åœ¨: {excel_file}')

        if self.perf_db_file and not self.perf_db_file.exists():
            raise FileNotFoundError(f'perf.db æ–‡ä»¶ä¸å­˜åœ¨: {perf_db_file}')

        if self.so_dir and not self.so_dir.exists():
            raise FileNotFoundError(f'SO æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {so_dir}')

        # åˆå§‹åŒ–åæ±‡ç¼–å™¨
        self.md = util.create_disassembler()

        # åˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆç¨åè®¾ç½® disassemble_funcï¼‰
        self.string_extractor = None

        # ç¼“å­˜ radare2 åˆ†æå™¨å®ä¾‹ï¼ˆæŒ‰ SO æ–‡ä»¶è·¯å¾„ç¼“å­˜ï¼Œé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
        self._r2_analyzers = {}  # {so_file_path: R2FunctionAnalyzer}

        # åˆå§‹åŒ– LLM åˆ†æå™¨ï¼ˆä½¿ç”¨å…¬å…±å·¥å…·å‡½æ•°ï¼Œé¿å…é‡å¤ä»£ç ï¼‰
        self.llm_analyzer, self.use_llm, self.use_batch_llm = init_llm_analyzer(
            use_llm=self.use_llm,
            llm_model=self.llm_model,
            use_batch_llm=self.use_batch_llm,
            batch_size=self.batch_size,
            logger=logger.info,
            save_prompts=save_prompts,
            output_dir=output_dir,
        )

    def find_so_file(self, file_path):
        """
        æ ¹æ®æ–‡ä»¶è·¯å¾„æ‰¾åˆ°å¯¹åº”çš„ SO æ–‡ä»¶

        Args:
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚ /proc/.../libxwebcore.soï¼‰

        Returns:
            SO æ–‡ä»¶è·¯å¾„ï¼Œå¦‚æœæ‰¾ä¸åˆ°è¿”å› None
        """
        # æå–æ–‡ä»¶åï¼ˆå¦‚ libxwebcore.soï¼‰
        so_name = None
        so_name = file_path.split('/')[-1] if '/' in file_path else file_path

        # åœ¨æŒ‡å®šç›®å½•ä¸­æŸ¥æ‰¾
        so_file = self.so_dir / so_name
        if so_file.exists():
            # è¿”å›ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„ä¸€è‡´æ€§ï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
            return so_file.resolve()

        # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå°è¯•æŸ¥æ‰¾æ‰€æœ‰ SO æ–‡ä»¶
        for so_file in self.so_dir.glob('*.so'):
            if so_file.name == so_name:
                # è¿”å›ç»å¯¹è·¯å¾„ï¼Œç¡®ä¿è·¯å¾„ä¸€è‡´æ€§ï¼ˆç”¨äºç¼“å­˜é”®ï¼‰
                return so_file.resolve()

        return None

    def extract_offset_from_address(self, address):
        """
        ä»åœ°å€å­—ç¬¦ä¸²ä¸­æå–åç§»é‡ï¼ˆè™šæ‹Ÿåœ°å€ï¼‰
        ä½¿ç”¨ç»Ÿä¸€çš„ parse_offset å‡½æ•°
        """
        return util.parse_offset(address)

    def vaddr_to_file_offset(self, elf_file, vaddr):
        """å°†è™šæ‹Ÿåœ°å€è½¬æ¢ä¸ºæ–‡ä»¶åç§»é‡"""
        for segment in elf_file.iter_segments():
            if segment['p_type'] == 'PT_LOAD':
                vaddr_start = segment['p_vaddr']
                vaddr_end = vaddr_start + segment['p_memsz']
                if vaddr_start <= vaddr < vaddr_end:
                    return segment['p_offset'] + (vaddr - vaddr_start)
        return None

    def find_function_start(self, elf_file, vaddr):
        """æŸ¥æ‰¾å‡½æ•°çš„èµ·å§‹ä½ç½®ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„ util.find_function_startï¼‰"""
        return util.find_function_start(elf_file, vaddr, self.md)

    def disassemble_function(self, elf_file, vaddr, size=2000):
        """åæ±‡ç¼–æŒ‡å®šè™šæ‹Ÿåœ°å€çš„å‡½æ•°ä»£ç 

        Args:
            elf_file: ELF æ–‡ä»¶å¯¹è±¡
            vaddr: å‡½æ•°è™šæ‹Ÿåœ°å€
            size: æœ€å¤§åæ±‡ç¼–å¤§å°ï¼ˆé»˜è®¤ 2000 å­—èŠ‚ï¼Œå¢åŠ ä»¥æ”¯æŒå¤§å‹å‡½æ•°ï¼‰
        """
        try:
            # è·å– .text æ®µ
            text_section = None
            for section in elf_file.iter_sections():
                if section.name == '.text':
                    text_section = section
                    break

            if not text_section:
                return None

            text_vaddr = text_section['sh_addr']
            text_size = text_section['sh_size']

            # ç¡®ä¿åœ°å€åœ¨ .text æ®µå†…
            if vaddr < text_vaddr or vaddr >= text_vaddr + text_size:
                logger.warning('âš ï¸  åœ°å€ 0x%s ä¸åœ¨ .text æ®µå†…', f'{vaddr:x}')
                return None

            # æŸ¥æ‰¾å‡½æ•°èµ·å§‹ä½ç½®
            func_start = self.find_function_start(elf_file, vaddr)

            # å°è¯•ä»ç¬¦å·è¡¨è·å–å‡½æ•°å¤§å°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            func_size = None
            try:
                # æŸ¥æ‰¾ .dynsym æˆ– .symtab ç¬¦å·è¡¨
                for section_name in ['.dynsym', '.symtab']:
                    symbol_table = elf_file.get_section_by_name(section_name)
                    if symbol_table:
                        for symbol in symbol_table.iter_symbols():
                            if symbol['st_info']['type'] == 'STT_FUNC':
                                sym_addr = symbol['st_value']
                                sym_size = symbol['st_size']
                                # æ£€æŸ¥åœ°å€æ˜¯å¦åœ¨è¿™ä¸ªç¬¦å·èŒƒå›´å†…
                                if sym_size > 0 and sym_addr <= vaddr < sym_addr + sym_size:
                                    func_size = sym_size
                                    logger.info(f'ä»ç¬¦å·è¡¨è·å–å‡½æ•°å¤§å°: {func_size} å­—èŠ‚ (ç¬¦å·: {symbol.name})')
                                    break
                    if func_size:
                        break
            except Exception:
                # ç¬¦å·è¡¨æŸ¥æ‰¾å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¤§å°
                pass

            # è®¡ç®—ç›¸å¯¹åç§»é‡
            relative_start = func_start - text_vaddr
            if func_size:
                # ä½¿ç”¨ç¬¦å·è¡¨ä¸­çš„å‡½æ•°å¤§å°ï¼Œä½†ä¸è¶…è¿‡ size é™åˆ¶
                relative_end = min(relative_start + func_size, relative_start + size, text_size)
            else:
                relative_end = min(relative_start + size, text_size)

            # è¯»å–ä»£ç 
            code = text_section.data()[relative_start:relative_end]

            if not code:
                return None

            # åæ±‡ç¼–
            instructions = []
            ret_count = 0  # è®°å½•é‡åˆ°çš„ ret æŒ‡ä»¤æ•°é‡
            consecutive_ret = 0  # è¿ç»­ ret æŒ‡ä»¤è®¡æ•°

            for inst in self.md.disasm(code, func_start):
                instructions.append(inst)

                # æ”¹è¿›çš„åœæ­¢æ¡ä»¶ï¼š
                # 1. å¦‚æœé‡åˆ° ret æŒ‡ä»¤ï¼Œè®°å½•ä½†ä¸ç«‹å³åœæ­¢
                # 2. å¦‚æœè¿ç»­é‡åˆ°å¤šä¸ª retï¼ˆå¯èƒ½æ˜¯å‡½æ•°ç»“æŸæ ‡è®°ï¼‰ï¼Œä¸”å·²åæ±‡ç¼–è¶³å¤ŸæŒ‡ä»¤ï¼Œåˆ™åœæ­¢
                # 3. å¦‚æœé‡åˆ° ret ä¸”å·²ç»åæ±‡ç¼–äº†å¤§éƒ¨åˆ†å‡½æ•°ï¼ˆè¶…è¿‡ 80%ï¼‰ï¼Œåˆ™åœæ­¢
                if inst.mnemonic == 'ret':
                    ret_count += 1
                    consecutive_ret += 1
                    # å¦‚æœè¿ç»­é‡åˆ° 2 ä¸ª retï¼Œä¸”å·²åæ±‡ç¼–è¶…è¿‡ 300 æ¡æŒ‡ä»¤ï¼ˆçº¦ 1200 å­—èŠ‚ï¼‰ï¼Œå¯èƒ½æ˜¯å‡½æ•°ç»“æŸ
                    # æ³¨æ„ï¼šARM64 æŒ‡ä»¤é€šå¸¸æ˜¯ 4 å­—èŠ‚ï¼Œ300 æ¡æŒ‡ä»¤ â‰ˆ 1200 å­—èŠ‚
                    # è¿™ä¸ªé˜ˆå€¼é€‚ç”¨äºå¤§å¤šæ•°å‡½æ•°ï¼Œä½†å¤æ‚å‡½æ•°å¯èƒ½è¶…è¿‡è¿™ä¸ªå€¼
                    if consecutive_ret >= 2 and len(instructions) > 300:
                        break
                    # å¦‚æœé‡åˆ° ret ä¸”å·²åæ±‡ç¼–è¶…è¿‡ size çš„ 80%ï¼Œå¯èƒ½æ˜¯å‡½æ•°ç»“æŸ
                    if len(instructions) * 4 > (relative_end - relative_start) * 0.8:
                        break
                else:
                    consecutive_ret = 0  # é‡ç½®è¿ç»­ ret è®¡æ•°

                # å¦‚æœå·²ç»åæ±‡ç¼–äº†è¶³å¤Ÿå¤šçš„æŒ‡ä»¤ï¼ˆè¶…è¿‡ size é™åˆ¶ï¼‰ï¼Œåœæ­¢
                if len(instructions) * 4 > (relative_end - relative_start):
                    break

            return instructions
        except Exception:
            logger.exception('åæ±‡ç¼–å¤±è´¥ (vaddr=0x%x)', vaddr)
            return None

    def _init_string_extractor(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆéœ€è¦å…ˆå®šä¹‰ disassemble_functionï¼‰"""
        if self.string_extractor is None:
            self.string_extractor = StringExtractor(disassemble_func=self.disassemble_function, md=self.md)

    def _build_context(self, so_file, file_path=None):
        """
        æ„å»º LLM åˆ†æçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆæ ¹æ® SO æ–‡ä»¶åå’Œåº”ç”¨è·¯å¾„è‡ªåŠ¨æ¨æ–­ï¼‰

        Args:
            so_file: SO æ–‡ä»¶è·¯å¾„
            file_path: æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œç”¨äºæ¨æ–­åº”ç”¨ç±»å‹ï¼‰

        Returns:
            ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²
        """
        so_name = Path(so_file).name.lower()
        so_file_name = Path(so_file).name

        # ä»æ–‡ä»¶è·¯å¾„æ¨æ–­åº”ç”¨ç±»å‹
        app_name = None
        if file_path:
            file_path_lower = file_path.lower()
            if 'taobao' in file_path_lower or 'com.taobao' in file_path_lower:
                app_name = 'æ·˜å®ï¼ˆTaobaoï¼‰'
            elif 'wechat' in file_path_lower or 'com.tencent.wechat' in file_path_lower:
                app_name = 'å¾®ä¿¡ï¼ˆWeChatï¼‰'
            elif 'alipay' in file_path_lower or 'com.alipay' in file_path_lower:
                app_name = 'æ”¯ä»˜å®ï¼ˆAlipayï¼‰'
            elif 'qq' in file_path_lower and 'com.tencent' in file_path_lower:
                app_name = 'QQ'
            elif 'douyin' in file_path_lower or 'com.ss.android' in file_path_lower:
                app_name = 'æŠ–éŸ³ï¼ˆDouyinï¼‰'

        # æ ¹æ® SO æ–‡ä»¶åæ¨æ–­åº“çš„ç±»å‹å’Œç”¨é€”
        if 'xwebcore' in so_name or 'xweb' in so_name:
            context = (
                f'è¿™æ˜¯ä¸€ä¸ªåŸºäº Chromium Embedded Framework (CEF) çš„ Web æ ¸å¿ƒåº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'è¿è¡Œåœ¨ HarmonyOS å¹³å°ä¸Šã€‚è¯¥åº“è´Ÿè´£ç½‘é¡µæ¸²æŸ“ã€ç½‘ç»œè¯·æ±‚ã€DOM æ“ä½œç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚'
            )
        elif 'wechat' in so_name or 'wx' in so_name:
            context = (
                f'è¿™æ˜¯ä¸€ä¸ªæ¥è‡ªå¾®ä¿¡ï¼ˆWeChatï¼‰åº”ç”¨çš„ SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'è¿è¡Œåœ¨ HarmonyOS å¹³å°ä¸Šã€‚è¯¥åº“è´Ÿè´£å³æ—¶é€šè®¯ã€ç¤¾äº¤ç½‘ç»œã€å¤šåª’ä½“å¤„ç†ç­‰åŠŸèƒ½ã€‚'
            )
        elif 'taobao' in so_name or 'tb' in so_name:
            context = (
                f'è¿™æ˜¯ä¸€ä¸ªæ¥è‡ªæ·˜å®ï¼ˆTaobaoï¼‰åº”ç”¨çš„ SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'è¿è¡Œåœ¨ HarmonyOS å¹³å°ä¸Šã€‚è¯¥åº“è´Ÿè´£ç”µå•†è´­ç‰©ã€å•†å“å±•ç¤ºã€æ”¯ä»˜å¤„ç†ç­‰åŠŸèƒ½ã€‚'
            )
        elif 'chromium' in so_name or 'blink' in so_name or 'v8' in so_name:
            context = (
                f'è¿™æ˜¯ä¸€ä¸ªåŸºäº Chromium/Blink å¼•æ“çš„ç»„ä»¶åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'é€šå¸¸ç”¨äº Web æ¸²æŸ“ã€JavaScript æ‰§è¡Œç­‰ Web ç›¸å…³åŠŸèƒ½ã€‚'
            )
        elif 'flutter' in so_name:
            context = (
                f'è¿™æ˜¯ä¸€ä¸ª Flutter æ¡†æ¶ç›¸å…³çš„ SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'Flutter æ˜¯ Google å¼€å‘çš„è·¨å¹³å° UI æ¡†æ¶ï¼Œç”¨äºæ„å»ºç§»åŠ¨åº”ç”¨ç•Œé¢ã€‚'
            )
        # é€šç”¨æ ¼å¼ï¼Œæ ¹æ®åº”ç”¨åç§°è°ƒæ•´
        elif app_name:
            context = f'è¿™æ˜¯ä¸€ä¸ªæ¥è‡ª {app_name} åº”ç”¨çš„ SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œè¿è¡Œåœ¨ HarmonyOS å¹³å°ä¸Šã€‚'
        else:
            context = f'è¿™æ˜¯ä¸€ä¸ª SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œæ¥è‡ª {Path(so_file).parent.name} ç›®å½•ã€‚'

        return context

    def _get_call_stack_info(self, file_path: str, address: str, vaddr: int) -> Optional[dict]:
        """ä» perf.db è·å–è°ƒç”¨å †æ ˆä¿¡æ¯
        
        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            address: åœ°å€å­—ç¬¦ä¸²
            vaddr: è™šæ‹Ÿåœ°å€åç§»é‡
            
        Returns:
            è°ƒç”¨å †æ ˆä¿¡æ¯å­—å…¸ï¼ŒåŒ…å«è°ƒç”¨è€…å’Œè¢«è°ƒç”¨è€…ä¿¡æ¯
        """
        if not self.perf_db_file or not self.perf_db_file.exists():
            return None
        
        try:
            conn = sqlite3.connect(str(self.perf_db_file))
            cursor = conn.cursor()
            
            try:
                # åŠ è½½æ˜ å°„å…³ç³»
                cursor.execute('SELECT DISTINCT file_id, path FROM perf_files WHERE path IS NOT NULL')
                file_id_to_path = {row[0]: row[1] for row in cursor.fetchall()}
                
                cursor.execute('SELECT id, data FROM data_dict WHERE data IS NOT NULL')
                name_to_data = {row[0]: row[1] for row in cursor.fetchall()}
                
                # æŸ¥æ‰¾æ–‡ä»¶ ID
                file_id = None
                for fid, path in file_id_to_path.items():
                    if path == file_path:
                        file_id = fid
                        break
                
                if file_id is None:
                    return None
                
                # æŸ¥æ‰¾åœ°å€ ID
                name_id = None
                for nid, data in name_to_data.items():
                    if data == address:
                        name_id = nid
                        break
                
                if name_id is None:
                    return None
                
                # æŸ¥è¯¢è°ƒç”¨å †æ ˆï¼šæ‰¾åˆ°è°ƒç”¨è¿™ä¸ªå‡½æ•°çš„å‡½æ•°ï¼ˆdepth æ›´å°çš„ï¼‰
                # é™åˆ¶æŸ¥è¯¢æ•°é‡ä»¥æé«˜æ€§èƒ½
                cursor.execute("""
                    SELECT DISTINCT pc2.file_id, pc2.name, pc2.depth, pc2.symbol_id as caller_symbol_id
                    FROM perf_callchain pc1
                    JOIN perf_sample ps ON pc1.callchain_id = ps.callchain_id
                    JOIN perf_callchain pc2 ON ps.callchain_id = pc2.callchain_id
                    WHERE pc1.file_id = ? AND pc1.name = ? AND pc1.symbol_id = -1
                      AND pc2.depth < pc1.depth
                      AND pc2.symbol_id != -1
                    ORDER BY pc2.depth DESC
                    LIMIT 10
                """, (file_id, name_id))
                
                callers = []
                for row in cursor.fetchall():
                    caller_file_id, caller_name_id, caller_depth, caller_symbol_id = row
                    caller_file_path = file_id_to_path.get(caller_file_id, '')
                    caller_address = name_to_data.get(caller_name_id, '')
                    
                    # è·å–è°ƒç”¨è€…å‡½æ•°åï¼ˆå¦‚æœæœ‰ç¬¦å·ï¼‰
                    caller_symbol_name = None
                    if caller_symbol_id and caller_symbol_id != -1:
                        cursor.execute('SELECT name FROM perf_symbols WHERE id = ?', (caller_symbol_id,))
                        symbol_row = cursor.fetchone()
                        if symbol_row:
                            caller_symbol_name = symbol_row[0]
                    
                    if caller_file_path and caller_address:
                        callers.append({
                            'file_path': caller_file_path,
                            'address': caller_address,
                            'symbol_name': caller_symbol_name,
                            'depth': caller_depth,
                        })
                
                # æŸ¥è¯¢è¢«è°ƒç”¨è€…ï¼šæ‰¾åˆ°è¿™ä¸ªå‡½æ•°è°ƒç”¨çš„å‡½æ•°ï¼ˆdepth æ›´å¤§çš„ï¼Œä¸”æœ‰ç¬¦å·çš„ï¼‰
                cursor.execute("""
                    SELECT DISTINCT pc2.file_id, pc2.name, pc2.depth, pc2.symbol_id as callee_symbol_id
                    FROM perf_callchain pc1
                    JOIN perf_sample ps ON pc1.callchain_id = ps.callchain_id
                    JOIN perf_callchain pc2 ON ps.callchain_id = pc2.callchain_id
                    WHERE pc1.file_id = ? AND pc1.name = ? AND pc1.symbol_id = -1
                      AND pc2.depth > pc1.depth
                      AND pc2.symbol_id != -1
                    ORDER BY pc2.depth ASC
                    LIMIT 10
                """, (file_id, name_id))
                
                callees = []
                for row in cursor.fetchall():
                    callee_file_id, callee_name_id, callee_depth, callee_symbol_id = row
                    callee_file_path = file_id_to_path.get(callee_file_id, '')
                    callee_address = name_to_data.get(callee_name_id, '')
                    
                    # è·å–è¢«è°ƒç”¨è€…å‡½æ•°åï¼ˆå¦‚æœæœ‰ç¬¦å·ï¼‰
                    callee_symbol_name = None
                    if callee_symbol_id and callee_symbol_id != -1:
                        cursor.execute('SELECT name FROM perf_symbols WHERE id = ?', (callee_symbol_id,))
                        symbol_row = cursor.fetchone()
                        if symbol_row:
                            callee_symbol_name = symbol_row[0]
                    
                    if callee_file_path and callee_address:
                        callees.append({
                            'file_path': callee_file_path,
                            'address': callee_address,
                            'symbol_name': callee_symbol_name,
                            'depth': callee_depth,
                        })
                
                return {
                    'callers': callers[:5],  # é™åˆ¶æœ€å¤š5ä¸ªè°ƒç”¨è€…
                    'callees': callees[:5],  # é™åˆ¶æœ€å¤š5ä¸ªè¢«è°ƒç”¨è€…
                }
                
            finally:
                conn.close()
                
        except Exception as e:
            logger.warning(f'è·å–è°ƒç”¨å †æ ˆä¿¡æ¯æ—¶å‡ºé”™: {e}')
            return None

    def _enhance_context_with_call_stack(self, base_context: str, call_stack_info: Optional[dict]) -> str:
        """å¢å¼ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼Œæ·»åŠ è°ƒç”¨å †æ ˆä¿¡æ¯
        
        Args:
            base_context: åŸºç¡€ä¸Šä¸‹æ–‡ä¿¡æ¯
            call_stack_info: è°ƒç”¨å †æ ˆä¿¡æ¯
            
        Returns:
            å¢å¼ºåçš„ä¸Šä¸‹æ–‡ä¿¡æ¯
        """
        if not call_stack_info:
            return base_context
        
        context_parts = [base_context]
        
        # æ·»åŠ è°ƒç”¨è€…ä¿¡æ¯
        callers = call_stack_info.get('callers', [])
        if callers:
            context_parts.append('\nè°ƒç”¨å †æ ˆä¿¡æ¯ï¼ˆè°è°ƒç”¨äº†è¿™ä¸ªå‡½æ•°ï¼‰:')
            for i, caller in enumerate(callers[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                caller_info = f'  {i}. '
                if caller.get('symbol_name'):
                    caller_info += f"{caller['symbol_name']} "
                caller_info += f"({caller['file_path']} {caller['address']})"
                context_parts.append(caller_info)
        
        # æ·»åŠ è¢«è°ƒç”¨è€…ä¿¡æ¯ï¼ˆæœ‰ç¬¦å·çš„å‡½æ•°ï¼‰
        callees = call_stack_info.get('callees', [])
        if callees:
            context_parts.append('\nè¢«è°ƒç”¨çš„å‡½æ•°ï¼ˆè¿™ä¸ªå‡½æ•°è°ƒç”¨äº†å“ªäº›æœ‰ç¬¦å·çš„å‡½æ•°ï¼‰:')
            for i, callee in enumerate(callees[:3], 1):  # åªæ˜¾ç¤ºå‰3ä¸ª
                callee_info = f'  {i}. '
                if callee.get('symbol_name'):
                    callee_info += f"{callee['symbol_name']} "
                callee_info += f"({callee['file_path']} {callee['address']})"
                context_parts.append(callee_info)
        
        return '\n'.join(context_parts)

    def extract_strings_near_offset(self, elf_file, vaddr, range_size=200):
        """
        æå–è™šæ‹Ÿåœ°å€é™„è¿‘çš„å­—ç¬¦ä¸²å¸¸é‡ï¼ˆä½¿ç”¨ç²¾å‡†æå–ï¼‰

        æ³¨æ„ï¼šrange_size å‚æ•°ä¿ç•™ä»¥ä¿æŒæ¥å£å…¼å®¹æ€§ï¼Œä½†å®é™…ä½¿ç”¨ç²¾å‡†æå–é€»è¾‘
        """
        # åˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
        self._init_string_extractor()

        # ä½¿ç”¨é€šç”¨çš„å­—ç¬¦ä¸²æå–å™¨
        return self.string_extractor.extract_strings_near_offset(elf_file, vaddr)

    def analyze_function(self, file_path, address, call_count, rank, event_count=None, skip_llm=False):
        """åˆ†æå•ä¸ªå‡½æ•°ï¼ˆä¼˜å…ˆä½¿ç”¨ radare2ï¼Œå¦‚æœä¸å¯ç”¨åˆ™ä½¿ç”¨ capstoneï¼‰

        Args:
            file_path: æ–‡ä»¶è·¯å¾„
            address: åœ°å€
            call_count: è°ƒç”¨æ¬¡æ•°
            rank: æ’å
            event_count: äº‹ä»¶è®¡æ•°ï¼ˆå¯é€‰ï¼Œå¦‚æœæä¾›åˆ™ä¼˜å…ˆæ˜¾ç¤ºï¼‰
        """
        logger.info(f'\n{"=" * 80}')
        logger.info(f'åˆ†æå‡½æ•° #{rank}: {file_path}')
        if event_count is not None and event_count > 0:
            logger.info(f'åœ°å€: {address}, æŒ‡ä»¤æ•°(event_count): {event_count:,}, è°ƒç”¨æ¬¡æ•°: {call_count:,}')
        else:
            logger.info(f'åœ°å€: {address}, è°ƒç”¨æ¬¡æ•°: {call_count:,}')
        logger.info(f'{"=" * 80}')

        # æå–è™šæ‹Ÿåœ°å€ï¼ˆåç§»é‡ï¼‰
        vaddr = self.extract_offset_from_address(address)
        if vaddr is None:
            logger.warning('âš ï¸  æ— æ³•è§£æåœ°å€: %s', address)
            return None

        # æ‰¾åˆ° SO æ–‡ä»¶
        so_file = self.find_so_file(file_path)
        if not so_file:
            logger.warning('âš ï¸  æœªæ‰¾åˆ° SO æ–‡ä»¶: %s', file_path)
            return None

        logger.info(f'âœ… æ‰¾åˆ° SO æ–‡ä»¶: {so_file}')

        # ä¼˜å…ˆä½¿ç”¨ radare2ï¼ˆå¦‚æœå¯ç”¨ä¸”æœªå¼ºåˆ¶ä½¿ç”¨ Capstoneï¼‰
        if R2_AVAILABLE and not self.use_capstone_only:
            # å»¶è¿Ÿæ£€æµ‹ radare2 æ˜¯å¦çœŸçš„å¯ç”¨ï¼ˆåªåœ¨ç¬¬ä¸€æ¬¡ä½¿ç”¨æ—¶æ£€æµ‹ï¼‰
            if self._r2_actually_available is None:
                self._r2_actually_available = _check_r2_actually_available()
                if not self._r2_actually_available:
                    logger.info('â„¹ï¸  radare2 å‘½ä»¤ä¸åœ¨ PATH ä¸­ï¼Œå°†ä½¿ç”¨ capstone è¿›è¡Œåæ±‡ç¼–')

            # å¦‚æœ radare2 å¯ç”¨ï¼Œå°è¯•ä½¿ç”¨å®ƒ
            if self._r2_actually_available:
                try:
                    return self._analyze_function_with_r2(
                        so_file,
                        vaddr,
                        file_path,
                        address,
                        call_count,
                        rank,
                        event_count,
                        skip_llm,
                    )
                except (FileNotFoundError, Exception) as e:
                    # å¦‚æœ radare2 ä¸å¯ç”¨ï¼ˆFileNotFoundError: ERROR: Cannot find radare2 in PATHï¼‰
                    # æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œåç»­ç›´æ¥ä½¿ç”¨ capstone
                    if isinstance(e, FileNotFoundError) and 'radare2' in str(e):
                        logger.warning('âš ï¸  radare2 å‘½ä»¤ä¸å¯ç”¨ï¼Œè‡ªåŠ¨åˆ‡æ¢åˆ° capstone æ–¹æ³•')
                        self._r2_actually_available = False  # æ ‡è®°ä¸ºä¸å¯ç”¨ï¼Œé¿å…é‡å¤å°è¯•
                    else:
                        logger.exception('âš ï¸  radare2 åˆ†æå¤±è´¥ï¼Œå›é€€åˆ° capstone æ–¹æ³•')

        # ä½¿ç”¨ capstone æ–¹æ³•ï¼ˆå›é€€æ–¹æ¡ˆæˆ–é»˜è®¤æ–¹æ¡ˆï¼‰
        return self._analyze_function_with_capstone(
            so_file, vaddr, file_path, address, call_count, rank, event_count, skip_llm
        )

    def _analyze_function_with_r2(
        self,
        so_file,
        vaddr,
        file_path,
        address,
        call_count,
        rank,
        event_count=None,
        skip_llm=False,
    ):
        """ä½¿ç”¨ radare2 åˆ†æå‡½æ•°ï¼ˆä¼˜åŒ–ï¼šå¤ç”¨åŒä¸€ä¸ª SO æ–‡ä»¶çš„ radare2 å®ä¾‹ï¼‰"""
        logger.info('ğŸ”§ ä½¿ç”¨ radare2 è¿›è¡Œå‡½æ•°åˆ†æ')

        # ä¼˜åŒ–ï¼šå¤ç”¨åŒä¸€ä¸ª SO æ–‡ä»¶çš„ radare2 å®ä¾‹ï¼Œé¿å…é‡å¤è¿è¡Œ aaa
        # ç¡®ä¿è·¯å¾„è§£æä¸€è‡´ï¼šç»Ÿä¸€è½¬æ¢ä¸ºç»å¯¹è·¯å¾„å¹¶æ ‡å‡†åŒ–
        so_file_path_obj = Path(so_file).resolve() if isinstance(so_file, str) else so_file.resolve()

        # ä½¿ç”¨æ ‡å‡†åŒ–çš„ç»å¯¹è·¯å¾„ä½œä¸ºç¼“å­˜é”®ï¼ˆç¡®ä¿è·¯å¾„æ ¼å¼ä¸€è‡´ï¼‰
        # Windows ä¸Šè·¯å¾„ä¸åŒºåˆ†å¤§å°å†™ï¼Œç»Ÿä¸€è½¬æ¢ä¸ºå°å†™å¹¶æ ‡å‡†åŒ–è·¯å¾„åˆ†éš”ç¬¦
        if os.name == 'nt':
            # Windows: è½¬æ¢ä¸ºå°å†™ï¼Œç»Ÿä¸€ä½¿ç”¨æ­£æ–œæ ï¼Œå»é™¤å°¾éƒ¨æ–œæ 
            so_file_path = str(so_file_path_obj).lower().replace('\\', '/').rstrip('/')
        else:
            # Unix/Linux: ä¿æŒåŸæ ·ï¼Œä½†æ ‡å‡†åŒ–è·¯å¾„
            so_file_path = str(so_file_path_obj)

        # ç¡®ä¿ _r2_analyzers å·²åˆå§‹åŒ–
        if not hasattr(self, '_r2_analyzers'):
            self._r2_analyzers = {}

        # æ£€æŸ¥ç¼“å­˜ï¼ˆä½¿ç”¨è·¯å¾„å¯¹è±¡æ¯”è¾ƒï¼Œæ›´å¯é ï¼‰
        cache_match = False
        matched_key = None
        for cached_key in self._r2_analyzers:
            try:
                # å°†ç¼“å­˜é”®å’Œå½“å‰è·¯å¾„éƒ½è½¬æ¢ä¸º Path å¯¹è±¡å¹¶è§£æä¸ºç»å¯¹è·¯å¾„è¿›è¡Œæ¯”è¾ƒ
                cached_path = Path(cached_key).resolve()
                current_path = so_file_path_obj.resolve()
                # ä½¿ç”¨ Path å¯¹è±¡çš„æ¯”è¾ƒï¼ˆæ›´å¯é ï¼‰
                if cached_path == current_path:
                    cache_match = True
                    matched_key = cached_key
                    break
            except Exception:
                # å¦‚æœè·¯å¾„è§£æå¤±è´¥ï¼Œå›é€€åˆ°å­—ç¬¦ä¸²æ¯”è¾ƒ
                if os.name == 'nt':
                    cached_normalized = cached_key.lower().replace('\\', '/').rstrip('/')
                    current_normalized = so_file_path.lower().replace('\\', '/').rstrip('/')
                else:
                    cached_normalized = cached_key
                    current_normalized = so_file_path
                if cached_normalized == current_normalized:
                    cache_match = True
                    matched_key = cached_key
                    break

        if not cache_match:
            # ç¬¬ä¸€æ¬¡æ‰“å¼€è¯¥ SO æ–‡ä»¶ï¼Œåˆ›å»ºå¹¶ç¼“å­˜åˆ†æå™¨å®ä¾‹
            logger.info(f'ğŸ“‚ é¦–æ¬¡æ‰“å¼€ SO æ–‡ä»¶ï¼Œåˆå§‹åŒ– radare2 åˆ†æå™¨: {so_file_path_obj.name}')
            r2_analyzer = R2FunctionAnalyzer(so_file_path_obj, skip_decompilation=self.skip_decompilation)
            r2_analyzer.__enter__()  # æ‰‹åŠ¨è¿›å…¥ä¸Šä¸‹æ–‡ç®¡ç†å™¨ï¼Œä½†ä¸é€€å‡º
            self._r2_analyzers[so_file_path] = r2_analyzer
        else:
            # å¤ç”¨å·²å­˜åœ¨çš„åˆ†æå™¨å®ä¾‹
            r2_analyzer = self._r2_analyzers[matched_key]
            logger.info(f'â™»ï¸  å¤ç”¨ radare2 åˆ†æå™¨å®ä¾‹: {so_file_path_obj.name} (å·²ç¼“å­˜)')

        # ä½¿ç”¨ç¼“å­˜çš„åˆ†æå™¨å®ä¾‹è¿›è¡Œåˆ†æ
        result = r2_analyzer.analyze_function_at_offset(vaddr)
        if not result:
            return None

        func_info = result['func_info']
        instructions_str = result['instructions']
        strings = result['strings']
        called_functions = result.get('called_functions', [])  # è·å–è¢«è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
        decompiled = result.get('decompiled')  # è·å–åç¼–è¯‘ä»£ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰

        # è½¬æ¢æŒ‡ä»¤æ ¼å¼ï¼ˆä»å­—ç¬¦ä¸²è½¬æ¢ä¸ºåˆ—è¡¨ï¼Œä¿æŒå…¼å®¹æ€§ï¼‰
        instructions = instructions_str  # å·²ç»æ˜¯å­—ç¬¦ä¸²åˆ—è¡¨æ ¼å¼

        # è·å–è°ƒç”¨å †æ ˆä¿¡æ¯ï¼ˆä» perf.dbï¼‰
        call_stack_info = None
        if self.perf_db_file and self.perf_db_file.exists():
            try:
                call_stack_info = self._get_call_stack_info(file_path, address, vaddr)
            except Exception as e:
                logger.warning(f'âš ï¸  è·å–è°ƒç”¨å †æ ˆä¿¡æ¯å¤±è´¥: {e}')

        # LLM åˆ†æï¼ˆå¦‚æœ skip_llm=Trueï¼Œåˆ™è·³è¿‡ï¼‰
        llm_result = None
        if self.use_llm and self.llm_analyzer and not skip_llm:
            logger.info('æ­£åœ¨ä½¿ç”¨ LLM åˆ†æå‡½æ•°...')
            try:
                # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆåŒ…å«è°ƒç”¨å †æ ˆä¿¡æ¯ï¼‰
                base_context = self.context if self.context else self._build_context(so_file, file_path)
                context = self._enhance_context_with_call_stack(base_context, call_stack_info)

                # è·å–å‡½æ•°åï¼ˆå¦‚æœæœ‰ï¼‰
                symbol_name = func_info.get('name', '')
                if symbol_name.startswith('sym.imp.') or symbol_name.startswith('fcn.'):
                    symbol_name = None  # è¿™äº›æ˜¯å¯¼å…¥å‡½æ•°æˆ–è‡ªåŠ¨ç”Ÿæˆçš„åç§°ï¼Œä¸ä½¿ç”¨

                llm_result = self.llm_analyzer.analyze_with_llm(
                    instructions=instructions,
                    strings=strings,
                    symbol_name=symbol_name,
                    called_functions=called_functions,  # ä¼ é€’è¢«è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
                    offset=vaddr,
                    context=context,
                )

                logger.info('âœ… LLM åˆ†æå®Œæˆ')
                logger.info(f'   æ¨æ–­å‡½æ•°å: {llm_result.get("function_name", "N/A")}')
                logger.info(f'   åŠŸèƒ½æè¿°: {llm_result.get("functionality", "N/A")[:100]}...')
                logger.info(f'   ç½®ä¿¡åº¦: {llm_result.get("confidence", "N/A")}')
            except Exception:
                logger.exception('âŒ LLM åˆ†æå¤±è´¥')

        # è¿”å›ç»“æœï¼ˆä¿æŒä¸ capstone æ–¹æ³•ç›¸åŒçš„æ ¼å¼ï¼‰
        return {
            'rank': rank,
            'file_path': file_path,
            'address': address,
            'offset': f'0x{vaddr:x}',
            'call_count': call_count,
            'event_count': event_count,  # æ·»åŠ  event_count
            'so_file': str(so_file),
            'instruction_count': len(instructions),
            'instructions': instructions,  # å­—ç¬¦ä¸²åˆ—è¡¨æ ¼å¼
            'strings': ', '.join(strings[:5]) if strings else '',
            'called_functions': called_functions,  # æ·»åŠ è¢«è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
            'decompiled': decompiled,  # æ·»åŠ åç¼–è¯‘ä»£ç ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            'llm_result': llm_result,
            'func_info': func_info,  # é¢å¤–çš„å‡½æ•°ä¿¡æ¯
        }

    def _analyze_function_with_capstone(
        self,
        so_file,
        vaddr,
        file_path,
        address,
        call_count,
        rank,
        event_count=None,
        skip_llm=False,
    ):
        """ä½¿ç”¨ capstone åˆ†æå‡½æ•°ï¼ˆåŸæœ‰æ–¹æ³•ï¼‰"""
        logger.info('ğŸ”§ ä½¿ç”¨ capstone è¿›è¡Œå‡½æ•°åˆ†æ')

        # æ‰“å¼€ ELF æ–‡ä»¶
        try:
            with open(so_file, 'rb') as f:
                elf_file = ELFFile(f)

                # åæ±‡ç¼–å‡½æ•°
                logger.info(f'æ­£åœ¨åæ±‡ç¼– (vaddr=0x{vaddr:x})...')
                instructions = self.disassemble_function(elf_file, vaddr, size=2000)

                if not instructions:
                    logger.error('âŒ åæ±‡ç¼–å¤±è´¥')
                    return None

                logger.info(f'âœ… åæ±‡ç¼–æˆåŠŸï¼Œå…± {len(instructions)} æ¡æŒ‡ä»¤')

                # åˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
                self._init_string_extractor()

                # æå–å­—ç¬¦ä¸²ï¼ˆä¼ å…¥æŒ‡ä»¤åˆ—è¡¨ä»¥è¿›è¡Œç²¾å‡†åˆ†æï¼‰
                strings = []
                try:
                    extracted_strings = self.string_extractor.extract_strings_from_instructions(
                        elf_file, instructions, vaddr
                    )
                    if extracted_strings:
                        strings = extracted_strings
                        logger.info(
                            f'æ‰¾åˆ° {len(strings)} ä¸ªå­—ç¬¦ä¸²å¸¸é‡: {", ".join(strings[:3])}{"..." if len(strings) > 3 else ""}'
                        )
                    else:
                        logger.warning('âš ï¸  æœªæ‰¾åˆ°å­—ç¬¦ä¸²å¸¸é‡')
                        # å¦‚æœç²¾å‡†æå–æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯• fallbackï¼ˆä» .rodata æ®µæå–ï¼‰
                        fallback_strings = self.string_extractor._fallback_extract_strings(elf_file)
                        if fallback_strings:
                            strings = fallback_strings
                            logger.info(
                                f'ä½¿ç”¨ fallback æ–¹æ³•æ‰¾åˆ° {len(strings)} ä¸ªå­—ç¬¦ä¸²å¸¸é‡: {", ".join(strings[:3])}{"..." if len(strings) > 3 else ""}'
                            )
                except Exception:
                    logger.exception('âš ï¸  å­—ç¬¦ä¸²æå–å¤±è´¥')
                    strings = []  # ç¡®ä¿ strings æœ‰é»˜è®¤å€¼

                # LLM åˆ†æï¼ˆå¦‚æœ skip_llm=Trueï¼Œåˆ™è·³è¿‡ï¼‰
                llm_result = None
                if self.use_llm and self.llm_analyzer and not skip_llm:
                    logger.info('æ­£åœ¨ä½¿ç”¨ LLM åˆ†æå‡½æ•°...')
                    try:
                        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†è‡ªå®šä¹‰ä¸Šä¸‹æ–‡åˆ™ä½¿ç”¨ï¼Œå¦åˆ™æ ¹æ® SO æ–‡ä»¶è‡ªåŠ¨æ¨æ–­ï¼‰
                        context = self.context if self.context else self._build_context(so_file, file_path)

                        llm_result = self.llm_analyzer.analyze_with_llm(
                            instructions=[f'{inst.address:x}: {inst.mnemonic} {inst.op_str}' for inst in instructions],
                            strings=strings,
                            symbol_name=None,
                            called_functions=[],
                            offset=vaddr,
                            context=context,
                        )

                        logger.info('âœ… LLM åˆ†æå®Œæˆ')
                        logger.info(f'   æ¨æ–­å‡½æ•°å: {llm_result.get("function_name", "N/A")}')
                        logger.info(f'   åŠŸèƒ½æè¿°: {llm_result.get("functionality", "N/A")[:100]}...')
                        logger.info(f'   ç½®ä¿¡åº¦: {llm_result.get("confidence", "N/A")}')
                    except Exception:
                        logger.exception('âŒ LLM åˆ†æå¤±è´¥')

                # è¿”å›ç»“æœ
                return {
                    'rank': rank,
                    'file_path': file_path,
                    'address': address,
                    'offset': f'0x{vaddr:x}',
                    'call_count': call_count,
                    'event_count': event_count,  # æ·»åŠ  event_count
                    'so_file': str(so_file),
                    'instruction_count': len(instructions),
                    'instructions': instructions,  # ä¿å­˜æŒ‡ä»¤ç”¨äº HTML æŠ¥å‘Š
                    'strings': ', '.join(strings[:5]) if strings else '',
                    'called_functions': [],  # capstone æ–¹æ³•æš‚ä¸æ”¯æŒè·å–è°ƒç”¨å‡½æ•°åˆ—è¡¨
                    'llm_result': llm_result,
                }
        except Exception:
            logger.exception('âŒ åˆ†æå¤±è´¥')
            return None

    def _get_missing_symbols_from_perf_db(self, top_n=None):
        """ä» perf.db ä¸­æå–ç¼ºå¤±ç¬¦å·ï¼ˆcall_count æ¨¡å¼ï¼‰"""
        if top_n is None:
            top_n = config.DEFAULT_TOP_N

        logger.info('=' * 80)
        logger.info('âš¡ï¸ ä» perf.db æå–ç¼ºå¤±ç¬¦å·ï¼ˆcall_count æ¨¡å¼ï¼‰')
        logger.info('=' * 80)

        conn = sqlite3.connect(str(self.perf_db_file))
        cursor = conn.cursor()

        try:
            # 1. åŠ è½½æ˜ å°„å…³ç³»
            logger.info('\næ­¥éª¤ 1: åŠ è½½æ˜ å°„å…³ç³»...')
            cursor.execute('SELECT DISTINCT file_id, path FROM perf_files WHERE path IS NOT NULL')
            file_id_to_path = {row[0]: row[1] for row in cursor.fetchall()}
            logger.info(f'âœ… åŠ è½½äº† {len(file_id_to_path):,} ä¸ªæ–‡ä»¶è·¯å¾„æ˜ å°„')

            cursor.execute('SELECT id, data FROM data_dict WHERE data IS NOT NULL')
            name_to_data = {row[0]: row[1] for row in cursor.fetchall()}
            logger.info(f'âœ… åŠ è½½äº† {len(name_to_data):,} ä¸ªåœ°å€æ•°æ®æ˜ å°„')

            # 2. æŸ¥è¯¢ç¼ºå¤±ç¬¦å·è®°å½•å¹¶èšåˆ
            logger.info('\næ­¥éª¤ 2: æŸ¥è¯¢ç¼ºå¤±ç¬¦å·è®°å½•å¹¶èšåˆ...')
            cursor.execute("""
                SELECT file_id, name, ip, depth
                FROM perf_callchain
                WHERE symbol_id = -1
            """)

            address_call_counts = defaultdict(int)
            address_info = {}

            batch_size = 100000
            total_rows = 0
            while True:
                rows = cursor.fetchmany(batch_size)
                if not rows:
                    break

                total_rows += len(rows)
                for file_id, name_id, _ip, _depth in rows:
                    file_path = file_id_to_path.get(file_id, 'æœªçŸ¥æ–‡ä»¶')
                    address_data = name_to_data.get(name_id)

                    if address_data and file_path != 'æœªçŸ¥æ–‡ä»¶':
                        key = (file_path, address_data)
                        address_call_counts[key] += 1

                        if key not in address_info:
                            address_info[key] = {
                                'file_path': file_path,
                                'address': address_data,
                            }

            logger.info(f'âœ… å¤„ç†å®Œæˆï¼Œå…± {total_rows:,} æ¡è®°å½•ï¼Œèšåˆä¸º {len(address_call_counts):,} ä¸ªå”¯ä¸€åœ°å€')

            # 3. è¿‡æ»¤ç³»ç»Ÿæ–‡ä»¶
            excluded_exact = ['[shmm]', 'æœªçŸ¥æ–‡ä»¶', '/bin/devhost.elf']
            excluded_prefixes = ['/system', '/vendor/lib64', '/lib', '/chip_prod']

            filtered_data = []
            for (file_path, address), call_count in address_call_counts.items():
                if file_path in excluded_exact:
                    continue
                if any(file_path.startswith(prefix) for prefix in excluded_prefixes):
                    continue
                filtered_data.append(
                    {
                        'file_path': file_path,
                        'address': address,
                        'call_count': call_count,
                    }
                )

            # 4. æŒ‰è°ƒç”¨æ¬¡æ•°æ’åºï¼Œå–å‰ N ä¸ª
            sorted_data = sorted(filtered_data, key=lambda x: x['call_count'], reverse=True)[:top_n]
            logger.info(f'âœ… è¿‡æ»¤åå‰©ä½™ {len(filtered_data):,} æ¡è®°å½•ï¼Œé€‰æ‹©å‰ {top_n} ä¸ª')

            return sorted_data

        finally:
            conn.close()

    def analyze_top_functions(self, top_n=None):
        """åˆ†æå‰ N ä¸ªå‡½æ•°"""
        if top_n is None:
            top_n = config.DEFAULT_TOP_N
        logger.info('=' * 80)
        logger.info(f'åˆ†æç¼ºå¤±ç¬¦å·ä¸­çš„å‰ {top_n} ä¸ªå‡½æ•°ï¼ˆæŒ‰è°ƒç”¨æ¬¡æ•°ï¼‰')
        logger.info('=' * 80)

        # å¦‚æœæä¾›äº† perf_db_fileï¼Œç›´æ¥ä»æ•°æ®åº“è¯»å–
        if self.perf_db_file:
            data_list = self._get_missing_symbols_from_perf_db(top_n)
        else:
            # å¦åˆ™ä» Excel æ–‡ä»¶è¯»å–
            df = pd.read_excel(self.excel_file)
            logger.info(f'\nè¯»å– Excel æ–‡ä»¶: {len(df)} æ¡è®°å½•')

            # æ£€æŸ¥æ˜¯å¦æœ‰ event_count åˆ—ï¼Œå¦‚æœæœ‰åˆ™æŒ‰ event_count æ’åºï¼Œå¦åˆ™æŒ‰è°ƒç”¨æ¬¡æ•°æ’åº
            if 'æŒ‡ä»¤æ•°(event_count)' in df.columns:
                # æŒ‰ event_count æ’åº
                top_df = df.nlargest(top_n, 'æŒ‡ä»¤æ•°(event_count)')
                logger.info(f'é€‰æ‹©å‰ {top_n} ä¸ªå‡½æ•°ï¼ˆæŒ‰ event_count æ’åºï¼‰')
            elif 'è°ƒç”¨æ¬¡æ•°' in df.columns:
                # æŒ‰è°ƒç”¨æ¬¡æ•°æ’åº
                top_df = df.nlargest(top_n, 'è°ƒç”¨æ¬¡æ•°')
                logger.info(f'é€‰æ‹©å‰ {top_n} ä¸ªå‡½æ•°ï¼ˆæŒ‰è°ƒç”¨æ¬¡æ•°æ’åºï¼‰')
            else:
                # å¦‚æœæ²¡æœ‰æ’åºåˆ—ï¼Œç›´æ¥å–å‰ top_n è¡Œï¼ˆä¿æŒåŸæœ‰é¡ºåºï¼‰
                top_df = df.head(top_n)
                logger.info(f'é€‰æ‹©å‰ {top_n} ä¸ªå‡½æ•°ï¼ˆä¿æŒåŸæœ‰é¡ºåºï¼‰')

            # è½¬æ¢ä¸ºåˆ—è¡¨æ ¼å¼
            data_list = []
            for _, row in top_df.iterrows():
                # è¯»å– event_countï¼Œå¤„ç† NaN å€¼
                event_count = None
                if 'æŒ‡ä»¤æ•°(event_count)' in row:
                    event_count_val = row['æŒ‡ä»¤æ•°(event_count)']
                    # å¤„ç† pandas çš„ NaN å€¼
                    if pd.notna(event_count_val) and event_count_val > 0:
                        event_count = int(event_count_val)

                data_list.append(
                    {
                        'file_path': row['æ–‡ä»¶è·¯å¾„'],
                        'address': row['åœ°å€'],
                        'call_count': row.get('è°ƒç”¨æ¬¡æ•°', 0),  # ä½¿ç”¨ get é¿å… KeyError
                        'event_count': event_count,  # å¦‚æœå­˜åœ¨ä¸”æœ‰æ•ˆï¼Œåˆ™ä½¿ç”¨
                    }
                )

        # åˆ†ææ¯ä¸ªå‡½æ•°
        # å¦‚æœä½¿ç”¨æ‰¹é‡ LLM åˆ†æï¼Œå…ˆæ”¶é›†æ‰€æœ‰å‡½æ•°ä¿¡æ¯ï¼Œç„¶åæ‰¹é‡åˆ†æ
        # æ£€æŸ¥æ˜¯å¦æ˜¯æ‰¹é‡åˆ†æå™¨
        is_batch_analyzer = (
            BatchLLMFunctionAnalyzer is not None
            and self.use_llm
            and self.use_batch_llm
            and self.llm_analyzer
            and isinstance(self.llm_analyzer, BatchLLMFunctionAnalyzer)
        )

        if is_batch_analyzer:
            # æ‰¹é‡åˆ†ææ¨¡å¼ï¼šå…ˆæ”¶é›†æ‰€æœ‰å‡½æ•°ä¿¡æ¯ï¼Œç„¶åæ‰¹é‡åˆ†æ
            logger.info(f'\nä½¿ç”¨æ‰¹é‡ LLM åˆ†ææ¨¡å¼ï¼ˆbatch_size={self.batch_size}ï¼‰')
            results = []
            functions_data = []  # ç”¨äºæ‰¹é‡åˆ†æçš„æ•°æ®

            # ç¬¬ä¸€æ­¥ï¼šæ”¶é›†æ‰€æœ‰å‡½æ•°çš„åæ±‡ç¼–å’Œå­—ç¬¦ä¸²ä¿¡æ¯ï¼ˆä¸è¿›è¡Œ LLM åˆ†æï¼‰
            logger.info('æ­¥éª¤ 1: æ”¶é›†æ‰€æœ‰å‡½æ•°çš„åæ±‡ç¼–å’Œå­—ç¬¦ä¸²ä¿¡æ¯...')
            # ç¡®ä¿ _r2_analyzers å·²åˆå§‹åŒ–
            if not hasattr(self, '_r2_analyzers'):
                self._r2_analyzers = {}

            for idx, item in enumerate(data_list, 1):
                file_path = item['file_path']
                address = item['address']
                call_count = item.get('call_count', 0)
                event_count = item.get('event_count', None)
                rank = idx

                # åªè¿›è¡Œåæ±‡ç¼–å’Œå­—ç¬¦ä¸²æå–ï¼Œä¸è¿›è¡Œ LLM åˆ†æ
                result = self.analyze_function(file_path, address, call_count, rank, event_count, skip_llm=True)
                if result:
                    results.append(result)
                    # å‡†å¤‡æ‰¹é‡åˆ†æçš„æ•°æ®
                    instructions = result.get('instructions', [])
                    if isinstance(instructions, list) and len(instructions) > 0:
                        # å¦‚æœæ˜¯å­—ç¬¦ä¸²åˆ—è¡¨ï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯ Instruction å¯¹è±¡ï¼Œè½¬æ¢ä¸ºå­—ç¬¦ä¸²
                        if isinstance(instructions[0], str):
                            inst_list = instructions
                        else:
                            inst_list = [f'{inst.address:x}: {inst.mnemonic} {inst.op_str}' for inst in instructions]
                    else:
                        inst_list = []

                    # å¤„ç†å­—ç¬¦ä¸²ï¼šå¦‚æœæ˜¯é€—å·åˆ†éš”çš„å­—ç¬¦ä¸²ï¼Œè½¬æ¢ä¸ºåˆ—è¡¨
                    strings_value = result.get('strings', '')
                    if isinstance(strings_value, str):
                        strings_list = (
                            [s.strip() for s in strings_value.split(',') if s.strip()] if strings_value else []
                        )
                    else:
                        strings_list = strings_value if strings_value else []

                    functions_data.append(
                        {
                            'function_id': f'func_{rank}',
                            'offset': result.get('offset', ''),
                            'instructions': inst_list,
                            'strings': strings_list,
                            'symbol_name': None,
                            'called_functions': result.get('called_functions', []),
                            'decompiled': result.get('decompiled'),  # æ·»åŠ åç¼–è¯‘ä»£ç 
                            'rank': rank,
                            'file_path': file_path,
                            'address': address,
                        }
                    )

                    # æ¯10ä¸ªå‡½æ•°æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                    if len(results) % 10 == 0:
                        logger.info(f'  è¿›åº¦: {len(results)}/{top_n} ä¸ªå‡½æ•°ä¿¡æ¯æ”¶é›†å®Œæˆ')

                # ç¬¬äºŒæ­¥ï¼šæ‰¹é‡ LLM åˆ†æ
            if functions_data and self.llm_analyzer:
                logger.info(f'\næ­¥éª¤ 2: æ‰¹é‡ LLM åˆ†æ {len(functions_data)} ä¸ªå‡½æ•°...')
                # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä½¿ç”¨ç¬¬ä¸€ä¸ªå‡½æ•°çš„ä¸Šä¸‹æ–‡ï¼‰
                context = None
                if results:
                    first_result = results[0]
                    so_file = self.find_so_file(first_result['file_path'])
                    if so_file:
                        context = (
                            self.context if self.context else self._build_context(so_file, first_result['file_path'])
                        )

                # æ‰¹é‡åˆ†æ
                batch_results = self.llm_analyzer.batch_analyze_functions(functions_data, context=context)

                # ç¬¬ä¸‰æ­¥ï¼šå°† LLM åˆ†æç»“æœåˆå¹¶åˆ° results ä¸­
                logger.info('\næ­¥éª¤ 3: åˆå¹¶ LLM åˆ†æç»“æœ...')
                batch_results_map = {r.get('function_id', ''): r for r in batch_results}
                for result in results:
                    func_id = f'func_{result["rank"]}'
                    if func_id in batch_results_map:
                        batch_result = batch_results_map[func_id]
                        # ç§»é™¤ function_idï¼Œä¿ç•™å…¶ä»–å­—æ®µ
                        llm_result = {k: v for k, v in batch_result.items() if k != 'function_id'}
                        result['llm_result'] = llm_result
        else:
            # å•ä¸ªåˆ†ææ¨¡å¼ï¼šé€ä¸ªåˆ†æï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            results = []
            for item in data_list:
                file_path = item['file_path']
                address = item['address']
                call_count = item.get('call_count', 0)
                event_count = item.get('event_count', None)  # ä» Excel è¯»å–æ—¶å¯èƒ½åŒ…å« event_count
                rank = len(results) + 1

                result = self.analyze_function(file_path, address, call_count, rank, event_count)
                if result:
                    results.append(result)

                # æ¯10ä¸ªå‡½æ•°æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
                if len(results) % 10 == 0:
                    logger.info(f'\nè¿›åº¦: {len(results)}/{top_n} ä¸ªå‡½æ•°åˆ†æå®Œæˆ')

        # åˆ†æå®Œæˆåï¼Œä¿å­˜æ‰€æœ‰ç¼“å­˜å’Œç»Ÿè®¡ï¼ˆç»Ÿä¸€åœ¨è¿™é‡Œè°ƒç”¨ï¼Œé¿å…é‡å¤ï¼‰
        if self.use_llm and self.llm_analyzer:
            self.llm_analyzer.finalize()

        return results

    def _analyze_top_functions_sequential(self, top_df, top_n):
        """é€ä¸ªåˆ†æå‰ N ä¸ªå‡½æ•°ï¼ˆåŸæœ‰é€»è¾‘ï¼‰"""
        results = []
        for _idx, row in top_df.iterrows():
            file_path = row['æ–‡ä»¶è·¯å¾„']
            address = row['åœ°å€']
            call_count = row.get('è°ƒç”¨æ¬¡æ•°', 0)

            # è¯»å– event_countï¼Œå¤„ç† NaN å€¼
            event_count = None
            if 'æŒ‡ä»¤æ•°(event_count)' in row:
                event_count_val = row['æŒ‡ä»¤æ•°(event_count)']
                # å¤„ç† pandas çš„ NaN å€¼
                if pd.notna(event_count_val) and event_count_val > 0:
                    event_count = int(event_count_val)

            rank = len(results) + 1

            result = self.analyze_function(file_path, address, call_count, rank, event_count)
            if result:
                results.append(result)

            # æ¯10ä¸ªå‡½æ•°æ˜¾ç¤ºä¸€æ¬¡è¿›åº¦
            if len(results) % 10 == 0:
                logger.info(f'\nè¿›åº¦: {len(results)}/{top_n} ä¸ªå‡½æ•°åˆ†æå®Œæˆ')

        # æ¸…ç† radare2 åˆ†æå™¨ï¼ˆåˆ†æå®Œæˆåé‡Šæ”¾èµ„æºï¼‰
        if hasattr(self, '_r2_analyzers'):
            self.cleanup_r2_analyzers()

        return results

    def cleanup_r2_analyzers(self):
        """æ¸…ç†æ‰€æœ‰ç¼“å­˜çš„ radare2 åˆ†æå™¨å®ä¾‹"""
        if not hasattr(self, '_r2_analyzers'):
            return
        for so_file_path, r2_analyzer in self._r2_analyzers.items():
            try:
                r2_analyzer.__exit__(None, None, None)  # æ‰‹åŠ¨é€€å‡ºä¸Šä¸‹æ–‡ç®¡ç†å™¨
            except Exception as e:
                logger.info(f'âš ï¸  å…³é—­ radare2 åˆ†æå™¨å¤±è´¥ ({Path(so_file_path).name}): {e}')
        self._r2_analyzers.clear()
        logger.info('âœ… å·²æ¸…ç†æ‰€æœ‰ radare2 åˆ†æå™¨å®ä¾‹')

    def save_results(
        self,
        results,
        output_file=None,
        html_file=None,
        time_tracker=None,
        top_n=None,
        output_dir=None,
    ):
        """ä¿å­˜åˆ†æç»“æœ

        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™æ ¹æ® top_n è‡ªåŠ¨ç”Ÿæˆï¼‰
            html_file: HTML æŠ¥å‘Šæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™æ ¹æ® output_file è‡ªåŠ¨ç”Ÿæˆï¼‰
            time_tracker: æ—¶é—´è·Ÿè¸ªå™¨ï¼ˆå¯é€‰ï¼‰
            top_n: åˆ†æçš„æ•°é‡ï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼Œå¦‚æœä¸æä¾›åˆ™ä»ç»“æœæ•°é‡æ¨æ–­ï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è¾“å‡ºç›®å½•ï¼‰
        """
        output_dir = config.get_output_dir() if output_dir is None else Path(output_dir)
        config.ensure_output_dir(output_dir)

        # å¦‚æœæ²¡æœ‰æä¾› top_nï¼Œä»ç»“æœæ•°é‡æ¨æ–­
        if top_n is None:
            top_n = len(results) if results else config.DEFAULT_TOP_N

        # æ£€æŸ¥æ˜¯å¦ä½¿ç”¨ event_countï¼ˆå¦‚æœç»“æœä¸­æœ‰ event_count å­—æ®µï¼‰
        use_event_count = any('event_count' in result and result.get('event_count', 0) > 0 for result in results)

        # å‡†å¤‡ Excel æ•°æ®
        excel_data = []
        for result in results:
            llm_result = result.get('llm_result', {})
            # ç¡®ä¿å­—ç¬¦ä¸²å¸¸é‡ä¸ä¸º Noneï¼Œç©ºå­—ç¬¦ä¸²ä¹Ÿè¦ä¿ç•™
            strings_value = result.get('strings', '')
            if strings_value is None:
                strings_value = ''
            # è·å–å‡½æ•°è¾¹ç•Œä¿¡æ¯ï¼ˆç”¨äºåœ°å€åŒ¹é…ï¼‰
            func_info = result.get('func_info', {})
            func_start = func_info.get('minbound', func_info.get('offset', 0))
            func_size = func_info.get('size', 0)
            func_end = func_info.get('maxbound', func_start + func_size) if func_size > 0 else func_start + 2000
            
            # å¤„ç†è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
            called_functions = result.get('called_functions', [])
            called_functions_str = ', '.join(called_functions[:10]) if called_functions else ''  # æœ€å¤šæ˜¾ç¤º10ä¸ª
            
            row_data = {
                'æ’å': result['rank'],
                'æ–‡ä»¶è·¯å¾„': result['file_path'],
                'åœ°å€': result['address'],
                'åç§»é‡': result['offset'],
                'SOæ–‡ä»¶': result['so_file'],
                'æŒ‡ä»¤æ•°': result['instruction_count'],
                'å­—ç¬¦ä¸²å¸¸é‡': strings_value,  # ç¡®ä¿æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œä¸æ˜¯ None
                'è°ƒç”¨çš„å‡½æ•°': called_functions_str,  # æ·»åŠ è°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
                'LLMæ¨æ–­å‡½æ•°å': llm_result.get('function_name', '') if llm_result else '',
                'LLMåŠŸèƒ½æè¿°': llm_result.get('functionality', '') if llm_result else '',
                'LLMç½®ä¿¡åº¦': llm_result.get('confidence', '') if llm_result else '',
                'LLMæ¨ç†è¿‡ç¨‹': llm_result.get('reasoning', '') if llm_result else '',
                'å‡½æ•°èµ·å§‹åç§»': f'0x{func_start:x}' if func_start else '',
                'å‡½æ•°å¤§å°': func_size if func_size > 0 else '',
                'å‡½æ•°ç»“æŸåç§»': f'0x{func_end:x}' if func_end > func_start else '',
            }

            # æ ¹æ®ç»Ÿè®¡æ–¹å¼é€‰æ‹©æ˜¾ç¤º event_count æˆ– call_count
            if use_event_count and 'event_count' in result:
                # ä½¿ç”¨ event_count ä½œä¸ºä¸»è¦æŒ‡æ ‡
                row_data['æŒ‡ä»¤æ•°(event_count)'] = result['event_count']
                # åŒæ—¶æ˜¾ç¤º call_countï¼ˆå³ä½¿ä¸º0ä¹Ÿæ˜¾ç¤ºï¼Œç”¨äºå¯¹æ¯”ï¼‰
                row_data['è°ƒç”¨æ¬¡æ•°'] = result.get('call_count', 0)
            else:
                # ä½¿ç”¨ call_count ä½œä¸ºä¸»è¦æŒ‡æ ‡
                row_data['è°ƒç”¨æ¬¡æ•°'] = result.get('call_count', 0)
                # å¦‚æœæœ‰ event_countï¼Œä¹Ÿæ˜¾ç¤ºï¼ˆç”¨äºå¯¹æ¯”ï¼‰
                if 'event_count' in result and result.get('event_count', 0) > 0:
                    row_data['æŒ‡ä»¤æ•°(event_count)'] = result['event_count']

            excel_data.append(row_data)

        # ä¿å­˜ Excel
        df = pd.DataFrame(excel_data)

        # ç¡®ä¿å­—ç¬¦ä¸²å¸¸é‡åˆ—æ˜¯å­—ç¬¦ä¸²ç±»å‹ï¼Œé¿å…ç©ºå­—ç¬¦ä¸²è¢«è½¬æ¢ä¸º nan
        if 'å­—ç¬¦ä¸²å¸¸é‡' in df.columns:
            df['å­—ç¬¦ä¸²å¸¸é‡'] = df['å­—ç¬¦ä¸²å¸¸é‡'].astype(str).replace('nan', '').replace('None', '')

        # ç¡®ä¿åˆ—çš„é¡ºåºï¼šå¦‚æœä½¿ç”¨ event_countï¼Œå°† event_count åˆ—æ”¾åœ¨è°ƒç”¨æ¬¡æ•°ä¹‹å‰
        if use_event_count and 'æŒ‡ä»¤æ•°(event_count)' in df.columns:
            # é‡æ–°æ’åˆ—åˆ—çš„é¡ºåº
            cols = list(df.columns)
            if 'æŒ‡ä»¤æ•°(event_count)' in cols and 'è°ƒç”¨æ¬¡æ•°' in cols:
                # ç§»é™¤è¿™ä¸¤ä¸ªåˆ—
                cols.remove('æŒ‡ä»¤æ•°(event_count)')
                cols.remove('è°ƒç”¨æ¬¡æ•°')
                # æ‰¾åˆ° 'åç§»é‡' çš„ä½ç½®ï¼Œåœ¨å…¶åæ’å…¥
                if 'åç§»é‡' in cols:
                    idx = cols.index('åç§»é‡')
                    cols.insert(idx + 1, 'æŒ‡ä»¤æ•°(event_count)')
                    cols.insert(idx + 2, 'è°ƒç”¨æ¬¡æ•°')
                # å¦‚æœæ²¡æœ‰åç§»é‡ï¼Œåœ¨åœ°å€åæ’å…¥
                elif 'åœ°å€' in cols:
                    idx = cols.index('åœ°å€')
                    cols.insert(idx + 1, 'æŒ‡ä»¤æ•°(event_count)')
                    cols.insert(idx + 2, 'è°ƒç”¨æ¬¡æ•°')
                else:
                    cols.insert(0, 'æŒ‡ä»¤æ•°(event_count)')
                    cols.insert(1, 'è°ƒç”¨æ¬¡æ•°')
                df = df[cols]

        if output_file is None:
            excel_file = output_dir / config.CALL_COUNT_ANALYSIS_PATTERN.format(n=top_n)
        else:
            excel_file = Path(output_file) if isinstance(output_file, str) else output_file
            if not excel_file.is_absolute():
                output_file_str = str(output_file)
                output_dir_str = str(output_dir)
                excel_file = Path(output_file) if output_dir_str in output_file_str else output_dir / excel_file

        # ä½¿ç”¨ openpyxl è®¾ç½®æ ¼å¼
        if not all([Workbook, Alignment, get_column_letter]):
            raise ImportError('openpyxl æœªå®‰è£…ï¼Œè¯·æ‰§è¡Œ pip install openpyxl')

        wb = Workbook()
        ws = wb.active
        ws.title = 'ç¼ºå¤±ç¬¦å·å‡½æ•°åˆ†æ'

        headers = list(df.columns)
        ws.append(headers)

        for _, row in df.iterrows():
            ws.append([row[col] for col in headers])

        # è®¾ç½®åˆ—å®½
        column_widths = {
            'æ’å': 8,
            'æ–‡ä»¶è·¯å¾„': 60,
            'åœ°å€': 40,
            'åç§»é‡': 15,
            'è°ƒç”¨æ¬¡æ•°': 12,
            'æŒ‡ä»¤æ•°(event_count)': 18,
            'SOæ–‡ä»¶': 50,
            'æŒ‡ä»¤æ•°': 10,
            'å­—ç¬¦ä¸²å¸¸é‡': 40,
            'è°ƒç”¨çš„å‡½æ•°': 50,  # æ–°å¢ï¼šè°ƒç”¨çš„å‡½æ•°åˆ—è¡¨
            'LLMæ¨æ–­å‡½æ•°å': 30,
            'LLMåŠŸèƒ½æè¿°': 80,
            'LLMç½®ä¿¡åº¦': 12,
            'LLMæ¨ç†è¿‡ç¨‹': 80,
            'å‡½æ•°èµ·å§‹åç§»': 15,
            'å‡½æ•°å¤§å°': 12,
            'å‡½æ•°ç»“æŸåç§»': 15,
        }

        for col_idx, header in enumerate(headers, 1):
            col_letter = get_column_letter(col_idx)
            ws.column_dimensions[col_letter].width = column_widths.get(header, 15)

            # è®¾ç½®æ–‡æœ¬æ¢è¡Œ
            if header in ['LLMåŠŸèƒ½æè¿°', 'LLMæ¨ç†è¿‡ç¨‹', 'æ–‡ä»¶è·¯å¾„', 'è°ƒç”¨çš„å‡½æ•°', 'å­—ç¬¦ä¸²å¸¸é‡']:
                for row_idx in range(2, len(df) + 2):
                    cell = ws[f'{col_letter}{row_idx}']
                    cell.alignment = Alignment(wrap_text=True, vertical='top')

        wb.save(excel_file)
        logger.info(f'\nâœ… Excel æŠ¥å‘Šå·²ç”Ÿæˆ: {excel_file}')

        # ä¸å†ç”Ÿæˆå•ç‹¬çš„ HTML æŠ¥å‘Šæ–‡ä»¶
        # HTML æŠ¥å‘Šå†…å®¹å°†åœ¨ Step 4 ä¸­ç›´æ¥åµŒå…¥åˆ° hiperf_report.html ä¸­
        logger.info('â„¹ï¸  è·³è¿‡ HTML æŠ¥å‘Šæ–‡ä»¶ç”Ÿæˆï¼ˆå°†åœ¨ Step 4 ä¸­åµŒå…¥åˆ° hiperf_report.htmlï¼‰')

        return excel_file
