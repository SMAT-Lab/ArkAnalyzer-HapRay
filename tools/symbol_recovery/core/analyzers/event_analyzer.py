#!/usr/bin/env python3

"""
æŒ‰æŒ‡ä»¤æ•°ï¼ˆevent_countï¼‰ç»Ÿè®¡ å’Œåˆ†æå‡½æ•°
ä»perf.db æ–‡ä»¶ä¸­è¯»å–æ•°æ®ï¼Œè¿›è¡Œåæ±‡ç¼–å’ŒLLMåˆ†æ
"""

import gc
import sqlite3
from collections import defaultdict
from pathlib import Path

import pandas as pd

from core.llm.initializer import init_llm_analyzer
from core.utils import config
from core.utils.logger import get_logger
from core.utils.perf_converter import MissingSymbolFunctionAnalyzer

#  ä½¿ç”¨æ—¥å¿—
logger = get_logger(__name__)

# åŠ è½½ .env æ–‡ä»¶ä¸­çš„ç¯å¢ƒå˜é‡
try:
    from dotenv import load_dotenv

    load_dotenv()
except ImportError:
    logger.warning('æœªå®‰è£… python-dotenv åº“ï¼Œå°†è·³è¿‡ .env æ–‡ä»¶çš„åŠ è½½')
    logger.warning('è¯·å®‰è£… python-dotenv åº“: pip install python-dotenv')
except Exception as e:
    logger.error('åŠ è½½ .env æ–‡ä»¶æ—¶å‡ºé”™: %s', e)
    raise


class EventCountAnalyzer:
    """äº‹ä»¶è®¡æ•°åˆ†æå™¨"""

    def __init__(
        self,
        perf_db_file,
        so_dir=None,
        so_file=None,
        use_llm=True,
        llm_model=None,
        use_batch_llm=True,
        batch_size=5,
        context=None,
        open_source_lib=None,
        use_capstone_only=False,
        save_prompts=False,
        output_dir=None,
        skip_decompilation=False,
    ):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            perf_db_file: perf.db æ–‡ä»¶è·¯å¾„
            so_dir: SO æ–‡ä»¶ç›®å½•ï¼ˆå¯é€‰ï¼Œå¦‚æœæŒ‡å®šäº† so_file åˆ™ä¸éœ€è¦ï¼‰
            so_file: å•ä¸ª SO æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼Œå¦‚æœæŒ‡å®šåˆ™ä¼˜å…ˆä½¿ç”¨æ­¤æ–‡ä»¶ï¼Œå¦åˆ™ä½¿ç”¨ so_dirï¼‰
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM åˆ†æ
            llm_model: LLM æ¨¡å‹åç§°
            use_batch_llm: æ˜¯å¦ä½¿ç”¨æ‰¹é‡ LLM åˆ†æï¼ˆä¸€ä¸ª prompt åŒ…å«å¤šä¸ªå‡½æ•°ï¼Œé»˜è®¤ Trueï¼‰
            batch_size: æ‰¹é‡åˆ†ææ—¶æ¯ä¸ª prompt åŒ…å«çš„å‡½æ•°æ•°é‡ï¼ˆé»˜è®¤ 3ï¼‰
            context: è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™æ ¹æ® SO æ–‡ä»¶åè‡ªåŠ¨æ¨æ–­ï¼‰
            open_source_lib: å¼€æºåº“åç§°ï¼ˆå¯é€‰ï¼Œå¦‚ "ffmpeg", "openssl" ç­‰ï¼‰ã€‚å¦‚æœæŒ‡å®šï¼Œä¼šå‘Šè¯‰å¤§æ¨¡å‹è¿™æ˜¯åŸºäºè¯¥å¼€æºåº“çš„å®šåˆ¶ç‰ˆæœ¬
            use_capstone_only: åªä½¿ç”¨ Capstone åæ±‡ç¼–ï¼ˆä¸ä½¿ç”¨ Radare2ï¼Œå³ä½¿å·²å®‰è£…ï¼‰
            save_prompts: æ˜¯å¦ä¿å­˜ç”Ÿæˆçš„ prompt åˆ°æ–‡ä»¶
            output_dir: è¾“å‡ºç›®å½•ï¼Œç”¨äºä¿å­˜ prompt æ–‡ä»¶
            skip_decompilation: æ˜¯å¦è·³è¿‡åç¼–è¯‘ï¼ˆé»˜è®¤ Falseï¼Œå¯ç”¨åç¼–è¯‘å¯æé«˜ LLM åˆ†æè´¨é‡ä½†è¾ƒæ…¢ï¼‰
        """
        self.perf_db_file = Path(perf_db_file)
        self.so_dir = Path(so_dir) if so_dir else None
        self.so_file = Path(so_file) if so_file else None
        
        # éªŒè¯ï¼šå¿…é¡»æä¾› so_file æˆ– so_dir ä¹‹ä¸€
        if not self.so_file and not self.so_dir:
            raise ValueError('å¿…é¡»æä¾› so_file æˆ– so_dir ä¹‹ä¸€')
        
        if self.so_file and not self.so_file.exists():
            raise FileNotFoundError(f'SO æ–‡ä»¶ä¸å­˜åœ¨: {so_file}')
        self.use_llm = use_llm
        self.llm_model = llm_model
        self.use_batch_llm = use_batch_llm
        self.batch_size = batch_size or config.DEFAULT_BATCH_SIZE
        self.context = context
        self.open_source_lib = open_source_lib
        self.use_capstone_only = use_capstone_only
        self.skip_decompilation = skip_decompilation

        if not self.perf_db_file.exists():
            raise FileNotFoundError(f'perf.db ä¸å­˜åœ¨: {perf_db_file}')
        if self.so_dir and not self.so_dir.exists():
            raise FileNotFoundError(f'SO æ–‡ä»¶ç›®å½•ä¸å­˜åœ¨: {so_dir}')

        # åˆå§‹åŒ– LLM åˆ†æå™¨ï¼ˆå…¬å…±å·¥å…·ï¼‰
        self.llm_analyzer, self.use_llm, self.use_batch_llm = init_llm_analyzer(
            use_llm=self.use_llm,
            llm_model=self.llm_model,
            use_batch_llm=self.use_batch_llm,
            batch_size=self.batch_size,
            logger=logger.info,
            save_prompts=save_prompts,
            output_dir=output_dir,
            open_source_lib=self.open_source_lib,
        )

    def analyze(self):
        """æ‰§è¡Œåˆ†æ"""
        logger.info('=' * 80)
        logger.info('åˆ†æ event_count çš„ top100')
        logger.info('=' * 80)

        conn = sqlite3.connect(str(self.perf_db_file))
        cursor = conn.cursor()

        try:
            # 1. åŠ è½½æ˜ å°„å…³ç³»
            logger.info('\næ­¥éª¤ 1: åŠ è½½æ˜ å°„å…³ç³»...')
            cursor.execute('SELECT DISTINCT file_id, path FROM perf_files WHERE path IS NOT NULL')
            file_id_to_path = {row[0]: row[1] for row in cursor.fetchall()}
            logger.info(f'[OK] åŠ è½½äº† {len(file_id_to_path):,} ä¸ªæ–‡ä»¶è·¯å¾„æ˜ å°„')

            cursor.execute('SELECT id, data FROM data_dict WHERE data IS NOT NULL')
            name_to_data = {row[0]: row[1] for row in cursor.fetchall()}
            logger.info(f'[OK] åŠ è½½äº† {len(name_to_data):,} ä¸ªåœ°å€æ•°æ®æ˜ å°„')

            # 2. æŒ‰è°ƒç”¨æ¬¡æ•°ç»Ÿè®¡ top100ï¼ˆç°æœ‰é€»è¾‘ï¼‰
            logger.info('\næ­¥éª¤ 2: æŒ‰è°ƒç”¨æ¬¡æ•°ç»Ÿè®¡ top100...')
            call_count_top100 = self._get_call_count_top100(cursor, file_id_to_path, name_to_data)
            logger.info(f'[OK] æ‰¾åˆ° {len(call_count_top100)} ä¸ªåœ°å€ï¼ˆè°ƒç”¨æ¬¡æ•° top100ï¼‰')

            # 3. æŒ‰ event_count æ±‚å’Œç»Ÿè®¡ top100ï¼ˆæ–°é€»è¾‘ï¼‰
            logger.info('\næ­¥éª¤ 3: æŒ‰ event_count æ±‚å’Œç»Ÿè®¡ top100...')
            event_count_top100 = self._get_event_count_top100(cursor, file_id_to_path, name_to_data)
            logger.info(f'[OK] æ‰¾åˆ° {len(event_count_top100)} ä¸ªåœ°å€ï¼ˆevent_count top100ï¼‰')

            # 4. æ‰¾å‡ºå·®å¼‚
            logger.info('\næ­¥éª¤ 4: æ‰¾å‡ºå·®å¼‚...')
            call_count_keys = set(call_count_top100.keys())
            event_count_keys = set(event_count_top100.keys())

            # åœ¨ event_count top100 ä¸­ä½†ä¸åœ¨ call_count top100 ä¸­çš„
            diff_keys = event_count_keys - call_count_keys
            logger.info(f'[OK] æ‰¾åˆ° {len(diff_keys)} ä¸ªå·®å¼‚åœ°å€ï¼ˆåœ¨ event_count top100 ä½†ä¸åœ¨ call_count top100ï¼‰')

            if diff_keys:
                logger.info('\nå·®å¼‚åœ°å€åˆ—è¡¨ï¼ˆå‰20ä¸ªï¼‰:')
                diff_list = sorted(
                    [(k, event_count_top100[k]) for k in diff_keys],
                    key=lambda x: x[1]['event_count'],
                    reverse=True,
                )
                for i, (_key, info) in enumerate(diff_list[:20], 1):
                    logger.info(
                        f'  {i}. {info["file_path"]} {info["address"]} - event_count: {info["event_count"]}, è°ƒç”¨æ¬¡æ•°: {info.get("call_count", 0)}'
                    )

            # 5. å¯¹å·®å¼‚éƒ¨åˆ†è¿›è¡Œ LLM åˆ†æ
            if diff_keys and self.use_llm:
                logger.info('\næ­¥éª¤ 5: å¯¹å·®å¼‚éƒ¨åˆ†è¿›è¡Œ LLM åˆ†æ...')
                self._analyze_differences(diff_keys, event_count_top100)

            # 6. ç”ŸæˆæŠ¥å‘Š
            logger.info('\næ­¥éª¤ 6: ç”ŸæˆæŠ¥å‘Š...')
            self._generate_report(call_count_top100, event_count_top100, diff_keys)

        finally:
            conn.close()

    def _get_call_count_top100(self, cursor, file_id_to_path, name_to_data):
        """æŒ‰è°ƒç”¨æ¬¡æ•°ç»Ÿè®¡ top100"""
        cursor.execute("""
            SELECT file_id, name, ip, depth
            FROM perf_callchain
            WHERE symbol_id = -1
        """)

        address_call_counts = defaultdict(int)
        address_info = {}

        batch_size = 100000
        while True:
            rows = cursor.fetchmany(batch_size)
            if not rows:
                break

            for file_id, name_id, ip, depth in rows:
                file_path = file_id_to_path.get(file_id, 'æœªçŸ¥æ–‡ä»¶')
                address_data = name_to_data.get(name_id, None)

                if address_data and file_path != 'æœªçŸ¥æ–‡ä»¶':
                    key = (file_path, address_data)
                    address_call_counts[key] += 1

                    if key not in address_info:
                        address_info[key] = {
                            'file_path': file_path,
                            'address': address_data,
                            'file_id': file_id,
                            'name_id': name_id,
                            'ip': ip,
                            'depth': depth,
                        }

        # è¿‡æ»¤å’Œæ’åº
        excluded_exact = ['[shmm]', 'æœªçŸ¥æ–‡ä»¶', '/bin/devhost.elf']
        excluded_prefixes = ['/system', '/vendor/lib64', '/lib', '/chip_prod']

        filtered = {}
        for key, count in address_call_counts.items():
            file_path, address = key
            if file_path in excluded_exact:
                continue
            if any(file_path.startswith(prefix) for prefix in excluded_prefixes):
                continue
            filtered[key] = {**address_info[key], 'call_count': count}

        # å– top_nï¼ˆä½¿ç”¨é»˜è®¤å€¼ï¼‰
        sorted_items = sorted(filtered.items(), key=lambda x: x[1]['call_count'], reverse=True)
        top_n = config.DEFAULT_TOP_N
        return {k: v for k, v in sorted_items[:top_n]}

    def _get_event_count_top100(self, cursor, file_id_to_path, name_to_data, top_n=None):
        """æŒ‰ event_count æ±‚å’Œç»Ÿè®¡ topN"""
        if top_n is None:
            top_n = config.DEFAULT_TOP_N
        # æŸ¥è¯¢ perf_sample å’Œ perf_callchain çš„å…³è”
        cursor.execute("""
            SELECT pc.file_id, pc.name, SUM(ps.event_count) as total_event_count,
                   COUNT(*) as call_count, pc.ip, pc.depth
            FROM perf_sample ps
            JOIN perf_callchain pc ON ps.callchain_id = pc.callchain_id
            WHERE pc.symbol_id = -1
            GROUP BY pc.file_id, pc.name
        """)

        # ç«‹å³è·å–æ‰€æœ‰ç»“æœï¼Œé¿å…åç»­è¿æ¥å…³é—­åæ— æ³•è®¿é—®
        all_rows = cursor.fetchall()

        address_event_counts = defaultdict(lambda: {'event_count': 0, 'call_count': 0, 'info': None})

        for file_id, name_id, total_event_count, call_count, ip, depth in all_rows:
            file_path = file_id_to_path.get(file_id, 'æœªçŸ¥æ–‡ä»¶')
            address_data = name_to_data.get(name_id, None)

            if address_data and file_path != 'æœªçŸ¥æ–‡ä»¶':
                key = (file_path, address_data)
                address_event_counts[key]['event_count'] += total_event_count
                address_event_counts[key]['call_count'] += call_count

                if address_event_counts[key]['info'] is None:
                    address_event_counts[key]['info'] = {
                        'file_path': file_path,
                        'address': address_data,
                        'file_id': file_id,
                        'name_id': name_id,
                        'ip': ip,
                        'depth': depth,
                    }

        # è¿‡æ»¤å’Œæ’åº
        excluded_exact = ['[shmm]', 'æœªçŸ¥æ–‡ä»¶', '/bin/devhost.elf']
        excluded_prefixes = ['/system', '/vendor/lib64', '/lib', '/chip_prod']

        # å¦‚æœæŒ‡å®šäº† so_fileï¼Œåªä¿ç•™åŒ¹é…çš„åœ°å€
        target_so_name = None
        if self.so_file:
            target_so_name = self.so_file.name
            logger.info(f'ğŸ“Œ å·²æŒ‡å®š SO æ–‡ä»¶: {target_so_name}ï¼Œå°†åªåˆ†æè¯¥æ–‡ä»¶çš„åœ°å€')

        filtered = {}
        for key, data in address_event_counts.items():
            file_path, address = key
            if file_path in excluded_exact:
                continue
            if any(file_path.startswith(prefix) for prefix in excluded_prefixes):
                continue
            
            # å¦‚æœæŒ‡å®šäº† so_fileï¼Œåªä¿ç•™åŒ¹é…çš„åœ°å€
            if target_so_name:
                file_so_name = Path(file_path).name
                if file_so_name != target_so_name:
                    continue
            
            filtered[key] = {
                **data['info'],
                'event_count': data['event_count'],
                'call_count': data['call_count'],
            }

        # å– topN
        sorted_items = sorted(filtered.items(), key=lambda x: x[1]['event_count'], reverse=True)
        return {k: v for k, v in sorted_items[:top_n]}

    def _analyze_differences(self, diff_keys, event_count_top100):
        """å¯¹å·®å¼‚éƒ¨åˆ†è¿›è¡Œ LLM åˆ†æ"""
        # åˆ›å»ºä¸´æ—¶ Excel æ–‡ä»¶
        diff_data = []
        for key in diff_keys:
            info = event_count_top100[key]
            diff_data.append(
                {
                    'æ–‡ä»¶è·¯å¾„': info['file_path'],
                    'åœ°å€': info['address'],
                    'event_count': info['event_count'],
                    'è°ƒç”¨æ¬¡æ•°': info.get('call_count', 0),
                    'æ–‡ä»¶ID': info['file_id'],
                    'åç§°ID': info['name_id'],
                    'IPåœ°å€': f'0x{info["ip"]:x}' if info['ip'] else None,
                    'å †æ ˆæ·±åº¦': info['depth'],
                }
            )

        # ä½¿ç”¨ç°æœ‰çš„åˆ†æå™¨
        output_dir = config.get_output_dir()
        config.ensure_output_dir(output_dir)
        temp_excel = output_dir / f'{config.TEMP_FILE_PREFIX}event_count_diff.xlsx'
        temp_excel.parent.mkdir(exist_ok=True)
        df = pd.DataFrame(diff_data)
        df.to_excel(temp_excel, index=False)

        logger.info(f'[OK] åˆ›å»ºä¸´æ—¶ Excel æ–‡ä»¶: {temp_excel}')
        logger.info(f'   åŒ…å« {len(diff_data)} ä¸ªå·®å¼‚åœ°å€')

        # ä½¿ç”¨ç°æœ‰çš„åˆ†æå™¨è¿›è¡Œåˆ†æ
        analyzer = MissingSymbolFunctionAnalyzer(
            excel_file=temp_excel,
            so_dir=self.so_dir,
            so_file=self.so_file,
            use_llm=self.use_llm,
            llm_model=self.llm_model,
            use_capstone_only=self.use_capstone_only,
        )

        logger.info('\nå¼€å§‹ LLM åˆ†æ...')
        # ä½¿ç”¨ analyze_top_functions æ–¹æ³•ï¼Œä¼ å…¥æ‰€æœ‰å·®å¼‚åœ°å€çš„æ•°é‡
        results = analyzer.analyze_top_functions(top_n=len(diff_data))

        # ä¿å­˜ç»“æœ
        output_file = output_dir / config.DIFF_ANALYSIS_PATTERN
        analyzer.save_results(results, output_file=output_file)
        logger.info(f'[OK] åˆ†æç»“æœå·²ä¿å­˜: {output_file}')

    def _generate_report(self, call_count_top100, event_count_top100, diff_keys):
        """ç”Ÿæˆå¯¹æ¯”æŠ¥å‘Š"""
        # è·å–è¾“å‡ºç›®å½•
        output_dir = config.get_output_dir()
        config.ensure_output_dir(output_dir)

        report_data = []

        # æ”¶é›†æ‰€æœ‰åœ°å€
        all_keys = set(call_count_top100.keys()) | set(event_count_top100.keys())

        for key in all_keys:
            call_info = call_count_top100.get(key, {})
            event_info = event_count_top100.get(key, {})

            file_path = call_info.get('file_path') or event_info.get('file_path', '')
            address = call_info.get('address') or event_info.get('address', '')

            report_data.append(
                {
                    'æ–‡ä»¶è·¯å¾„': file_path,
                    'åœ°å€': address,
                    'è°ƒç”¨æ¬¡æ•°æ’å': 'æ˜¯' if key in call_count_top100 else 'å¦',
                    'è°ƒç”¨æ¬¡æ•°': call_info.get('call_count', 0),
                    'event_countæ’å': 'æ˜¯' if key in event_count_top100 else 'å¦',
                    'event_count': event_info.get('event_count', 0),
                    'å·®å¼‚æ ‡è®°': 'æ˜¯' if key in diff_keys else 'å¦',
                }
            )

        # ä¿å­˜æŠ¥å‘Š
        report_file = output_dir / config.COMPARISON_REPORT_PATTERN
        report_file.parent.mkdir(exist_ok=True)
        df = pd.DataFrame(report_data)
        df.to_excel(report_file, index=False)
        logger.info(f'[OK] å¯¹æ¯”æŠ¥å‘Šå·²ä¿å­˜: {report_file}')

    def analyze_event_count_only(self, top_n=None):
        """åªæŒ‰ event_count ç»Ÿè®¡ topNï¼Œä¸è¿›è¡Œå¯¹æ¯”"""
        if top_n is None:
            top_n = config.DEFAULT_TOP_N
        logger.info('=' * 80)
        logger.info(f'åˆ†æ event_count çš„ top{top_n}')
        logger.info('=' * 80)

        conn = None
        cursor = None

        try:
            conn = sqlite3.connect(str(self.perf_db_file))
            cursor = conn.cursor()

            # 1. åŠ è½½æ˜ å°„å…³ç³»
            logger.info('\næ­¥éª¤ 1: åŠ è½½æ˜ å°„å…³ç³»...')
            try:
                cursor.execute('SELECT DISTINCT file_id, path FROM perf_files WHERE path IS NOT NULL')
                file_id_to_path = {row[0]: row[1] for row in cursor.fetchall()}
                logger.info(f'[OK] åŠ è½½äº† {len(file_id_to_path):,} ä¸ªæ–‡ä»¶è·¯å¾„æ˜ å°„')
            except Exception as e:
                logger.info(f'[ERROR] åŠ è½½æ–‡ä»¶è·¯å¾„æ˜ å°„å¤±è´¥: {e}')
                raise

            try:
                cursor.execute('SELECT id, data FROM data_dict WHERE data IS NOT NULL')
                name_to_data = {row[0]: row[1] for row in cursor.fetchall()}
                logger.info(f'[OK] åŠ è½½äº† {len(name_to_data):,} ä¸ªåœ°å€æ•°æ®æ˜ å°„')
            except Exception as e:
                logger.info(f'[ERROR] åŠ è½½åœ°å€æ•°æ®æ˜ å°„å¤±è´¥: {e}')
                raise

            # 2. æŒ‰ event_count æ±‚å’Œç»Ÿè®¡ topN
            logger.info(f'\næ­¥éª¤ 2: æŒ‰ event_count æ±‚å’Œç»Ÿè®¡ top{top_n}...')
            try:
                # åœ¨å…³é—­è¿æ¥å‰è·å–æ‰€æœ‰æ•°æ®
                event_count_top = self._get_event_count_top100(cursor, file_id_to_path, name_to_data, top_n)
                logger.info(f'[OK] æ‰¾åˆ° {len(event_count_top)} ä¸ªåœ°å€ï¼ˆevent_count top{top_n}ï¼‰')
            except Exception:
                logger.exception('[ERROR] ç»Ÿè®¡ event_count å¤±è´¥')
                raise

            # 3. è½¬æ¢ä¸ºåˆ†æç»“æœæ ¼å¼ï¼Œå¹¶å¤„ç† HAP åœ°å€ï¼ˆåœ¨å…³é—­è¿æ¥ä¹‹å‰ï¼‰
            logger.info('\næ­¥éª¤ 3: å‡†å¤‡åˆ†ææ•°æ®...')
            try:
                results = []
                sorted_items = sorted(
                    event_count_top.items(),
                    key=lambda x: x[1]['event_count'],
                    reverse=True,
                )[:top_n]

                # 3.1 æ£€æµ‹å¹¶æ‰¹é‡è§£æ HAP åœ°å€
                hap_addresses = []
                for _key, info in sorted_items:
                    address = info['address']
                    # æ£€æµ‹ HAP åœ°å€
                    try:
                        from core.utils.hap_address_resolver import is_hap_address, resolve_hap_addresses_batch
                        if is_hap_address(address):
                            hap_addresses.append(address)
                    except ImportError:
                        pass  # HAP è§£ææ¨¡å—ä¸å¯ç”¨
                
                # æ‰¹é‡è§£æ HAP åœ°å€
                hap_resolutions = {}
                if hap_addresses:
                    try:
                        from core.utils.hap_address_resolver import resolve_hap_addresses_batch
                        from pathlib import Path
                        logger.info(f'æ£€æµ‹åˆ° {len(hap_addresses)} ä¸ª HAP åœ°å€ï¼Œå¼€å§‹æ‰¹é‡è§£æ...')
                        from pathlib import Path
                        so_dir = Path(self.so_dir) if self.so_dir else None
                        
                        hap_resolutions = resolve_hap_addresses_batch(Path(self.perf_db_file), hap_addresses, quick_mode=True, so_dir=so_dir)
                        resolved_count = sum(1 for r in hap_resolutions.values() if r.get("resolved"))
                        logger.info(f'âœ… HAP åœ°å€è§£æå®Œæˆï¼ŒæˆåŠŸè§£æ {resolved_count}/{len(hap_resolutions)} ä¸ª')
                        if resolved_count < len(hap_resolutions):
                            logger.warning(f'âš ï¸  æœ‰ {len(hap_resolutions) - resolved_count} ä¸ª HAP åœ°å€æ— æ³•è§£æï¼ˆåç§»é‡è¶…å‡ºæ–‡ä»¶å¤§å°ï¼‰')
                    except Exception as e:
                        logger.warning(f'âš ï¸  HAP åœ°å€è§£æå¤±è´¥: {e}')

                # 3.2 è½¬æ¢ä¸ºç»“æœæ ¼å¼
                for rank, (_key, info) in enumerate(sorted_items, 1):
                    address = info['address']
                    file_path = info['file_path']
                    
                    # å¤„ç† HAP åœ°å€è§£æç»“æœ
                    if address in hap_resolutions:
                        resolution = hap_resolutions[address]
                        if resolution.get('resolved') and resolution.get('so_file_path'):
                            # æ›´æ–°ä¸º SO æ–‡ä»¶è·¯å¾„å’Œåœ°å€
                            file_path = resolution['so_file_path']
                            address = f"{resolution['so_name']}+0x{resolution['so_offset']:x}"
                            logger.info(f'  âœ… HAP åœ°å€è§£æ: {info["address"]} -> {address}')
                        else:
                            # æ— æ³•è§£æçš„ HAP åœ°å€ï¼Œè·³è¿‡
                            logger.warning(f'  âš ï¸  HAP åœ°å€æ— æ³•è§£æï¼Œè·³è¿‡: {address}')
                            continue  # è·³è¿‡è¿™ä¸ªåœ°å€ï¼Œä¸æ·»åŠ åˆ° results ä¸­
                    
                    # æå–åç§»é‡ï¼ˆä» address ä¸­æå–ï¼Œæ ¼å¼å¦‚ "libxwebcore.so+0x50338a0"ï¼‰
                    offset = None
                    if '+' in address:
                        try:
                            offset_str = address.split('+')[-1]
                            offset = f'0x{offset_str}' if not offset_str.startswith('0x') else offset_str
                        except Exception:
                            offset = address
                    else:
                        offset = address

                    results.append(
                        {
                            'rank': rank,
                            'file_path': file_path,  # ä½¿ç”¨è§£æåçš„æ–‡ä»¶è·¯å¾„
                            'address': address,  # ä½¿ç”¨è§£æåçš„åœ°å€
                            'offset': offset,
                            'event_count': info['event_count'],
                            'call_count': info.get('call_count', 0),
                            'file_id': info['file_id'],
                            'name_id': info['name_id'],
                            'ip': info.get('ip', 0),
                            'depth': info.get('depth', 0),
                            'so_file': '',  # å°†åœ¨åç»­åˆ†æä¸­å¡«å……
                            'instruction_count': 0,  # å°†åœ¨åç»­åˆ†æä¸­å¡«å……
                            'strings': '',  # å°†åœ¨åç»­åˆ†æä¸­å¡«å……
                            'llm_result': None,  # å°†åœ¨åç»­åˆ†æä¸­å¡«å……
                        }
                    )
                logger.info(f'[OK] å‡†å¤‡äº† {len(results)} ä¸ªç»“æœ')
            except Exception:
                logger.exception('[ERROR] å‡†å¤‡åˆ†ææ•°æ®å¤±è´¥')
                raise
            finally:
                # å…³é—­æ•°æ®åº“è¿æ¥ï¼ˆåœ¨å‡†å¤‡å®Œæ•°æ®ä¹‹åï¼‰
                if conn:
                    conn.close()
                    conn = None
                    cursor = None

            # 4. è¿›è¡Œå‡½æ•°åˆ†æï¼ˆåæ±‡ç¼–å’Œå­—ç¬¦ä¸²æå–ï¼Œä»¥åŠå¯é€‰çš„ LLM åˆ†æï¼‰
            logger.info('\næ­¥éª¤ 4: è¿›è¡Œå‡½æ•°åˆ†æï¼ˆåæ±‡ç¼–ã€å­—ç¬¦ä¸²æå–å’Œ LLM åˆ†æï¼‰...')
            # è·å–è¾“å‡ºç›®å½•
            output_dir = config.get_output_dir()
            config.ensure_output_dir(output_dir)
            # åˆ›å»ºä¸´æ—¶ Excel æ–‡ä»¶ç”¨äºåˆ†æï¼ˆåŒ…å« event_count åˆ—ï¼‰
            temp_excel = output_dir / f'{config.TEMP_FILE_PREFIX}event_count.xlsx'
            temp_excel.parent.mkdir(exist_ok=True)
            temp_data = []
            for r in results:
                row = {
                    'æ–‡ä»¶è·¯å¾„': r['file_path'],
                    'åœ°å€': r['address'],
                    'è°ƒç”¨æ¬¡æ•°': r.get('call_count', 0),
                }
                # å¦‚æœå­˜åœ¨ event_countï¼Œä¹Ÿæ·»åŠ åˆ°ä¸´æ—¶ Excel ä¸­
                if 'event_count' in r and r.get('event_count', 0) > 0:
                    row['æŒ‡ä»¤æ•°(event_count)'] = r['event_count']
                temp_data.append(row)
            pd.DataFrame(temp_data).to_excel(temp_excel, index=False)

            # åˆ›å»ºåˆ†æå™¨ï¼ˆæ— è®ºæ˜¯å¦ä½¿ç”¨ LLMï¼Œéƒ½éœ€è¦è¿›è¡Œåæ±‡ç¼–å’Œå­—ç¬¦ä¸²æå–ï¼‰
            if self.llm_analyzer:
                # å¦‚æœå·²ç»æœ‰ LLM åˆ†æå™¨ï¼Œç›´æ¥å¤ç”¨ï¼›å¦åˆ™åˆ›å»ºæ–°çš„ï¼ˆä½†å¯èƒ½æ²¡æœ‰ LLMï¼‰
                analyzer = MissingSymbolFunctionAnalyzer(
                    skip_decompilation=self.skip_decompilation,
                    excel_file=str(temp_excel),
                    so_dir=str(self.so_dir) if self.so_dir else None,
                    so_file=str(self.so_file) if self.so_file else None,
                    use_llm=False,  # å…ˆä¸å¯ç”¨ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
                    llm_model=self.llm_model,
                    use_batch_llm=self.use_batch_llm,
                    batch_size=self.batch_size,
                    context=self.context,  # ä¼ é€’ä¸Šä¸‹æ–‡
                    use_capstone_only=self.use_capstone_only,
                )
                # å¤ç”¨å·²åˆå§‹åŒ–çš„ LLM åˆ†æå™¨ï¼Œå¹¶ç¡®ä¿ use_llm å’Œ use_batch_llm ä¸º Trueï¼ˆå¦‚æœå¯ç”¨ LLMï¼‰
                if self.use_llm:
                    analyzer.llm_analyzer = self.llm_analyzer
                    analyzer.use_llm = True
                    analyzer.use_batch_llm = self.use_batch_llm  # ç¡®ä¿æ‰¹é‡åˆ†æè®¾ç½®æ­£ç¡®
                    analyzer.batch_size = self.batch_size  # ç¡®ä¿ batch_size æ­£ç¡®
            else:
                # å¦‚æœæ²¡æœ‰ LLM åˆ†æå™¨ï¼Œæ­£å¸¸åˆ›å»ºï¼ˆä¼šå°è¯•åˆå§‹åŒ–ï¼‰
                analyzer = MissingSymbolFunctionAnalyzer(
                    skip_decompilation=self.skip_decompilation,
                    excel_file=str(temp_excel),
                    so_dir=str(self.so_dir) if self.so_dir else None,
                    so_file=str(self.so_file) if self.so_file else None,
                    use_llm=self.use_llm,
                    llm_model=self.llm_model,
                    use_batch_llm=self.use_batch_llm,
                    batch_size=self.batch_size,
                    context=self.context,  # ä¼ é€’ä¸Šä¸‹æ–‡
                    use_capstone_only=self.use_capstone_only,
                )

            # ä½¿ç”¨ analyze_top_functions è¿›è¡Œåˆ†æï¼ˆä¼šè¿›è¡Œåæ±‡ç¼–ã€å­—ç¬¦ä¸²æå–å’Œå¯é€‰çš„ LLM åˆ†æï¼‰
            analyzed_results = analyzer.analyze_top_functions(top_n=len(results))

            # å°† event_count å’Œ call_count æ·»åŠ åˆ°ç»“æœä¸­ï¼ˆå› ä¸º analyze_top_functions å¯èƒ½ä¸åŒ…å«è¿™äº›å­—æ®µï¼‰
            event_count_map = {r['address']: r['event_count'] for r in results}
            call_count_map = {r['address']: r.get('call_count', 0) for r in results}
            for result in analyzed_results:
                address = result.get('address', '')
                if address in event_count_map:
                    result['event_count'] = event_count_map[address]
                if address in call_count_map:
                    result['call_count'] = call_count_map[address]
            # æ³¨æ„ï¼šå­—ç¬¦ä¸²å¸¸é‡å·²ç»åœ¨ analyze_top_functions -> analyze_function ä¸­æå–äº†

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            if temp_excel.exists():
                temp_excel.unlink()

            return analyzed_results

        except Exception:
            logger.exception('[ERROR] analyze_event_count_only æ‰§è¡Œå¤±è´¥')
            raise
        finally:
            if conn:
                try:
                    conn.close()
                except Exception as e:
                    logger.info(f'[WARN] å…³é—­æ•°æ®åº“è¿æ¥æ—¶å‡ºé”™: {e}')
                    pass

    def save_event_count_results(self, results, time_tracker=None, output_dir=None, top_n=None):
        """ä¿å­˜ event_count åˆ†æç»“æœ

        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            time_tracker: æ—¶é—´è·Ÿè¸ªå™¨ï¼ˆå¯é€‰ï¼‰
            output_dir: è¾“å‡ºç›®å½•ï¼ˆå¯é€‰ï¼Œé»˜è®¤ä½¿ç”¨é…ç½®ä¸­çš„è¾“å‡ºç›®å½•ï¼‰
            top_n: ç”¨æˆ·æŒ‡å®šçš„åˆ†ææ•°é‡ï¼ˆç”¨äºç”Ÿæˆæ–‡ä»¶åï¼Œå¦‚æœä¸æä¾›åˆ™ä½¿ç”¨å®é™…ç»“æœæ•°é‡ï¼‰
        """
        try:
            # è·å–è¾“å‡ºç›®å½•
            output_dir = config.get_output_dir() if output_dir is None else Path(output_dir)
            config.ensure_output_dir(output_dir)
            # ç¡®ä¿ results æŒ‰ event_count æ’åºï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            # å› ä¸ºåç»­çš„ save_results å¯èƒ½ä¼šé‡æ–°æ’åºï¼Œæˆ‘ä»¬éœ€è¦ç¡®ä¿é¡ºåºæ­£ç¡®
            if results and any('event_count' in r and r.get('event_count', 0) > 0 for r in results):
                # æŒ‰ event_count é™åºæ’åº
                results = sorted(results, key=lambda x: x.get('event_count', 0), reverse=True)
                # æ›´æ–°æ’å
                for rank, result in enumerate(results, 1):
                    result['rank'] = rank

            # åˆ›å»ºä¸´æ—¶ Excel æ–‡ä»¶ç”¨äºä¿å­˜
            temp_excel = output_dir / f'{config.TEMP_FILE_PREFIX}event_count.xlsx'
            temp_excel.parent.mkdir(exist_ok=True)

            # åˆ›å»ºä¸´æ—¶ Excel æ–‡ä»¶æ—¶ï¼ŒåŒ…å« event_count å­—æ®µï¼ˆå¦‚æœå­˜åœ¨ï¼‰
            temp_data = []
            for r in results:
                row = {
                    'æ–‡ä»¶è·¯å¾„': r['file_path'],
                    'åœ°å€': r['address'],
                    'è°ƒç”¨æ¬¡æ•°': r.get('call_count', 0),
                }
                # å¦‚æœå­˜åœ¨ event_countï¼Œä¹Ÿæ·»åŠ åˆ°ä¸´æ—¶ Excel ä¸­ï¼Œä»¥ä¾¿åç»­æŒ‰ event_count æ’åº
                if 'event_count' in r and r.get('event_count', 0) > 0:
                    row['æŒ‡ä»¤æ•°(event_count)'] = r['event_count']
                temp_data.append(row)

            # ç¡®ä¿æ–‡ä»¶å†™å…¥å®Œæˆ
            try:
                df_temp = pd.DataFrame(temp_data)
                df_temp.to_excel(temp_excel, index=False, engine='openpyxl')
                # ç¡®ä¿æ–‡ä»¶å·²å…³é—­
                gc.collect()
            except Exception as e:
                logger.info(f'[ERROR] åˆ›å»ºä¸´æ—¶ Excel æ–‡ä»¶å¤±è´¥: {e}')
                raise

            # å¦‚æœå·²ç»æœ‰ LLM åˆ†æå™¨ï¼Œç›´æ¥å¤ç”¨ï¼›å¦åˆ™åˆ›å»ºæ–°çš„ï¼ˆä½†å¯èƒ½æ²¡æœ‰ LLMï¼‰
            if self.llm_analyzer:
                # åˆ›å»ºæ—¶å…ˆä¸å¯ç”¨ LLMï¼Œé¿å…é‡å¤åˆå§‹åŒ–
                analyzer = MissingSymbolFunctionAnalyzer(
                    skip_decompilation=self.skip_decompilation,
                    excel_file=str(temp_excel),
                    so_dir=str(self.so_dir) if self.so_dir else None,
                    so_file=str(self.so_file) if self.so_file else None,
                    use_llm=False,  # å…ˆä¸å¯ç”¨ï¼Œé¿å…é‡å¤åˆå§‹åŒ–
                    llm_model=self.llm_model,
                    use_capstone_only=self.use_capstone_only,
                )
                # å¤ç”¨å·²åˆå§‹åŒ–çš„ LLM åˆ†æå™¨ï¼Œå¹¶ç¡®ä¿ use_llm å’Œ use_batch_llm ä¸º True
                analyzer.llm_analyzer = self.llm_analyzer
                analyzer.use_llm = True
                analyzer.use_batch_llm = self.use_batch_llm  # ç¡®ä¿æ‰¹é‡åˆ†æè®¾ç½®æ­£ç¡®
                analyzer.batch_size = self.batch_size  # ç¡®ä¿ batch_size æ­£ç¡®
            else:
                # å¦‚æœæ²¡æœ‰ LLM åˆ†æå™¨ï¼Œæ­£å¸¸åˆ›å»ºï¼ˆä¼šå°è¯•åˆå§‹åŒ–ï¼‰
                analyzer = MissingSymbolFunctionAnalyzer(
                    skip_decompilation=self.skip_decompilation,
                    excel_file=str(temp_excel),
                    so_dir=str(self.so_dir) if self.so_dir else None,
                    so_file=str(self.so_file) if self.so_file else None,
                    use_llm=self.use_llm,
                    llm_model=self.llm_model,
                    use_batch_llm=self.use_batch_llm,  # ä¼ é€’æ‰¹é‡åˆ†æè®¾ç½®
                    batch_size=self.batch_size,  # ä¼ é€’ batch_size
                    use_capstone_only=self.use_capstone_only,
                )

            # ç¡®å®šè¾“å‡ºæ–‡ä»¶åï¼ˆä½¿ç”¨ç”¨æˆ·æŒ‡å®šçš„ top_nï¼Œå¦‚æœæ²¡æœ‰åˆ™ä½¿ç”¨å®é™…ç»“æœæ•°é‡ï¼‰
            if top_n is None:
                top_n = len(results)
            output_file = str(output_dir / config.EVENT_COUNT_ANALYSIS_PATTERN.format(n=top_n))
            html_file = str(output_dir / config.EVENT_COUNT_REPORT_PATTERN.format(n=top_n))

            # ä¿å­˜ Excel ç»“æœå’Œç”Ÿæˆ HTML æŠ¥å‘Šï¼ˆä¼ é€’ time_trackerã€html_file å’Œ output_dirï¼‰
            saved_file = analyzer.save_results(
                results,
                output_file=output_file,
                html_file=html_file,
                time_tracker=time_tracker,
                output_dir=output_dir,
            )

            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            try:
                if temp_excel.exists():
                    temp_excel.unlink()
            except Exception as e:
                logger.info(f'[WARN] æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {e}')

            return saved_file
        except Exception:
            logger.exception('[ERROR] save_event_count_results å¤±è´¥')
            raise
