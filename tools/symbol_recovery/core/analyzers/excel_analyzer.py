#!/usr/bin/env python3

"""
ä» Excel æ–‡ä»¶è¯»å–åç§»é‡åœ°å€è¿›è¡Œåˆ†æ
è¾“å…¥ï¼šsoæ–‡ä»¶ + Excel æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«å‡½æ•°åç§»é‡åœ°å€ï¼‰
è¾“å‡ºï¼šåˆ†æç»“æœçš„excelæ–‡ä»¶ + HTMLæŠ¥å‘Š
"""

from pathlib import Path
from typing import Any, Optional

import pandas as pd
from elftools.elf.elffile import ELFFile

from core.llm.initializer import init_llm_analyzer
from core.utils import common as util
from core.utils.config import (
    DEFAULT_BATCH_SIZE,
    DEFAULT_LLM_MODEL,
    EXCEL_ANALYSIS_PATTERN,
    EXCEL_REPORT_PATTERN,
    config,
)
from core.utils.logger import get_logger
from core.utils.string_extractor import StringExtractor
from core.utils.time_tracker import TimeTracker

logger = get_logger(__name__)


class ExcelOffsetAnalyzer:
    """ä» Excel æ–‡ä»¶è¯»å–åç§»é‡åœ°å€è¿›è¡Œåˆ†æ"""

    def __init__(
        self,
        so_file: str,
        excel_file: str,
        use_llm: bool = True,
        llm_model: str = None,
        batch_size: int = None,
        context: str = None,
        save_prompts: bool = False,
        output_dir: str = None,
        skip_decompilation: bool = False,
    ):
        """
        åˆå§‹åŒ–åˆ†æå™¨

        Args:
            so_file: SO æ–‡ä»¶è·¯å¾„
            excel_file: Excel æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«å‡½æ•°åç§»é‡åœ°å€ï¼‰
            use_llm: æ˜¯å¦ä½¿ç”¨ LLM åˆ†æ
            llm_model: LLM æ¨¡å‹åç§°
            use_batch_llm: æ˜¯å¦ä½¿ç”¨æ‰¹é‡ LLM åˆ†æ
            batch_size: æ‰¹é‡åˆ†ææ—¶æ¯ä¸ª prompt åŒ…å«çš„å‡½æ•°æ•°é‡
            context: è‡ªå®šä¹‰ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¯é€‰ï¼Œå¦‚æœä¸æä¾›åˆ™æ ¹æ® SO æ–‡ä»¶åè‡ªåŠ¨æ¨æ–­ï¼‰
            save_prompts: æ˜¯å¦ä¿å­˜ç”Ÿæˆçš„ prompt åˆ°æ–‡ä»¶
            output_dir: è¾“å‡ºç›®å½•ï¼Œç”¨äºä¿å­˜ prompt æ–‡ä»¶
            skip_decompilation: æ˜¯å¦è·³è¿‡åç¼–è¯‘ï¼ˆé»˜è®¤ Falseï¼Œå¯ç”¨åç¼–è¯‘å¯æé«˜ LLM åˆ†æè´¨é‡ä½†è¾ƒæ…¢ï¼‰
        """
        self.so_file = Path(so_file)
        self.excel_file = Path(excel_file)
        self.use_llm = use_llm
        self.llm_model = llm_model if llm_model is not None else DEFAULT_LLM_MODEL
        self.batch_size = batch_size if batch_size is not None else DEFAULT_BATCH_SIZE
        self.context = context  # è‡ªå®šä¹‰ä¸Šä¸‹æ–‡

        if not self.so_file.exists():
            raise FileNotFoundError(f'SO æ–‡ä»¶ä¸å­˜åœ¨: {so_file}')
        if not self.excel_file.exists():
            raise FileNotFoundError(f'Excel æ–‡ä»¶ä¸å­˜åœ¨: {excel_file}')

        # åˆå§‹åŒ–åæ±‡ç¼–å™¨
        self.md = util.create_disassembler()

        # åˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆç¨åè®¾ç½® disassemble_funcï¼‰
        self.string_extractor = None

        # åˆå§‹åŒ– LLM åˆ†æå™¨
        self.llm_analyzer, self.use_llm, self.use_batch_llm = init_llm_analyzer(
            use_llm=self.use_llm,
            llm_model=self.llm_model,
            batch_size=self.batch_size,
            save_prompts=save_prompts,
            output_dir=output_dir,
        )

    def parse_offset(self, offset_str: str) -> Optional[int]:
        """è§£æåç§»é‡å­—ç¬¦ä¸²ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„ util.parse_offsetï¼‰"""
        return util.parse_offset(offset_str)

    def load_offsets_from_excel(self) -> list[dict[str, Any]]:
        """
        ä» Excel æ–‡ä»¶åŠ è½½åç§»é‡åœ°å€

        Returns:
            åç§»é‡åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« {'offset': int, 'row_data': dict}
        """
        logger.info(f'\nğŸ“– è¯»å– Excel æ–‡ä»¶: {self.excel_file}')

        try:
            df = pd.read_excel(self.excel_file, engine='openpyxl')
            logger.info(f'âœ… æˆåŠŸè¯»å– Excel æ–‡ä»¶ï¼Œå…± {len(df)} è¡Œ')
        except Exception as e:
            logger.error('âŒ è¯»å– Excel æ–‡ä»¶å¤±è´¥: %s', e)
            return []

        # æŸ¥æ‰¾åç§»é‡åˆ—ï¼ˆå¯èƒ½çš„åˆ—åï¼‰
        offset_column = None
        for col in df.columns:
            col_lower = str(col).lower()
            if 'offset' in col_lower or 'åç§»' in col_lower or 'åœ°å€' in col_lower or 'address' in col_lower:
                offset_column = col
                break

        if offset_column is None:
            logger.warning('âš ï¸  æœªæ‰¾åˆ°åç§»é‡åˆ—ï¼Œå°è¯•ä½¿ç”¨ç¬¬ä¸€åˆ—')
            offset_column = df.columns[0]

        logger.info(f'ğŸ“‹ ä½¿ç”¨åˆ—: {offset_column}')

        # è§£æåç§»é‡
        offsets = []
        for idx, row in df.iterrows():
            offset_str = row.get(offset_column, '')
            offset = self.parse_offset(offset_str)

            if offset is not None:
                offsets.append(
                    {
                        'offset': offset,
                        'offset_str': f'0x{offset:x}',
                        'row_index': idx,
                        'row_data': row.to_dict(),
                    }
                )
            else:
                logger.warning('âš ï¸  ç¬¬ %s è¡Œåç§»é‡è§£æå¤±è´¥: %s', idx + 1, offset_str)

        logger.info(f'âœ… æˆåŠŸè§£æ {len(offsets)} ä¸ªåç§»é‡')
        return offsets

    def find_function_start(self, elf_file: ELFFile, vaddr: int) -> int:
        """æŸ¥æ‰¾å‡½æ•°çš„èµ·å§‹ä½ç½®ï¼ˆä½¿ç”¨ç»Ÿä¸€çš„ util.find_function_startï¼‰"""
        return util.find_function_start(elf_file, vaddr, self.md)

    def disassemble_function(self, elf_file: ELFFile, vaddr: int, size: int = 2000):
        """åæ±‡ç¼–æŒ‡å®šè™šæ‹Ÿåœ°å€çš„å‡½æ•°ä»£ç 

        Args:
            elf_file: ELF æ–‡ä»¶å¯¹è±¡
            vaddr: å‡½æ•°è™šæ‹Ÿåœ°å€
            size: æœ€å¤§åæ±‡ç¼–å¤§å°ï¼ˆé»˜è®¤ 2000 å­—èŠ‚ï¼Œå¢åŠ ä»¥æ”¯æŒå¤§å‹å‡½æ•°ï¼‰
        """
        try:
            # è·å– .text æ®µ
            text_section = None
            for section in elf_file.iter_sections():
                if section.name == '.text':
                    text_section = section
                    break

            if not text_section:
                return None

            text_vaddr = text_section['sh_addr']
            text_size = text_section['sh_size']

            # ç¡®ä¿åœ°å€åœ¨ .text æ®µå†…
            if vaddr < text_vaddr or vaddr >= text_vaddr + text_size:
                logger.warning('âš ï¸  åœ°å€ 0x%s ä¸åœ¨ .text æ®µå†…', f'{vaddr:x}')
                return None

            # æŸ¥æ‰¾å‡½æ•°èµ·å§‹ä½ç½®
            func_start = self.find_function_start(elf_file, vaddr)

            # å°è¯•ä»ç¬¦å·è¡¨è·å–å‡½æ•°å¤§å°ï¼ˆå¦‚æœå¯ç”¨ï¼‰
            func_size = None
            try:
                # æŸ¥æ‰¾ .dynsym æˆ– .symtab ç¬¦å·è¡¨
                for section_name in ['.dynsym', '.symtab']:
                    symbol_table = elf_file.get_section_by_name(section_name)
                    if symbol_table:
                        for symbol in symbol_table.iter_symbols():
                            if symbol['st_info']['type'] == 'STT_FUNC':
                                sym_addr = symbol['st_value']
                                sym_size = symbol['st_size']
                                # æ£€æŸ¥åœ°å€æ˜¯å¦åœ¨è¿™ä¸ªç¬¦å·èŒƒå›´å†…
                                if sym_size > 0 and sym_addr <= vaddr < sym_addr + sym_size:
                                    func_size = sym_size
                                    logger.info(f'ä»ç¬¦å·è¡¨è·å–å‡½æ•°å¤§å°: {func_size} å­—èŠ‚ (ç¬¦å·: {symbol.name})')
                                    break
                    if func_size:
                        break
            except Exception:
                # ç¬¦å·è¡¨æŸ¥æ‰¾å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤å¤§å°
                pass

            # è®¡ç®—ç›¸å¯¹åç§»é‡
            relative_start = func_start - text_vaddr
            if func_size:
                # ä½¿ç”¨ç¬¦å·è¡¨ä¸­çš„å‡½æ•°å¤§å°ï¼Œä½†ä¸è¶…è¿‡ size é™åˆ¶
                relative_end = min(relative_start + func_size, relative_start + size, text_size)
            else:
                relative_end = min(relative_start + size, text_size)

            # è¯»å–ä»£ç 
            code = text_section.data()[relative_start:relative_end]

            if not code:
                return None

            # åæ±‡ç¼–
            instructions = []
            ret_count = 0  # è®°å½•é‡åˆ°çš„ ret æŒ‡ä»¤æ•°é‡
            consecutive_ret = 0  # è¿ç»­ ret æŒ‡ä»¤è®¡æ•°

            for inst in self.md.disasm(code, func_start):
                instructions.append(inst)

                # æ”¹è¿›çš„åœæ­¢æ¡ä»¶ï¼š
                # 1. å¦‚æœé‡åˆ° ret æŒ‡ä»¤ï¼Œè®°å½•ä½†ä¸ç«‹å³åœæ­¢
                # 2. å¦‚æœè¿ç»­é‡åˆ°å¤šä¸ª retï¼ˆå¯èƒ½æ˜¯å‡½æ•°ç»“æŸæ ‡è®°ï¼‰ï¼Œä¸”å·²åæ±‡ç¼–è¶³å¤ŸæŒ‡ä»¤ï¼Œåˆ™åœæ­¢
                # 3. å¦‚æœé‡åˆ° ret ä¸”å·²ç»åæ±‡ç¼–äº†å¤§éƒ¨åˆ†å‡½æ•°ï¼ˆè¶…è¿‡ 80%ï¼‰ï¼Œåˆ™åœæ­¢
                if inst.mnemonic == 'ret':
                    ret_count += 1
                    consecutive_ret += 1
                    # å¦‚æœè¿ç»­é‡åˆ° 2 ä¸ª retï¼Œä¸”å·²åæ±‡ç¼–è¶…è¿‡ 300 æ¡æŒ‡ä»¤ï¼ˆçº¦ 1200 å­—èŠ‚ï¼‰ï¼Œå¯èƒ½æ˜¯å‡½æ•°ç»“æŸ
                    # æ³¨æ„ï¼šARM64 æŒ‡ä»¤é€šå¸¸æ˜¯ 4 å­—èŠ‚ï¼Œ300 æ¡æŒ‡ä»¤ â‰ˆ 1200 å­—èŠ‚
                    # è¿™ä¸ªé˜ˆå€¼é€‚ç”¨äºå¤§å¤šæ•°å‡½æ•°ï¼Œä½†å¤æ‚å‡½æ•°å¯èƒ½è¶…è¿‡è¿™ä¸ªå€¼
                    if consecutive_ret >= 2 and len(instructions) > 300:
                        break
                    # å¦‚æœé‡åˆ° ret ä¸”å·²åæ±‡ç¼–è¶…è¿‡ size çš„ 80%ï¼Œå¯èƒ½æ˜¯å‡½æ•°ç»“æŸ
                    if len(instructions) * 4 > (relative_end - relative_start) * 0.8:
                        break
                else:
                    consecutive_ret = 0  # é‡ç½®è¿ç»­ ret è®¡æ•°

                # å¦‚æœå·²ç»åæ±‡ç¼–äº†è¶³å¤Ÿå¤šçš„æŒ‡ä»¤ï¼ˆè¶…è¿‡ size é™åˆ¶ï¼‰ï¼Œåœæ­¢
                if len(instructions) * 4 > (relative_end - relative_start):
                    break

            return instructions
        except Exception:
            logger.exception('åæ±‡ç¼–å¤±è´¥ (vaddr=0x%x)', vaddr)
            return None

    def _init_string_extractor(self):
        """å»¶è¿Ÿåˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆéœ€è¦å…ˆå®šä¹‰ disassemble_functionï¼‰"""
        if self.string_extractor is None:
            self.string_extractor = StringExtractor(disassemble_func=self.disassemble_function, md=self.md)

    def extract_strings_near_offset(self, elf_file: ELFFile, vaddr: int, instructions: list = None):
        """
        æå–è™šæ‹Ÿåœ°å€é™„è¿‘çš„å­—ç¬¦ä¸²å¸¸é‡ï¼ˆä½¿ç”¨é€šç”¨å­—ç¬¦ä¸²æå–å™¨ï¼‰

        Args:
            elf_file: ELF æ–‡ä»¶å¯¹è±¡
            vaddr: å‡½æ•°è™šæ‹Ÿåœ°å€
            instructions: åæ±‡ç¼–æŒ‡ä»¤åˆ—è¡¨ï¼ˆå¦‚æœä¸º Noneï¼Œå°†é‡æ–°åæ±‡ç¼–ï¼‰

        Returns:
            å­—ç¬¦ä¸²å¸¸é‡åˆ—è¡¨
        """
        # åˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
        self._init_string_extractor()

        # ä½¿ç”¨é€šç”¨çš„å­—ç¬¦ä¸²æå–å™¨
        return self.string_extractor.extract_strings_near_offset(elf_file, vaddr, instructions)

    def analyze_offset(self, offset: int, rank: int) -> Optional[dict[str, Any]]:
        """
        åˆ†æå•ä¸ªåç§»é‡

        Args:
            offset: åç§»é‡ï¼ˆè™šæ‹Ÿåœ°å€ï¼‰
            rank: æ’å

        Returns:
            åˆ†æç»“æœå­—å…¸
        """
        logger.info(f'\n{"=" * 80}')
        logger.info(f'åˆ†æå‡½æ•° #{rank}: åç§»é‡ 0x{offset:x}')
        logger.info(f'{"=" * 80}')

        try:
            with open(self.so_file, 'rb') as f:
                elf_file = ELFFile(f)

                # åæ±‡ç¼–å‡½æ•°
                instructions = self.disassemble_function(elf_file, offset)
                if not instructions:
                    logger.warning('âš ï¸  æ— æ³•åæ±‡ç¼–åç§»é‡ 0x%s', f'{offset:x}')
                    return None

                logger.info(f'âœ… åæ±‡ç¼–æˆåŠŸï¼Œå…± {len(instructions)} æ¡æŒ‡ä»¤')

                # åˆå§‹åŒ–å­—ç¬¦ä¸²æå–å™¨ï¼ˆå¦‚æœè¿˜æ²¡æœ‰åˆå§‹åŒ–ï¼‰
                self._init_string_extractor()

                # æå–å­—ç¬¦ä¸²ï¼ˆä¼ å…¥æŒ‡ä»¤åˆ—è¡¨ä»¥è¿›è¡Œç²¾å‡†åˆ†æï¼‰
                strings = []  # åˆå§‹åŒ–ä¸ºç©ºåˆ—è¡¨ï¼Œç¡®ä¿å§‹ç»ˆæœ‰å€¼
                try:
                    extracted_strings = self.string_extractor.extract_strings_from_instructions(
                        elf_file, instructions, offset
                    )
                    if extracted_strings:
                        strings = extracted_strings
                        logger.info(
                            f'æ‰¾åˆ° {len(strings)} ä¸ªå­—ç¬¦ä¸²å¸¸é‡: {", ".join(strings[:3])}{"..." if len(strings) > 3 else ""}'
                        )
                    else:
                        logger.warning('âš ï¸  æœªæ‰¾åˆ°å­—ç¬¦ä¸²å¸¸é‡')
                        # å¦‚æœç²¾å‡†æå–æ²¡æœ‰æ‰¾åˆ°ï¼Œå°è¯• fallback
                        fallback_strings = self.string_extractor._fallback_extract_strings(elf_file)
                        if fallback_strings:
                            strings = fallback_strings
                            logger.info(
                                f'ä½¿ç”¨ fallback æ–¹æ³•æ‰¾åˆ° {len(strings)} ä¸ªå­—ç¬¦ä¸²å¸¸é‡: {", ".join(strings[:3])}{"..." if len(strings) > 3 else ""}'
                            )
                except Exception:
                    logger.exception('âš ï¸  å­—ç¬¦ä¸²æå–å¤±è´¥')
                strings = []  # ç¡®ä¿ strings æœ‰é»˜è®¤å€¼

                # ç¡®ä¿ strings æ˜¯åˆ—è¡¨ç±»å‹
                if not isinstance(strings, list):
                    strings = []

                # LLM åˆ†æ
                llm_result = None
                if self.use_llm and self.llm_analyzer:
                    logger.info('ğŸ¤– å¼€å§‹ LLM åˆ†æ...')
                    try:
                        # æ„å»ºä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆå¦‚æœæä¾›äº†è‡ªå®šä¹‰ä¸Šä¸‹æ–‡åˆ™ä½¿ç”¨ï¼Œå¦åˆ™æ ¹æ® SO æ–‡ä»¶è‡ªåŠ¨æ¨æ–­ï¼‰
                        context = self.context if self.context else self._build_context(offset, strings)

                        llm_result = self.llm_analyzer.analyze_with_llm(
                            instructions=[f'{inst.address:x}: {inst.mnemonic} {inst.op_str}' for inst in instructions],
                            strings=strings,
                            symbol_name=None,
                            called_functions=[],
                            offset=offset,
                            context=context,
                        )
                        if llm_result:
                            logger.info('âœ… LLM åˆ†æå®Œæˆ')
                            if 'function_name' in llm_result:
                                logger.info(f'   æ¨æ–­å‡½æ•°å: {llm_result["function_name"]}')
                    except Exception as e:
                        logger.warning('âš ï¸  LLM åˆ†æå¤±è´¥: %s', e)

                return {
                    'rank': rank,
                    'offset': f'0x{offset:x}',
                    'offset_int': offset,
                    'so_file': str(self.so_file),
                    'instruction_count': len(instructions),
                    'strings': ', '.join(strings) if strings else '',
                    'llm_result': llm_result,
                    'function_name': llm_result.get('function_name', '') if llm_result else '',
                    'function_description': llm_result.get('functionality', '')
                    if llm_result
                    else '',  # LLM è¿”å›çš„æ˜¯ 'functionality'
                    'confidence': llm_result.get('confidence', '') if llm_result else '',
                    'instructions': [
                        f'{inst.address:x}: {inst.mnemonic} {inst.op_str}' for inst in instructions[:50]
                    ],  # åªä¿å­˜å‰50æ¡
                }
        except Exception:
            logger.exception('âŒ åˆ†æåç§»é‡ 0x%s å¤±è´¥', f'{offset:x}')
            return None

    def _build_context(self, offset: int, strings: list[str] = None) -> str:
        """
        æ„å»º LLM åˆ†æçš„ä¸Šä¸‹æ–‡ä¿¡æ¯ï¼ˆä¸ llm_prompt_simple_example.txt æ ¼å¼ä¿æŒä¸€è‡´ï¼‰

        Args:
            offset: å‡½æ•°åç§»é‡ï¼ˆç”¨äºå†…éƒ¨é€»è¾‘ï¼Œä¸åŒ…å«åœ¨è¿”å›çš„ä¸Šä¸‹æ–‡ä¸­ï¼‰
            strings: å‡½æ•°é™„è¿‘çš„å­—ç¬¦ä¸²å¸¸é‡åˆ—è¡¨ï¼ˆç”¨äºå†…éƒ¨é€»è¾‘ï¼Œä¸åŒ…å«åœ¨è¿”å›çš„ä¸Šä¸‹æ–‡ä¸­ï¼‰

        Returns:
            ä¸Šä¸‹æ–‡å­—ç¬¦ä¸²ï¼ˆç®€æ´æ ¼å¼ï¼ŒåªåŒ…å«åº“çš„ç±»å‹ã€åç§°ã€å¹³å°å’Œä¸»è¦åŠŸèƒ½ï¼‰
        """
        so_name = self.so_file.name.lower()
        so_file_name = self.so_file.name

        # æ ¹æ® SO æ–‡ä»¶åæ¨æ–­åº“çš„ç±»å‹å’Œç”¨é€”ï¼Œæ ¼å¼ä¸ç¤ºä¾‹ä¿æŒä¸€è‡´
        if 'xwebcore' in so_name or 'xweb' in so_name:
            return (
                f'è¿™æ˜¯ä¸€ä¸ªåŸºäº Chromium Embedded Framework (CEF) çš„ Web æ ¸å¿ƒåº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'è¿è¡Œåœ¨ HarmonyOS å¹³å°ä¸Šã€‚è¯¥åº“è´Ÿè´£ç½‘é¡µæ¸²æŸ“ã€ç½‘ç»œè¯·æ±‚ã€DOM æ“ä½œç­‰æ ¸å¿ƒåŠŸèƒ½ã€‚'
            )
        if 'wechat' in so_name or 'wx' in so_name:
            return (
                f'è¿™æ˜¯ä¸€ä¸ªæ¥è‡ªå¾®ä¿¡ï¼ˆWeChatï¼‰åº”ç”¨çš„ SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'è¿è¡Œåœ¨ HarmonyOS å¹³å°ä¸Šã€‚è¯¥åº“è´Ÿè´£å³æ—¶é€šè®¯ã€ç¤¾äº¤ç½‘ç»œã€å¤šåª’ä½“å¤„ç†ç­‰åŠŸèƒ½ã€‚'
            )
        if 'taobao' in so_name or 'tb' in so_name:
            return (
                f'è¿™æ˜¯ä¸€ä¸ªæ¥è‡ªæ·˜å®ï¼ˆTaobaoï¼‰åº”ç”¨çš„ SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'è¿è¡Œåœ¨ HarmonyOS å¹³å°ä¸Šã€‚è¯¥åº“è´Ÿè´£ç”µå•†è´­ç‰©ã€å•†å“å±•ç¤ºã€æ”¯ä»˜å¤„ç†ç­‰åŠŸèƒ½ã€‚'
            )
        if 'chromium' in so_name or 'blink' in so_name or 'v8' in so_name:
            return (
                f'è¿™æ˜¯ä¸€ä¸ªåŸºäº Chromium/Blink å¼•æ“çš„ç»„ä»¶åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'é€šå¸¸ç”¨äº Web æ¸²æŸ“ã€JavaScript æ‰§è¡Œç­‰ Web ç›¸å…³åŠŸèƒ½ã€‚'
            )
        if 'flutter' in so_name:
            return (
                f'è¿™æ˜¯ä¸€ä¸ª Flutter æ¡†æ¶ç›¸å…³çš„ SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œ'
                f'Flutter æ˜¯ Google å¼€å‘çš„è·¨å¹³å° UI æ¡†æ¶ï¼Œç”¨äºæ„å»ºç§»åŠ¨åº”ç”¨ç•Œé¢ã€‚'
            )
        # é€šç”¨æ ¼å¼
        return f'è¿™æ˜¯ä¸€ä¸ª SO åº“ï¼ˆ{so_file_name}ï¼‰ï¼Œæ¥è‡ª {self.so_file.parent.name} ç›®å½•ã€‚'

    def analyze_all(self, progress_callback=None) -> list[dict[str, Any]]:
        """
        åˆ†ææ‰€æœ‰åç§»é‡

        Args:
            progress_callback: è¿›åº¦å›è°ƒå‡½æ•°

        Returns:
            åˆ†æç»“æœåˆ—è¡¨
        """
        # åŠ è½½åç§»é‡
        offsets_data = self.load_offsets_from_excel()
        if not offsets_data:
            logger.error('âŒ æ²¡æœ‰æ‰¾åˆ°æœ‰æ•ˆçš„åç§»é‡')
            return []

        # åˆ†ææ¯ä¸ªåç§»é‡
        results = []
        total_offsets = len(offsets_data)
        logger.info(f'å…± {total_offsets} ä¸ªåç§»é‡éœ€è¦åˆ†æ')

        for idx, offset_data in enumerate(offsets_data, 1):
            if progress_callback:
                progress_callback(idx, f'åˆ†æåç§»é‡ {offset_data["offset_str"]}')

            result = self.analyze_offset(offset_data['offset'], idx)
            if result:
                # æ·»åŠ åŸå§‹è¡Œæ•°æ®
                result['original_row'] = offset_data['row_data']
                results.append(result)

        # åˆ†æå®Œæˆåï¼Œä¿å­˜æ‰€æœ‰ç¼“å­˜å’Œç»Ÿè®¡
        if self.use_llm and self.llm_analyzer:
            self.llm_analyzer.finalize()

        return results

    def save_results(self, results: list[dict[str, Any]], output_file: Optional[str] = None) -> str:
        """
        ä¿å­˜åˆ†æç»“æœåˆ° Excel æ–‡ä»¶

        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰

        Returns:
            è¾“å‡ºæ–‡ä»¶è·¯å¾„
        """
        if output_file is None:
            output_dir = config.get_output_dir()
            config.ensure_output_dir(output_dir)
            output_file = str(output_dir / EXCEL_ANALYSIS_PATTERN.format(n=len(results)))

        output_file = Path(output_file)
        output_file.parent.mkdir(parents=True, exist_ok=True)

        logger.info(f'\nğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_file}')

        # å‡†å¤‡æ•°æ®
        data = []
        for result in results:
            row = {
                'æ’å': result['rank'],
                'åç§»é‡': result['offset'],
                'SOæ–‡ä»¶': result['so_file'],
                'æŒ‡ä»¤æ•°': result['instruction_count'],
                'å­—ç¬¦ä¸²å¸¸é‡': result['strings'],
            }

            if result.get('llm_result'):
                # æ ¼å¼åŒ–å‡½æ•°åï¼Œæ·»åŠ  "Function: " å‰ç¼€
                function_name = result.get('function_name', '')
                if (
                    function_name
                    and function_name not in {'nan', 'None'}
                    and not function_name.startswith('Function: ')
                ):
                    function_name = f'Function: {function_name}'
                row['LLMæ¨æ–­å‡½æ•°å'] = function_name
                row['å‡½æ•°åŠŸèƒ½æè¿°'] = result.get('function_description', '')
                row['ç½®ä¿¡åº¦'] = result.get('confidence', '')
            else:
                row['LLMæ¨æ–­å‡½æ•°å'] = ''
                row['å‡½æ•°åŠŸèƒ½æè¿°'] = ''
                row['ç½®ä¿¡åº¦'] = ''

            # æ·»åŠ åŸå§‹ Excel ä¸­çš„å…¶ä»–åˆ—
            if 'original_row' in result:
                for key, value in result['original_row'].items():
                    if key not in row:
                        row[f'åŸå§‹_{key}'] = value

            data.append(row)

        # åˆ›å»º DataFrame
        df = pd.DataFrame(data)

        # ä¿å­˜åˆ° Excel
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            df.to_excel(writer, index=False, sheet_name='åˆ†æç»“æœ')

            # è®¾ç½®åˆ—å®½
            worksheet = writer.sheets['åˆ†æç»“æœ']
            for idx, col in enumerate(df.columns, 1):
                max_length = max(df[col].astype(str).map(len).max(), len(str(col)))
                worksheet.column_dimensions[chr(64 + idx)].width = min(max_length + 2, 50)

        logger.info(f'âœ… Excel æŠ¥å‘Šå·²ä¿å­˜: {output_file}')
        return str(output_file)

    def generate_html_report(
        self,
        results: list[dict[str, Any]],
        html_file: Optional[str] = None,
        time_tracker: Optional[TimeTracker] = None,
    ) -> str:
        """
        ç”Ÿæˆ HTML æŠ¥å‘Š

        Args:
            results: åˆ†æç»“æœåˆ—è¡¨
            html_file: HTML æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
            time_tracker: æ—¶é—´è·Ÿè¸ªå™¨ï¼ˆå¯é€‰ï¼‰

        Returns:
            HTML æ–‡ä»¶è·¯å¾„
        """
        if html_file is None:
            output_dir = config.get_output_dir()
            config.ensure_output_dir(output_dir)
            html_file = str(output_dir / EXCEL_REPORT_PATTERN.format(n=len(results)))

        html_file = Path(html_file)
        html_file.parent.mkdir(parents=True, exist_ok=True)

        logger.info(f'\nğŸ“„ ç”Ÿæˆ HTML æŠ¥å‘Š: {html_file}')

        # ç›´æ¥ç”Ÿæˆ HTMLï¼ˆå¤ç”¨ç°æœ‰ä»£ç ç»“æ„ï¼‰
        # è½¬æ¢ç»“æœæ ¼å¼
        formatted_results = []
        for result in results:
            formatted_result = {
                'rank': result['rank'],
                'file_path': result['so_file'],
                'address': f'{Path(result["so_file"]).name}+{result["offset"]}',
                'offset': result['offset'],
                'so_file': result['so_file'],
                'instruction_count': result.get('instruction_count', 0),
                'strings': result.get('strings', ''),
                'call_count': result.get('call_count', 0),
                'event_count': result.get('event_count', 0),
                'llm_result': result.get('llm_result'),
                'function_name': result.get('function_name', ''),
                'function_description': result.get('function_description', ''),
                'confidence': result.get('confidence', ''),
            }
            formatted_results.append(formatted_result)

        html_content = util.render_html_report(
            formatted_results,
            llm_analyzer=self.llm_analyzer if self.use_llm else None,
            time_tracker=time_tracker,
            title='Excel åç§»é‡åˆ†ææŠ¥å‘Š',
        )
        html_path = Path(html_file)
        html_path.parent.mkdir(parents=True, exist_ok=True)
        html_path.write_text(html_content, encoding='utf-8')

        logger.info(f'âœ… HTML æŠ¥å‘Šå·²ä¿å­˜: {html_path}')
        return str(html_path)
